{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lec_8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOqmypoyTdX6cAL1bACfay9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nichtigVermissen/PyTorchZeroToAll/blob/master/lec_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hINA8_Bk2atk",
        "outputId": "142634ec-5c4c-41ea-91f3-d6f24f6996b0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l1bq9ae2cYL",
        "outputId": "b00259a5-5ada-42a8-92d1-0aa65c58f641"
      },
      "source": [
        "cd /content/drive/My Drive/Colab Notebooks/data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfhClZI_k3lz"
      },
      "source": [
        "from torch import nn, from_numpy, tensor, optim\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO7aONprnNTz",
        "outputId": "2ab03024-be8b-4e31-e67b-cf19a37de758"
      },
      "source": [
        "class DiabetesDataset(Dataset):\n",
        "\n",
        "  def __init__(self):\n",
        "    xy = np.loadtxt('./diabetes.csv', delimiter=',', dtype=np.float32)\n",
        "    self.len = xy.shape[0]\n",
        "    self.x_data = from_numpy(xy[:, 0: -1])\n",
        "    self.y_data = from_numpy(xy[:, [-1]])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x_data[index], self.y_data[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "\n",
        "dataset = DiabetesDataset()\n",
        "train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "for epoch in range(2):\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    inputs, labels = data\n",
        "\n",
        "    inputs,labels = tensor(inputs), tensor(labels)\n",
        "\n",
        "    print(f'Epoch:{i} | Inputs {inputs.data} | Labels {labels.data}')\n",
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.l1 = nn.Linear(8, 6) \n",
        "    self.l2 = nn.Linear(6, 4) \n",
        "    self.l3 = nn.Linear(4, 1) \n",
        "\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out1 = self.sigmoid(self.l1(x))\n",
        "    out2 = self.sigmoid(self.l2(out1))\n",
        "    y_pred = self.sigmoid(self.l3(out2))\n",
        "    return y_pred\n",
        "\n",
        "model = Model()\n",
        "\n",
        "criterion = nn.BCELoss(reduction='sum')\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
        "\n",
        "for epoch in range(100):\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    inputs, labels = data\n",
        "    y_pred = model(inputs)\n",
        "    loss = criterion(y_pred, labels)\n",
        "    print(f'Epoch {epoch + 1} | Batch: {i+1} | Loss: {loss.item():.4f}')\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0 | Inputs tensor([[-0.1765,  0.9598,  0.1475, -0.3333, -0.6572, -0.2519, -0.9274,  0.1333],\n",
            "        [ 0.1765,  0.7990,  0.1475,  0.0000,  0.0000,  0.0462, -0.8958, -0.4667],\n",
            "        [-0.6471,  0.0653, -0.1148, -0.5758, -0.6265, -0.0790, -0.8173, -0.9000],\n",
            "        [-0.6471,  0.2965,  0.0492, -0.4141, -0.7281, -0.2131, -0.8796, -0.7667],\n",
            "        [-0.6471, -0.1859,  0.4098, -0.6768, -0.8440, -0.1803, -0.8053, -0.9667],\n",
            "        [-0.5294,  0.2965,  0.4098, -0.5960, -0.3617,  0.0462, -0.8693, -0.9333],\n",
            "        [-0.0588,  0.4372,  0.0820,  0.0000,  0.0000,  0.0402, -0.9564, -0.3333],\n",
            "        [-0.5294, -0.0050,  0.2459, -0.6970, -0.8794, -0.3085, -0.8762,  0.0000],\n",
            "        [ 0.1765, -0.0553,  0.1803, -0.6364,  0.0000, -0.3115, -0.5585,  0.1667],\n",
            "        [ 0.0000, -0.0553,  0.1475, -0.4545, -0.7281,  0.2966, -0.7703,  0.0000],\n",
            "        [-0.7647,  0.1960,  0.0000,  0.0000,  0.0000, -0.4158, -0.3561,  0.7000],\n",
            "        [-0.8824,  0.8995, -0.0164, -0.5354,  1.0000, -0.1028, -0.7267,  0.2667],\n",
            "        [ 0.4118,  0.0653,  0.3115,  0.0000,  0.0000, -0.2966, -0.9496, -0.2333],\n",
            "        [-0.0588,  0.0050,  0.2131, -0.1919, -0.4917,  0.1744, -0.5021, -0.2667],\n",
            "        [-0.5294, -0.0854,  0.1475, -0.3535, -0.7920, -0.0134, -0.6857, -0.9667],\n",
            "        [-0.4118,  0.1658,  0.2131,  0.0000,  0.0000, -0.2370, -0.8950, -0.7000],\n",
            "        [-0.1765,  0.2462,  0.1475, -0.3333, -0.4917, -0.2399, -0.9291, -0.4667],\n",
            "        [-0.8824,  0.2060,  0.3115, -0.0303, -0.5272,  0.1595, -0.0743, -0.3333],\n",
            "        [ 0.1765,  0.2965,  0.2459, -0.4343, -0.7116,  0.0700, -0.8275, -0.4000],\n",
            "        [ 0.0000,  0.1960,  0.0000,  0.0000,  0.0000, -0.0343, -0.9462, -0.9000],\n",
            "        [-0.8824,  0.4070,  0.2131, -0.4747, -0.5745, -0.2817, -0.3595, -0.9333],\n",
            "        [-0.7647,  0.0754,  0.2131, -0.3939, -0.7636,  0.0015, -0.7216, -0.9333],\n",
            "        [ 0.0000,  0.0251,  0.4098, -0.6566, -0.7518, -0.1267, -0.4731, -0.8000],\n",
            "        [-0.5294,  0.4774,  0.2131, -0.4949, -0.3073,  0.0402, -0.7378, -0.7000],\n",
            "        [ 0.0000, -0.0653,  0.6393, -0.2121, -0.8298,  0.2936, -0.1947, -0.5333],\n",
            "        [-0.7647,  0.2764, -0.0492, -0.5152, -0.3499, -0.1744,  0.2997, -0.8667],\n",
            "        [-0.2941,  0.8392,  0.5410,  0.0000,  0.0000,  0.2161,  0.1810, -0.2000],\n",
            "        [-0.7647, -0.0754, -0.1475,  0.0000,  0.0000, -0.1028, -0.9462, -0.9667],\n",
            "        [-0.4118,  0.2362,  0.2131, -0.1919, -0.8180,  0.0164, -0.8369, -0.7667],\n",
            "        [-0.8824,  0.1256,  0.1803, -0.3939, -0.5839,  0.0253, -0.6157, -0.8667],\n",
            "        [ 0.2941,  0.3668,  0.3770, -0.2929, -0.6927, -0.1565, -0.8446, -0.3000],\n",
            "        [-0.8824, -0.1357,  0.0820,  0.0505, -0.8463,  0.2310, -0.2835, -0.7333]]) | Labels tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])\n",
            "Epoch:1 | Inputs tensor([[-0.8824, -0.0050,  0.1803, -0.3939, -0.9574,  0.1505, -0.7148,  0.0000],\n",
            "        [ 0.0000, -0.0251,  0.0492, -0.2727, -0.7636,  0.0969, -0.5542, -0.8667],\n",
            "        [-0.4118,  0.8794,  0.2459, -0.4545, -0.5106,  0.2996, -0.1836,  0.0667],\n",
            "        [-0.8824,  0.0754,  0.1148, -0.6162,  0.0000, -0.2101, -0.9257, -0.9000],\n",
            "        [-0.2941,  0.5477,  0.2131, -0.3535, -0.5437, -0.1267, -0.3501, -0.4000],\n",
            "        [-0.8824, -0.1256,  0.1148, -0.3131, -0.8180,  0.1207, -0.7242, -0.9000],\n",
            "        [-0.0588,  0.5176,  0.2787, -0.3535, -0.5035,  0.2787, -0.6260, -0.5000],\n",
            "        [-0.7647,  0.1256,  0.1148, -0.5556, -0.7778,  0.0164, -0.7976, -0.8333],\n",
            "        [-0.8824,  0.0000,  0.1148, -0.2929,  0.0000, -0.0462, -0.7344, -0.9667],\n",
            "        [-0.2941,  0.3467,  0.1475, -0.5354, -0.6927,  0.0551, -0.6038, -0.7333],\n",
            "        [-0.4118, -0.2161, -0.2131,  0.0000,  0.0000,  0.0045, -0.5081, -0.8667],\n",
            "        [-0.2941, -0.0352,  0.0000,  0.0000,  0.0000, -0.2936, -0.9044, -0.7667],\n",
            "        [-0.1765,  0.8794,  0.1148, -0.2121, -0.2813,  0.1237, -0.8497, -0.3333],\n",
            "        [ 0.0000,  0.2764,  0.3115, -0.2525, -0.5035,  0.0820, -0.3800, -0.9333],\n",
            "        [-0.5294,  0.3769,  0.3770,  0.0000,  0.0000, -0.0700, -0.8514, -0.7000],\n",
            "        [-0.8824, -0.0251,  0.1475, -0.6970,  0.0000, -0.4575, -0.9411,  0.0000],\n",
            "        [-0.7647,  0.0050,  0.0820, -0.5960, -0.7872, -0.0194, -0.3262, -0.7667],\n",
            "        [-0.0588,  0.0050,  0.2459,  0.0000,  0.0000,  0.1535, -0.9044, -0.3000],\n",
            "        [-0.8824, -0.0251,  0.1475, -0.1919,  0.0000,  0.1356, -0.8804, -0.7000],\n",
            "        [-0.1765,  0.9698,  0.4754,  0.0000,  0.0000,  0.1863, -0.6815, -0.3333],\n",
            "        [ 0.0588, -0.0854,  0.1148,  0.0000,  0.0000, -0.2787, -0.8958,  0.2333],\n",
            "        [-0.2941,  0.5477,  0.2787, -0.1717, -0.6690,  0.3741, -0.5790, -0.8000],\n",
            "        [-0.8824,  0.0854,  0.4426, -0.6162,  0.0000, -0.1922, -0.7250, -0.9000],\n",
            "        [-0.6471,  0.3970, -0.1148,  0.0000,  0.0000, -0.2370, -0.7233, -0.9667],\n",
            "        [-0.4118,  0.3668,  0.3770, -0.1717, -0.7920,  0.0432, -0.8224, -0.5333],\n",
            "        [-0.2941,  0.2462,  0.1803,  0.0000,  0.0000, -0.1773, -0.7523, -0.7333],\n",
            "        [-0.1765,  0.0352,  0.0820, -0.3535,  0.0000,  0.1654, -0.7728, -0.6667],\n",
            "        [-0.8824,  0.2864,  0.4426, -0.2121, -0.7400,  0.0879, -0.1640, -0.4667],\n",
            "        [-0.7647, -0.1859,  0.1803, -0.6970, -0.8203, -0.1028, -0.5995, -0.8667],\n",
            "        [ 0.0588,  0.0251,  0.2459, -0.2525,  0.0000, -0.0194, -0.4987, -0.1667],\n",
            "        [ 0.0000,  0.3769,  0.1148, -0.7172, -0.6501, -0.2608, -0.9445,  0.0000],\n",
            "        [-0.8824,  0.0955, -0.0164, -0.8384, -0.5697, -0.2429, -0.2579,  0.0000]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:2 | Inputs tensor([[-0.4118,  0.4774,  0.2295,  0.0000,  0.0000, -0.1088, -0.6960, -0.7667],\n",
            "        [ 0.0000,  0.0251,  0.2787, -0.1919, -0.7872,  0.0283, -0.8634, -0.9000],\n",
            "        [ 0.0000,  0.1357,  0.2459,  0.0000,  0.0000, -0.0075, -0.8292, -0.9333],\n",
            "        [-0.5294,  0.1759,  0.0164, -0.7576,  0.0000, -0.1148, -0.7421, -0.7000],\n",
            "        [-0.8824,  0.1156,  0.0164, -0.7374, -0.5697, -0.2846, -0.9488, -0.9333],\n",
            "        [-0.2941,  0.0854, -0.2787, -0.5960, -0.6927, -0.2846, -0.3723, -0.5333],\n",
            "        [ 0.0000,  0.2965,  0.8033, -0.0707, -0.6927,  1.0000, -0.7942, -0.8333],\n",
            "        [-0.7647,  0.3970,  0.2295,  0.0000,  0.0000, -0.2370, -0.9240, -0.7333],\n",
            "        [-0.6471, -0.1558,  0.1803, -0.3535,  0.0000,  0.1088, -0.8386, -0.7667],\n",
            "        [-0.2941, -0.0754,  0.5082,  0.0000,  0.0000, -0.4069, -0.9061, -0.7667],\n",
            "        [-0.0588,  0.5477,  0.2787, -0.3535,  0.0000, -0.0343, -0.6883, -0.2000],\n",
            "        [ 0.0000,  0.2462,  0.1475, -0.5960,  0.0000, -0.1833, -0.8497, -0.5000],\n",
            "        [-0.0588,  0.0955,  0.2459, -0.2121, -0.7305, -0.1684, -0.5201, -0.6667],\n",
            "        [-0.6471,  0.9397,  0.1475, -0.3737,  0.0000,  0.0402, -0.8608, -0.8667],\n",
            "        [-0.8824,  0.8191,  0.2787, -0.1515, -0.3073,  0.1922,  0.0077, -0.9667],\n",
            "        [-0.4118,  0.1759,  0.4098, -0.3939, -0.7518,  0.1654, -0.8523, -0.3000],\n",
            "        [ 0.0000, -0.2161,  0.4426, -0.4141, -0.9054,  0.0999, -0.6960,  0.0000],\n",
            "        [-0.7647,  0.1859,  0.3115,  0.0000,  0.0000,  0.2787, -0.4748,  0.0000],\n",
            "        [-0.2941,  0.0352,  0.1803, -0.3535, -0.5508,  0.1237, -0.7899,  0.1333],\n",
            "        [-0.8824,  0.2864, -0.2131, -0.0909, -0.5414,  0.2072, -0.5431, -0.9000],\n",
            "        [-0.8824,  0.0251,  0.2131,  0.0000,  0.0000,  0.1773, -0.8164, -0.3000],\n",
            "        [-0.8824, -0.2060, -0.0164, -0.1515, -0.8865,  0.2966, -0.4876, -0.9333],\n",
            "        [ 0.0000,  0.2462, -0.0820, -0.7374, -0.7518, -0.3502, -0.6806,  0.0000],\n",
            "        [-0.1765,  0.0754,  0.2131,  0.0000,  0.0000, -0.1177, -0.8497, -0.6667],\n",
            "        [-0.5294, -0.1457, -0.0492, -0.5556, -0.8842, -0.1714, -0.8053, -0.7667],\n",
            "        [-0.0588,  0.0754,  0.3115,  0.0000,  0.0000, -0.2668, -0.3356, -0.5667],\n",
            "        [ 0.0000,  0.0553,  0.0492, -0.1717, -0.6643,  0.2370, -0.9189, -0.9667],\n",
            "        [-0.4118,  0.0653,  0.3443, -0.3939,  0.0000,  0.1773, -0.8224, -0.4333],\n",
            "        [-0.1765,  0.4271,  0.4754, -0.5152,  0.1348, -0.0939, -0.9573, -0.2667],\n",
            "        [-0.7647, -0.1256, -0.0492, -0.6768, -0.8771, -0.0253, -0.9249, -0.8667],\n",
            "        [ 0.0000,  0.8894,  0.3443, -0.7172, -0.5626, -0.0462, -0.4842, -0.9667],\n",
            "        [-0.6471,  0.3065,  0.2787, -0.5354, -0.8132, -0.1535, -0.7908, -0.5667]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.]])\n",
            "Epoch:3 | Inputs tensor([[-0.7647, -0.0452, -0.1148, -0.7172, -0.7920, -0.2221, -0.4278, -0.9667],\n",
            "        [-0.6471, -0.2161,  0.1475,  0.0000,  0.0000, -0.0313, -0.8360, -0.4000],\n",
            "        [ 0.5294,  0.0653,  0.1475,  0.0000,  0.0000,  0.0194, -0.8523,  0.0333],\n",
            "        [-0.1765,  0.6181,  0.4098,  0.0000,  0.0000, -0.0939, -0.9257, -0.1333],\n",
            "        [-0.2941, -0.0050, -0.0164, -0.6162, -0.8723, -0.1982, -0.6422, -0.6333],\n",
            "        [-0.6471,  0.0050,  0.1148, -0.5354, -0.8085, -0.0581, -0.2562, -0.7667],\n",
            "        [-0.6471,  0.0352,  0.1803, -0.3939, -0.6407, -0.1773, -0.4432, -0.8000],\n",
            "        [-0.1765,  0.0050,  0.0000,  0.0000,  0.0000, -0.1058, -0.6533, -0.6333],\n",
            "        [ 0.0000,  0.0553,  0.3770,  0.0000,  0.0000, -0.1684, -0.4338,  0.3667],\n",
            "        [-0.5294,  0.2060,  0.1148,  0.0000,  0.0000, -0.1177, -0.4611, -0.5667],\n",
            "        [-0.8824,  0.1658,  0.2787, -0.4141, -0.5745,  0.0760, -0.6430, -0.8667],\n",
            "        [-0.6471,  0.6281, -0.1475, -0.2323,  0.0000,  0.1088, -0.5098, -0.9000],\n",
            "        [ 0.0588,  0.7186,  0.8033, -0.5152, -0.4326,  0.3532, -0.4509,  0.1000],\n",
            "        [-0.5294,  0.8995,  0.8033, -0.3737,  0.0000, -0.1505, -0.4859, -0.4667],\n",
            "        [-0.5294,  0.2864,  0.1475,  0.0000,  0.0000,  0.0224, -0.8079, -0.9000],\n",
            "        [-0.8824,  0.1457,  0.0820, -0.2727, -0.5272,  0.1356, -0.8198,  0.0000],\n",
            "        [-0.4118,  0.1256,  0.0820,  0.0000,  0.0000,  0.1267, -0.8437, -0.3333],\n",
            "        [ 0.0000,  0.0553,  0.4754,  0.0000,  0.0000, -0.1177, -0.8984, -0.1667],\n",
            "        [-0.1765,  0.1457,  0.2459, -0.6566, -0.7400, -0.2906, -0.6687, -0.6667],\n",
            "        [ 0.1765, -0.2462,  0.3443,  0.0000,  0.0000, -0.0075, -0.8420, -0.4333],\n",
            "        [-0.7647,  0.0151, -0.0492, -0.2929, -0.7872, -0.3502, -0.9342, -0.9667],\n",
            "        [ 0.4118,  0.4070,  0.3934, -0.3333,  0.0000,  0.1148, -0.8582, -0.3333],\n",
            "        [-0.1765,  0.5075,  0.0820, -0.1515, -0.1915,  0.0343, -0.4535, -0.3000],\n",
            "        [-0.5294,  0.1256,  0.2787, -0.1919,  0.0000,  0.1744, -0.8651, -0.4333],\n",
            "        [ 0.1765,  0.2563,  0.1475, -0.4747, -0.7281, -0.0730, -0.8915, -0.3333],\n",
            "        [-0.7647, -0.2462,  0.0492, -0.5152, -0.8700, -0.1148, -0.7506, -0.6000],\n",
            "        [-0.8824, -0.1156,  0.0164, -0.5152, -0.8960, -0.1088, -0.7062, -0.9333],\n",
            "        [-0.7647, -0.2864,  0.1475, -0.4545,  0.0000, -0.1654, -0.5662, -0.9667],\n",
            "        [-0.7647, -0.0955,  0.1148, -0.1515,  0.0000,  0.1386, -0.6371, -0.8000],\n",
            "        [-0.6471,  0.8090,  0.0492, -0.4949, -0.8345,  0.0134, -0.8352, -0.8333],\n",
            "        [ 0.0000,  0.2161,  0.0820, -0.3939, -0.6099,  0.0224, -0.8933, -0.6000],\n",
            "        [-0.7647, -0.2563,  0.0000,  0.0000,  0.0000,  0.0000, -0.9795, -0.9667]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])\n",
            "Epoch:4 | Inputs tensor([[-0.8824, -0.1156, -0.5082, -0.1515, -0.7660,  0.6393, -0.6430, -0.8333],\n",
            "        [-0.5294, -0.0352, -0.0820, -0.6566, -0.8842, -0.3800, -0.7763, -0.8333],\n",
            "        [-0.5294, -0.0955,  0.4426, -0.0505, -0.8723,  0.1237, -0.7575, -0.7333],\n",
            "        [-0.0588,  0.1256,  0.1803,  0.0000,  0.0000, -0.2966, -0.3493,  0.2333],\n",
            "        [-0.1765, -0.0553,  0.0492, -0.4949, -0.8132, -0.0075, -0.4364, -0.3333],\n",
            "        [-0.4118,  0.1558,  0.6066,  0.0000,  0.0000,  0.5768, -0.8881, -0.7667],\n",
            "        [-0.8824, -0.0251,  0.0492, -0.6162, -0.8061, -0.4575, -0.8113,  0.0000],\n",
            "        [ 0.1765, -0.3166,  0.7377, -0.5354, -0.8842,  0.0581, -0.8232, -0.1333],\n",
            "        [ 0.0588,  0.1256,  0.3443, -0.5152,  0.0000, -0.1595,  0.0282, -0.0333],\n",
            "        [-0.4118, -0.5578,  0.0164,  0.0000,  0.0000, -0.2548, -0.5653, -0.5000],\n",
            "        [-0.8824,  0.2261,  0.0492, -0.3535, -0.6312,  0.0462, -0.4757, -0.7000],\n",
            "        [-0.5294, -0.0452, -0.0164, -0.3535,  0.0000,  0.0551, -0.8241, -0.7667],\n",
            "        [ 0.0000, -0.0653, -0.0164,  0.0000,  0.0000,  0.0522, -0.8420, -0.8667],\n",
            "        [-0.1765,  0.6884,  0.4426, -0.1515, -0.2411,  0.1386, -0.3945, -0.3667],\n",
            "        [ 0.0000,  0.0754,  0.0164, -0.3939, -0.8251,  0.0909, -0.4202, -0.8667],\n",
            "        [-0.5294,  0.8492,  0.2787, -0.2121, -0.3452,  0.1028, -0.8412, -0.6667],\n",
            "        [ 0.0000,  0.1960,  0.0492, -0.6364, -0.7825,  0.0402, -0.4475, -0.9333],\n",
            "        [ 0.0000,  0.0854,  0.1148, -0.5960,  0.0000, -0.1863, -0.3945, -0.6333],\n",
            "        [ 0.0000,  0.1156,  0.0656,  0.0000,  0.0000, -0.2668, -0.5030, -0.6667],\n",
            "        [-0.7647,  0.2462,  0.1148, -0.4343, -0.5154, -0.0194, -0.3194, -0.7000],\n",
            "        [ 0.0588,  0.7085,  0.2131, -0.3737,  0.0000,  0.3115, -0.7225, -0.2667],\n",
            "        [-0.0588,  0.2663,  0.4426, -0.2727, -0.7447,  0.1475, -0.7686, -0.0667],\n",
            "        [-0.8824, -0.1558,  0.0492, -0.5354, -0.7281,  0.0999, -0.6644, -0.7667],\n",
            "        [ 0.0000,  0.0251,  0.2295, -0.5354,  0.0000,  0.0000, -0.5781,  0.0000],\n",
            "        [ 0.0588,  0.0653, -0.1475,  0.0000,  0.0000, -0.0700, -0.7421, -0.3000],\n",
            "        [ 0.0000,  0.0452,  0.0492, -0.2525, -0.8487,  0.0015, -0.6311, -0.9667],\n",
            "        [-0.8824, -0.0452,  0.3443, -0.4949, -0.5745,  0.0432, -0.8676, -0.2667],\n",
            "        [-0.6471, -0.1960,  0.0000,  0.0000,  0.0000,  0.0000, -0.9180, -0.9667],\n",
            "        [-0.7647,  0.2965,  0.3770,  0.0000,  0.0000, -0.1654, -0.8241, -0.8000],\n",
            "        [-0.0588, -0.2563,  0.1475, -0.1919, -0.8842,  0.0522, -0.4646, -0.4000],\n",
            "        [-0.6471, -0.1256, -0.0164, -0.6364,  0.0000, -0.3502, -0.6874,  0.0000],\n",
            "        [-0.6471,  0.4874,  0.0820, -0.4949,  0.0000, -0.0313, -0.8480, -0.9667]]) | Labels tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:5 | Inputs tensor([[-0.6471, -0.1558,  0.1148, -0.3939, -0.7494, -0.0492, -0.5619, -0.8667],\n",
            "        [-0.6471,  0.1357, -0.2787, -0.7374,  0.0000, -0.3323, -0.9471, -0.9667],\n",
            "        [-0.4118, -0.2261,  0.3443, -0.1717, -0.9007,  0.0671, -0.9334, -0.5333],\n",
            "        [ 0.0588,  0.6583,  0.4426,  0.0000,  0.0000, -0.0939, -0.8087, -0.0667],\n",
            "        [-0.6471, -0.0050, -0.1148, -0.6162, -0.7967, -0.2370, -0.9351, -0.9000],\n",
            "        [-0.5294,  0.5879,  0.2787,  0.0000,  0.0000, -0.0194, -0.3809, -0.6667],\n",
            "        [-0.7647,  0.0050,  0.0492, -0.5354,  0.0000, -0.1148, -0.7523,  0.0000],\n",
            "        [-0.2941,  0.6583,  0.1148, -0.4747, -0.6028,  0.0015, -0.5278, -0.0667],\n",
            "        [-0.2941,  0.1457,  0.0000,  0.0000,  0.0000,  0.0000, -0.9052, -0.8333],\n",
            "        [-0.2941, -0.1457,  0.2787,  0.0000,  0.0000, -0.0700, -0.7404, -0.3000],\n",
            "        [ 0.1765,  0.1558,  0.0000,  0.0000,  0.0000,  0.0522, -0.9522, -0.7333],\n",
            "        [-0.0588,  0.8894,  0.2787,  0.0000,  0.0000,  0.4277, -0.9496, -0.2667],\n",
            "        [-0.6471, -0.1759,  0.1475,  0.0000,  0.0000, -0.3711, -0.7344, -0.8667],\n",
            "        [ 0.0000,  0.0151,  0.0492, -0.6566,  0.0000, -0.3741, -0.8514,  0.0000],\n",
            "        [-0.6471,  0.7387,  0.3443, -0.0303,  0.0993,  0.1446,  0.7583, -0.8667],\n",
            "        [ 0.0000,  0.1357,  0.3115, -0.6768,  0.0000, -0.0760, -0.3202,  0.0000],\n",
            "        [-0.5294,  0.1156,  0.1803, -0.0505, -0.5106,  0.1058,  0.1204,  0.1667],\n",
            "        [-0.4118,  0.8995,  0.0492, -0.3333, -0.2317, -0.0700, -0.5687, -0.7333],\n",
            "        [-0.7647,  0.5879,  0.4754,  0.0000,  0.0000, -0.0581, -0.3792,  0.5000],\n",
            "        [-0.8824,  0.4372,  0.3770, -0.5354, -0.2671,  0.2638, -0.1477, -0.9667],\n",
            "        [-0.2941,  0.1558, -0.0164, -0.2121,  0.0000,  0.0045, -0.8574, -0.3667],\n",
            "        [-0.8824, -0.2663, -0.1803, -0.7980,  0.0000, -0.3145, -0.8548,  0.0000],\n",
            "        [-0.5294,  0.9799,  0.1475, -0.2121,  0.7589,  0.0939,  0.9223, -0.6667],\n",
            "        [-0.4118, -0.2663, -0.0164,  0.0000,  0.0000, -0.2012, -0.8377, -0.8000],\n",
            "        [-0.1765,  0.0553,  0.0000,  0.0000,  0.0000,  0.0000, -0.8061, -0.9000],\n",
            "        [ 0.0000, -0.3266,  0.2459,  0.0000,  0.0000,  0.3502, -0.9009, -0.1667],\n",
            "        [-0.7647, -0.0151, -0.0164, -0.6566, -0.7163,  0.0343, -0.8975, -0.9667],\n",
            "        [-0.1765,  0.5075,  0.2787, -0.4141, -0.7021,  0.0492, -0.4757,  0.1000],\n",
            "        [-0.4118,  0.3970,  0.0492, -0.2929, -0.6690, -0.1475, -0.7156, -0.8333],\n",
            "        [-0.1765,  0.7990,  0.5574, -0.3737,  0.0000,  0.0194, -0.9266,  0.3000],\n",
            "        [-0.8824, -0.0452,  0.0820, -0.7374, -0.9102, -0.4158, -0.7814, -0.8667],\n",
            "        [-0.1765,  0.9497,  0.1148, -0.4343,  0.0000,  0.0700, -0.4304, -0.3333]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]])\n",
            "Epoch:6 | Inputs tensor([[-0.5294, -0.0754,  0.3115,  0.0000,  0.0000,  0.2578, -0.8642, -0.7333],\n",
            "        [ 0.0588, -0.4271,  0.3115, -0.2525,  0.0000, -0.0224, -0.9846, -0.3333],\n",
            "        [ 0.0000,  0.3467, -0.0492, -0.5960, -0.3121, -0.2131, -0.7660,  0.0000],\n",
            "        [-0.7647, -0.3166,  0.0164, -0.7374, -0.9645, -0.4009, -0.8471, -0.9333],\n",
            "        [-0.8824,  0.5176, -0.0164,  0.0000,  0.0000, -0.2221, -0.9137, -0.9667],\n",
            "        [ 0.1765,  0.2261,  0.2787, -0.3737,  0.0000, -0.1773, -0.6294, -0.2000],\n",
            "        [-0.8824,  0.1960,  0.4426, -0.1717, -0.5981,  0.3502, -0.6336, -0.8333],\n",
            "        [-0.7647,  0.2261,  0.2459, -0.4545, -0.5272,  0.0700, -0.6541, -0.8333],\n",
            "        [-0.7647, -0.0050,  0.1475, -0.6768, -0.8960, -0.3920, -0.8659, -0.8000],\n",
            "        [-0.5294,  0.1859,  0.1475,  0.0000,  0.0000,  0.3264, -0.2946, -0.8333],\n",
            "        [-0.6471, -0.1055,  0.2131, -0.6768, -0.7991, -0.0939, -0.5961, -0.4333],\n",
            "        [-0.0588, -0.0452,  0.1803,  0.0000,  0.0000,  0.0969, -0.6524,  0.2000],\n",
            "        [-0.2941, -0.0653, -0.1803, -0.3939, -0.8487, -0.1446, -0.7626, -0.9333],\n",
            "        [ 0.0588,  0.8492,  0.3934, -0.6970,  0.0000, -0.1058, -0.0307, -0.0667],\n",
            "        [ 0.0000,  0.2362,  0.1803,  0.0000,  0.0000,  0.0820, -0.8463,  0.0333],\n",
            "        [-0.6471,  0.1658,  0.0000,  0.0000,  0.0000, -0.2996, -0.9069, -0.9333],\n",
            "        [-0.7647, -0.1859, -0.0164, -0.5556,  0.0000, -0.1744, -0.8190, -0.8667],\n",
            "        [-0.5294,  0.1457,  0.0656,  0.0000,  0.0000, -0.3472, -0.6977, -0.4667],\n",
            "        [-0.4118,  0.4372,  0.2787,  0.0000,  0.0000,  0.3413, -0.9044, -0.1333],\n",
            "        [-0.7647,  0.1256,  0.4098, -0.1515, -0.6217,  0.1446, -0.8565, -0.7667],\n",
            "        [-0.1765,  0.1457,  0.0820,  0.0000,  0.0000, -0.0224, -0.8463, -0.3000],\n",
            "        [ 0.0000,  0.2362,  0.4426, -0.2525,  0.0000,  0.0492, -0.8984, -0.7333],\n",
            "        [-0.4118,  0.2161,  0.1803, -0.5354, -0.7352, -0.2191, -0.8574, -0.7000],\n",
            "        [-0.2941,  0.0000,  0.1148, -0.1717,  0.0000,  0.1624, -0.4458, -0.3333],\n",
            "        [ 0.1765, -0.0955,  0.3934, -0.3535,  0.0000,  0.0402, -0.3621,  0.1667],\n",
            "        [-0.0588,  0.2663,  0.2131, -0.2323, -0.8227, -0.2280, -0.9283, -0.4000],\n",
            "        [-0.8824, -0.2864, -0.2131, -0.6364, -0.8203, -0.3920, -0.7908, -0.9667],\n",
            "        [ 0.1765,  0.2965,  0.0164, -0.2727,  0.0000,  0.2280, -0.6900, -0.4333],\n",
            "        [ 0.0000, -0.0854,  0.1148, -0.3535, -0.5035,  0.1893, -0.7412, -0.8667],\n",
            "        [-0.6471,  0.3266,  0.3115,  0.0000,  0.0000,  0.0253, -0.7233, -0.2333],\n",
            "        [-0.8824, -0.1759,  0.0492, -0.7374, -0.7754, -0.3681, -0.7122, -0.9333],\n",
            "        [-0.6471, -0.1156, -0.0492, -0.7778, -0.8723, -0.2608, -0.8386, -0.9667]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:7 | Inputs tensor([[-0.8824, -0.0452,  0.2131, -0.5758, -0.8274, -0.2280, -0.4919, -0.5000],\n",
            "        [ 0.5294,  0.4573,  0.3443, -0.6162, -0.7400, -0.3383, -0.8574,  0.2000],\n",
            "        [-0.5294,  0.4472,  0.3443, -0.3535,  0.0000,  0.1475, -0.5935, -0.4667],\n",
            "        [ 0.2941,  0.0352,  0.1148, -0.1919,  0.0000,  0.3770, -0.9590, -0.3000],\n",
            "        [-0.5294,  0.4472, -0.0492, -0.4343, -0.6690, -0.1207, -0.8215, -0.4667],\n",
            "        [ 0.0000, -0.2663,  0.0000,  0.0000,  0.0000, -0.3711, -0.7746, -0.8667],\n",
            "        [ 0.0000,  0.3266,  0.2787,  0.0000,  0.0000, -0.0343, -0.7310,  0.0000],\n",
            "        [-0.4118,  0.1658,  0.2131, -0.4141,  0.0000, -0.0373, -0.5030, -0.5333],\n",
            "        [-0.4118,  0.2864,  0.3115,  0.0000,  0.0000,  0.0313, -0.9436, -0.2000],\n",
            "        [ 0.0000,  0.6583,  0.2459, -0.1313, -0.3972,  0.4277, -0.8454, -0.8333],\n",
            "        [-0.0588, -0.3467,  0.1803, -0.5354,  0.0000, -0.0462, -0.5542, -0.3000],\n",
            "        [-0.1765,  0.2965,  0.1148, -0.0101, -0.7045,  0.1475, -0.6917, -0.2667],\n",
            "        [-0.6471,  0.2663,  0.4426, -0.1717, -0.4444,  0.1714, -0.4654, -0.8000],\n",
            "        [-0.7647,  0.2261, -0.0164, -0.6364, -0.7494, -0.1118, -0.4543, -0.9667],\n",
            "        [-0.7647, -0.0553,  0.1148, -0.6364, -0.8203, -0.2250, -0.5875,  0.0000],\n",
            "        [-0.2941,  0.6683,  0.2131,  0.0000,  0.0000, -0.2072, -0.8070,  0.5000],\n",
            "        [-0.2941,  0.1960, -0.1803, -0.5556, -0.5839, -0.1922,  0.0589, -0.6000],\n",
            "        [ 0.0000,  0.0251, -0.1475,  0.0000,  0.0000, -0.2519,  0.0000,  0.0000],\n",
            "        [-0.1765,  0.0653, -0.0164, -0.5152,  0.0000, -0.2101, -0.8138, -0.7333],\n",
            "        [-0.4118,  0.0955,  0.0164, -0.1717, -0.6950,  0.0671, -0.6277, -0.8667],\n",
            "        [-0.8824,  0.0754, -0.1803, -0.6162,  0.0000, -0.1565, -0.9120, -0.7333],\n",
            "        [-0.6471,  0.2965,  0.5082, -0.0101, -0.6336,  0.0849, -0.2400, -0.6333],\n",
            "        [ 0.2941,  0.3869,  0.2131, -0.4747, -0.6596,  0.0760, -0.5909, -0.0333],\n",
            "        [-0.1765,  0.8794, -0.1803, -0.3333, -0.0733,  0.0104, -0.3612, -0.5667],\n",
            "        [-0.4118, -0.1156,  0.2787, -0.3939,  0.0000, -0.1773, -0.8463, -0.4667],\n",
            "        [ 0.1765,  0.1156,  0.1475, -0.4545,  0.0000, -0.1803, -0.9462, -0.3667],\n",
            "        [-0.8824,  0.3065,  0.1475, -0.7374, -0.7518, -0.2280, -0.6635, -0.9667],\n",
            "        [-0.7647,  0.4673,  0.1475, -0.2323, -0.1489, -0.1654, -0.7788, -0.7333],\n",
            "        [ 0.0000,  0.1859,  0.0492, -0.5354, -0.7896,  0.0000,  0.4116,  0.0000],\n",
            "        [ 0.0000,  0.5276,  0.3443, -0.2121, -0.3570,  0.2370, -0.8360, -0.8000],\n",
            "        [-0.8824, -0.1960,  0.2131, -0.7778, -0.8582, -0.1058, -0.6166, -0.9667],\n",
            "        [-0.2941,  0.0553,  0.1475, -0.3535, -0.8392, -0.0820, -0.9624, -0.4667]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:8 | Inputs tensor([[-0.8824,  0.5377,  0.3443, -0.1515,  0.1466,  0.2101, -0.4799, -0.9333],\n",
            "        [ 0.2941, -0.1457,  0.2131,  0.0000,  0.0000, -0.1028, -0.8104, -0.5333],\n",
            "        [ 0.5294,  0.2965,  0.0000, -0.3939,  0.0000,  0.1893, -0.5807, -0.2333],\n",
            "        [-0.6471,  0.2161, -0.1475,  0.0000,  0.0000,  0.0730, -0.9582, -0.8667],\n",
            "        [ 0.0000,  0.8191,  0.4426, -0.1111,  0.2057,  0.2906, -0.8770, -0.8333],\n",
            "        [-0.8824,  0.3869,  0.3443,  0.0000,  0.0000,  0.1952, -0.8651, -0.7667],\n",
            "        [ 0.0000, -0.0452,  0.3115, -0.0909, -0.7825,  0.0879, -0.7848, -0.8333],\n",
            "        [-0.1765, -0.0251,  0.2459, -0.3535, -0.7849,  0.2191, -0.3228, -0.6333],\n",
            "        [-0.6471,  0.4171,  0.0000,  0.0000,  0.0000, -0.1058, -0.4167, -0.8000],\n",
            "        [-0.2941, -0.1256,  0.3115,  0.0000,  0.0000, -0.3085, -0.9949, -0.6333],\n",
            "        [-0.7647,  0.1759,  0.4754, -0.6162, -0.8322, -0.2489, -0.7993,  0.0000],\n",
            "        [ 0.0000,  0.4774,  0.3934,  0.0909,  0.0000,  0.2757, -0.7464, -0.9000],\n",
            "        [-0.1765, -0.1859,  0.2787, -0.1919, -0.8865,  0.3920, -0.8437, -0.3000],\n",
            "        [-0.6471, -0.0955,  0.2787,  0.0000,  0.0000,  0.2727, -0.5892,  0.0000],\n",
            "        [ 0.0588,  0.4070,  0.5410,  0.0000,  0.0000, -0.0253, -0.4398, -0.2000],\n",
            "        [-0.5294, -0.0955,  0.0000,  0.0000,  0.0000, -0.1654, -0.5457, -0.6667],\n",
            "        [ 1.0000,  0.6382,  0.1803, -0.1717, -0.7305,  0.2191, -0.3689, -0.1333],\n",
            "        [ 0.1765, -0.0754,  0.0164,  0.0000,  0.0000, -0.2280, -0.9240, -0.6667],\n",
            "        [-0.2941,  0.0352,  0.0820,  0.0000,  0.0000, -0.2757, -0.8540, -0.7333],\n",
            "        [-0.8824,  0.1859, -0.0492, -0.2727, -0.7778, -0.0075, -0.8437, -0.9333],\n",
            "        [-0.8824, -0.2864,  0.2787,  0.0101, -0.8936, -0.0104, -0.7062,  0.0000],\n",
            "        [-0.7647,  0.2764, -0.2459, -0.5758, -0.2080,  0.0253, -0.9163, -0.9667],\n",
            "        [ 0.4118, -0.1156,  0.2131, -0.1919, -0.8723,  0.0522, -0.7438, -0.1000],\n",
            "        [ 0.0000,  0.7990, -0.1803, -0.2727, -0.6241,  0.1267, -0.6781, -0.9667],\n",
            "        [-0.5294,  0.1658,  0.1803, -0.7576, -0.7943, -0.3413, -0.6712, -0.4667],\n",
            "        [ 0.0000,  0.0151,  0.0656, -0.4343,  0.0000, -0.2668, -0.8642, -0.9667],\n",
            "        [-0.2941,  0.4874,  0.1803, -0.2929,  0.0000,  0.0015, -0.5312, -0.0333],\n",
            "        [-0.7647,  0.5578, -0.1475, -0.4545,  0.2766,  0.1535, -0.8617, -0.8667],\n",
            "        [-0.6471,  0.6985,  0.2131, -0.6162, -0.7045, -0.1088, -0.8377, -0.6667],\n",
            "        [-0.7647,  0.1558,  0.0492, -0.5556,  0.0000, -0.0820, -0.7071,  0.0000],\n",
            "        [ 0.0000,  0.8090,  0.2787,  0.2727, -0.9669,  0.7705,  1.0000, -0.8667],\n",
            "        [-0.7647,  0.3467,  0.1475,  0.0000,  0.0000, -0.1386, -0.6038, -0.9333]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.]])\n",
            "Epoch:9 | Inputs tensor([[-0.6471,  0.8291,  0.2131,  0.0000,  0.0000, -0.0909, -0.7720, -0.7333],\n",
            "        [-0.8824,  0.1156,  0.4098, -0.6162,  0.0000, -0.1028, -0.9445, -0.9333],\n",
            "        [-0.7647,  0.0050, -0.1148, -0.4343, -0.7518,  0.1267, -0.6413, -0.9000],\n",
            "        [-0.2941,  0.2563,  0.2787, -0.3737,  0.0000, -0.1773, -0.5841, -0.0667],\n",
            "        [-0.8824, -0.1055, -0.6066, -0.6162, -0.9409, -0.1714, -0.5892,  0.0000],\n",
            "        [-0.7647,  0.2563, -0.0164, -0.5960, -0.6690,  0.0075, -0.9915, -0.6667],\n",
            "        [-0.8824,  0.1759, -0.0164, -0.5354, -0.7494,  0.0075, -0.6687, -0.8000],\n",
            "        [-0.4118,  0.1759,  0.5082,  0.0000,  0.0000,  0.0164, -0.7788, -0.4333],\n",
            "        [-0.8824,  0.0653,  0.1475, -0.4343, -0.6809,  0.0194, -0.9453, -0.9667],\n",
            "        [ 0.0000,  0.3769,  0.3770, -0.4545,  0.0000, -0.1863, -0.8693,  0.2667],\n",
            "        [ 0.0588,  0.5678,  0.4098, -0.4343, -0.6336,  0.0224, -0.0512, -0.3000],\n",
            "        [-0.8824, -0.0754,  0.0164, -0.4949, -0.9031, -0.4188, -0.6550, -0.8667],\n",
            "        [ 0.4118, -0.0754,  0.0164, -0.8586, -0.3901, -0.1773, -0.2758, -0.2333],\n",
            "        [ 0.0588, -0.2764,  0.2787, -0.4949,  0.0000, -0.0581, -0.8275, -0.4333],\n",
            "        [ 0.0000,  0.4070,  0.0656, -0.4747, -0.6927,  0.2697, -0.6985, -0.9000],\n",
            "        [ 0.0000,  0.6784,  0.0000,  0.0000,  0.0000, -0.0373, -0.3501, -0.7000],\n",
            "        [-0.8824, -0.2060,  0.3115, -0.4949, -0.9125, -0.2429, -0.5687, -0.9667],\n",
            "        [ 0.0000,  0.0653,  0.1475, -0.2525, -0.6501,  0.1744, -0.5500, -0.9667],\n",
            "        [-0.8824,  0.8090,  0.0000,  0.0000,  0.0000,  0.2906, -0.8258, -0.3333],\n",
            "        [-0.6471, -0.1658, -0.0492, -0.3737, -0.9574,  0.0224, -0.7797, -0.8667],\n",
            "        [-0.8824,  0.7286,  0.1148, -0.0101,  0.3688,  0.2638, -0.4671, -0.7667],\n",
            "        [-0.8824,  0.0653,  0.2459,  0.0000,  0.0000,  0.1177, -0.8984, -0.8333],\n",
            "        [-0.5294,  0.4271,  0.4098,  0.0000,  0.0000,  0.3115, -0.5158, -0.9667],\n",
            "        [ 0.0000,  0.0452,  0.2459,  0.0000,  0.0000, -0.4516, -0.5696, -0.8000],\n",
            "        [-0.7647, -0.0050,  0.0000,  0.0000,  0.0000, -0.3383, -0.9744, -0.9333],\n",
            "        [-0.7647,  0.5578,  0.2131, -0.6566, -0.7731, -0.2072, -0.6968, -0.8000],\n",
            "        [-0.8824, -0.2261, -0.0820, -0.3939, -0.8676, -0.0075,  0.0017, -0.9000],\n",
            "        [ 0.1765,  0.6884,  0.2131,  0.0000,  0.0000,  0.1326, -0.6080, -0.5667],\n",
            "        [-0.5294, -0.2362,  0.0164,  0.0000,  0.0000,  0.0134, -0.7327, -0.8667],\n",
            "        [-0.1765,  0.1457,  0.0492,  0.0000,  0.0000, -0.1833, -0.4415, -0.5667],\n",
            "        [-0.5294,  0.2261,  0.1148,  0.0000,  0.0000,  0.0432, -0.7301, -0.7333],\n",
            "        [ 0.0000,  0.4171,  0.3770, -0.4747,  0.0000, -0.0343, -0.6968, -0.9667]]) | Labels tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:10 | Inputs tensor([[-0.8824, -0.0653, -0.0820, -0.7778,  0.0000, -0.3294, -0.7105, -0.9667],\n",
            "        [ 0.0000,  0.0050,  0.4426,  0.2121, -0.7400,  0.3949, -0.2451, -0.6667],\n",
            "        [-0.5294,  0.4673,  0.3934, -0.4545, -0.7636, -0.1386, -0.9052, -0.8000],\n",
            "        [-0.6471, -0.0050,  0.0164, -0.6162, -0.8251, -0.3502, -0.8284, -0.8333],\n",
            "        [ 0.0000,  0.2663,  0.3770, -0.4141, -0.4917, -0.0849, -0.6225, -0.9000],\n",
            "        [-0.6471,  0.2462,  0.3115, -0.3333, -0.6927, -0.0104, -0.8061, -0.8333],\n",
            "        [-0.7647, -0.1457,  0.0656,  0.0000,  0.0000,  0.1803, -0.2724, -0.8000],\n",
            "        [-0.8824,  0.3970,  0.0164, -0.1717,  0.1348,  0.2131, -0.6089,  0.0000],\n",
            "        [ 0.7647,  0.3668,  0.1475, -0.3535, -0.7400,  0.1058, -0.9360, -0.2667],\n",
            "        [-0.8824, -0.1859,  0.2131, -0.1717, -0.8652,  0.3800, -0.1307, -0.6333],\n",
            "        [ 0.0000, -0.1558,  0.3443, -0.3737, -0.7045,  0.1386, -0.8676, -0.9333],\n",
            "        [-0.2941,  0.2563,  0.1148, -0.3939, -0.7163, -0.1058, -0.6704, -0.6333],\n",
            "        [-0.8824,  0.7387,  0.2131,  0.0000,  0.0000,  0.0969, -0.9915, -0.4333],\n",
            "        [ 0.0000,  0.0251,  0.0492, -0.0707, -0.8156,  0.2101, -0.6430,  0.0000],\n",
            "        [ 0.0000,  0.6281,  0.2459,  0.1313, -0.7636,  0.5857, -0.4184, -0.8667],\n",
            "        [-0.7647,  0.4171, -0.0492, -0.3131, -0.6974, -0.2429, -0.4697, -0.9000],\n",
            "        [-0.8824,  0.2864,  0.3443, -0.6566, -0.5674, -0.1803, -0.9684, -0.9667],\n",
            "        [-0.8824,  1.0000,  0.2459, -0.1313,  0.0000,  0.2787,  0.1238, -0.9667],\n",
            "        [ 0.0000,  0.4573,  0.0000,  0.0000,  0.0000,  0.3174, -0.5286, -0.6667],\n",
            "        [-0.5294,  0.0352, -0.0164, -0.3333, -0.5461, -0.2846, -0.2417, -0.6000],\n",
            "        [-0.6471,  0.2864,  0.2787,  0.0000,  0.0000, -0.3711, -0.8377,  0.1333],\n",
            "        [-0.4118, -0.0251,  0.2459, -0.4545,  0.0000,  0.0611, -0.7438,  0.0333],\n",
            "        [ 0.0000,  0.3166,  0.4426,  0.0000,  0.0000, -0.0581, -0.4321, -0.6333],\n",
            "        [ 0.0000,  0.2060,  0.2131, -0.6364, -0.8511, -0.0909, -0.8232, -0.8333],\n",
            "        [-0.0588,  0.2060,  0.0000,  0.0000,  0.0000, -0.1058, -0.9103, -0.4333],\n",
            "        [-0.6471,  0.5879,  0.2459, -0.2727, -0.4208, -0.0581, -0.3399, -0.7667],\n",
            "        [-0.8824,  0.1759,  0.4426, -0.5152, -0.6572,  0.0283, -0.7225, -0.3667],\n",
            "        [-0.8824, -0.1055,  0.0820, -0.5354, -0.7778, -0.1624, -0.9240,  0.0000],\n",
            "        [-0.8824,  0.4372,  0.4098, -0.3939, -0.2199, -0.1028, -0.3049, -0.9333],\n",
            "        [-0.7647,  0.2060, -0.1148,  0.0000,  0.0000, -0.2012, -0.6781, -0.8000],\n",
            "        [-0.7647,  0.0553, -0.0492, -0.1919, -0.7778,  0.0402, -0.8745, -0.8667],\n",
            "        [ 0.0000,  0.1759,  0.0820, -0.3737, -0.5556, -0.0820, -0.6456, -0.9667]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:11 | Inputs tensor([[-0.8824,  0.0000, -0.2131, -0.5960,  0.0000, -0.2638, -0.9471, -0.9667],\n",
            "        [ 0.0000,  0.0553,  0.1148, -0.5556,  0.0000, -0.4039, -0.8651, -0.9667],\n",
            "        [-0.7647,  0.0151, -0.0492, -0.6566, -0.3735, -0.2787, -0.5423, -0.9333],\n",
            "        [-0.6471, -0.0352, -0.0820, -0.3131, -0.7281, -0.2638, -0.2605, -0.4000],\n",
            "        [ 0.0000,  0.2563,  0.5738,  0.0000,  0.0000, -0.3294, -0.8429,  0.0000],\n",
            "        [-0.7647,  0.0854,  0.0164, -0.3535, -0.8676, -0.2489, -0.9573,  0.0000],\n",
            "        [-0.6471, -0.2563,  0.1148, -0.4343, -0.8936, -0.1148, -0.8164, -0.9333],\n",
            "        [ 0.0000,  0.7789, -0.0164, -0.4141,  0.1300,  0.0313, -0.1512,  0.0000],\n",
            "        [-0.7647, -0.0854,  0.0164,  0.0000,  0.0000, -0.1863, -0.6183, -0.9667],\n",
            "        [-0.4118, -0.1357,  0.1148, -0.4343, -0.8322, -0.0999, -0.7558, -0.9000],\n",
            "        [ 0.0000, -0.0452,  0.3934, -0.4949, -0.9149,  0.1148, -0.8557, -0.9000],\n",
            "        [-0.8824,  0.5779,  0.1803, -0.5758, -0.6028, -0.2370, -0.9616, -0.9000],\n",
            "        [ 0.0000,  0.3166,  0.0820, -0.1919,  0.0000,  0.0224, -0.8992, -0.9667],\n",
            "        [-0.7647, -0.0955,  0.3115, -0.7172, -0.8700, -0.2727, -0.8540, -0.9000],\n",
            "        [-0.8824, -0.0653,  0.1475, -0.3737,  0.0000, -0.0939, -0.7976, -0.9333],\n",
            "        [ 0.0000, -0.0854,  0.3115,  0.0000,  0.0000, -0.0343, -0.5534, -0.8000],\n",
            "        [-0.7647,  0.0854,  0.0164, -0.7980, -0.3428, -0.2459, -0.3143, -0.9667],\n",
            "        [ 0.0000,  0.2563,  0.1148,  0.0000,  0.0000, -0.2638, -0.8907,  0.0000],\n",
            "        [-0.4118,  0.6683,  0.2459,  0.0000,  0.0000,  0.3621, -0.7763, -0.8000],\n",
            "        [-0.7647, -0.1558,  0.0000,  0.0000,  0.0000,  0.0000, -0.8070,  0.0000],\n",
            "        [-0.1765,  0.7889,  0.3770,  0.0000,  0.0000,  0.1893, -0.7839, -0.3333],\n",
            "        [-0.1765,  0.3668,  0.4754,  0.0000,  0.0000, -0.1088, -0.8873, -0.0333],\n",
            "        [-0.7647, -0.1759, -0.1475, -0.5556, -0.7281, -0.1505,  0.3843, -0.8667],\n",
            "        [-0.5294,  0.2965, -0.0164, -0.7576, -0.4539, -0.1803, -0.6166, -0.6667],\n",
            "        [ 0.0000,  0.9900,  0.0820, -0.3535, -0.3522,  0.2310, -0.6379, -0.7667],\n",
            "        [-0.4118, -0.0452,  0.1803, -0.3333,  0.0000,  0.1237, -0.7506, -0.8000],\n",
            "        [-0.4118,  0.2663,  0.2787, -0.4545, -0.9480, -0.1177, -0.6917, -0.3667],\n",
            "        [ 0.0000,  0.7990,  0.4754, -0.4545,  0.0000,  0.3145, -0.4808, -0.9333],\n",
            "        [-0.6471,  0.7688,  0.4098, -0.4545, -0.6312, -0.0075, -0.0811,  0.0333],\n",
            "        [ 0.1765,  0.0151,  0.4098, -0.2525,  0.0000,  0.3592, -0.0965, -0.4333],\n",
            "        [-0.5294,  0.5477,  0.1803, -0.4141, -0.7021, -0.0671, -0.7780, -0.4667],\n",
            "        [-0.7647,  0.9799,  0.1475,  1.0000,  0.0000,  0.0343, -0.5756,  0.3667]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.]])\n",
            "Epoch:12 | Inputs tensor([[-0.8824,  0.2563,  0.1475, -0.5152, -0.7400, -0.2757, -0.8779, -0.8667],\n",
            "        [-0.6471,  0.1156, -0.0492, -0.3737, -0.8960, -0.1207, -0.6994, -0.9667],\n",
            "        [-0.5294, -0.0452,  0.0492,  0.0000,  0.0000, -0.0462, -0.9291, -0.6667],\n",
            "        [-0.5294,  0.3166,  0.1148, -0.5758, -0.6076, -0.0134, -0.9300, -0.7667],\n",
            "        [-0.8824,  0.0050,  0.2131, -0.7576, -0.8913, -0.4188, -0.9394, -0.7667],\n",
            "        [-0.7647,  0.2261,  0.1475, -0.4545,  0.0000,  0.0969, -0.7763, -0.8000],\n",
            "        [-0.6471,  0.7387,  0.2787, -0.2121, -0.5626,  0.0075, -0.2383, -0.6667],\n",
            "        [-0.4118,  0.6281,  0.7049,  0.0000,  0.0000,  0.1237, -0.9377,  0.0333],\n",
            "        [ 0.4118,  0.0050,  0.3770, -0.3333, -0.7518, -0.1058, -0.6499, -0.1667],\n",
            "        [-0.7647, -0.0050, -0.0164, -0.6566, -0.6217,  0.0909, -0.6798,  0.0000],\n",
            "        [-0.7647,  0.0854,  0.0492,  0.0000,  0.0000, -0.0820, -0.9317,  0.0000],\n",
            "        [-0.6471,  0.5879,  0.1475, -0.3939, -0.2246,  0.0581, -0.7728, -0.5333],\n",
            "        [-0.8824,  0.0151, -0.1803, -0.6970, -0.9149, -0.2787, -0.6174, -0.8333],\n",
            "        [-0.6471,  0.7387,  0.3770, -0.3333,  0.1206,  0.0641, -0.8463, -0.9667],\n",
            "        [-0.2941, -0.0754,  0.0164, -0.3535, -0.7021, -0.0462, -0.9940, -0.1667],\n",
            "        [-0.7647, -0.1156,  0.2131, -0.6162, -0.8747, -0.1356, -0.8711, -0.9667],\n",
            "        [-0.5294,  0.3467,  0.1803,  0.0000,  0.0000, -0.2906, -0.8301,  0.3000],\n",
            "        [-0.0588,  0.0854,  0.1475,  0.0000,  0.0000, -0.0909, -0.2511, -0.6000],\n",
            "        [-0.1765, -0.3769,  0.2787,  0.0000,  0.0000, -0.0283, -0.7327, -0.3333],\n",
            "        [ 0.0588,  0.2462,  0.1475, -0.3333, -0.0496,  0.0551, -0.8258, -0.5667],\n",
            "        [-0.5294, -0.0251, -0.0164, -0.5354,  0.0000, -0.1595, -0.6883, -0.9667],\n",
            "        [ 0.0000, -0.0050,  0.0000,  0.0000,  0.0000, -0.2548, -0.8506, -0.9667],\n",
            "        [-0.4118,  0.0854,  0.1803, -0.1313, -0.8227,  0.0760, -0.8420, -0.6000],\n",
            "        [ 0.2941,  0.3568,  0.0000,  0.0000,  0.0000,  0.5589, -0.5730, -0.3667],\n",
            "        [-0.7647,  0.0653,  0.0492, -0.2929, -0.7187, -0.0909,  0.1289, -0.5667],\n",
            "        [-0.8824,  0.9698,  0.2459, -0.2727, -0.4113,  0.0879, -0.3194, -0.7333],\n",
            "        [-0.5294,  0.0955,  0.0492, -0.1111, -0.7660,  0.0373, -0.2938, -0.8333],\n",
            "        [-0.8824,  0.1156,  0.5410,  0.0000,  0.0000, -0.0224, -0.8403, -0.2000],\n",
            "        [-0.2941,  0.0452,  0.2131, -0.6364, -0.6312, -0.1088, -0.4500, -0.3333],\n",
            "        [-0.8824,  0.2663, -0.0820, -0.4141, -0.6407, -0.1446, -0.3826,  0.0000],\n",
            "        [ 0.0588,  0.5678,  0.4098,  0.0000,  0.0000, -0.2608, -0.8702,  0.0667],\n",
            "        [-0.0588,  0.8693,  0.4754, -0.2929, -0.4681,  0.0283, -0.7054, -0.4667]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.]])\n",
            "Epoch:13 | Inputs tensor([[ 0.5294,  0.2663,  0.4754,  0.0000,  0.0000,  0.2936, -0.5687, -0.3000],\n",
            "        [-0.8824,  0.0955, -0.3770, -0.6364, -0.7163, -0.3115, -0.7190, -0.8333],\n",
            "        [-0.2941,  0.4774,  0.3115,  0.0000,  0.0000, -0.1207, -0.9146, -0.0333],\n",
            "        [ 0.0000,  0.8090,  0.4754, -0.4747, -0.7872,  0.0879, -0.7985, -0.5333],\n",
            "        [-0.7647,  0.3065,  0.5738,  0.0000,  0.0000, -0.3264, -0.8377,  0.0000],\n",
            "        [-0.6471,  0.1156, -0.0820, -0.2121,  0.0000, -0.1028, -0.5909, -0.7000],\n",
            "        [-0.1765,  0.5276,  0.4426, -0.1111,  0.0000,  0.4903, -0.7788, -0.5000],\n",
            "        [ 0.0000,  0.0754, -0.0164, -0.4949,  0.0000, -0.2131, -0.9530, -0.9333],\n",
            "        [ 0.4118,  0.2161,  0.2787, -0.6566,  0.0000, -0.2101, -0.8454,  0.3667],\n",
            "        [-0.6471,  0.1558,  0.0820, -0.2121, -0.6690,  0.1356, -0.9385, -0.7667],\n",
            "        [-0.5294, -0.0452,  0.1475, -0.3535,  0.0000, -0.0432, -0.5440, -0.9000],\n",
            "        [-0.0588,  0.2563,  0.5738,  0.0000,  0.0000,  0.0000, -0.8685,  0.1000],\n",
            "        [ 0.0000,  0.3769, -0.3443, -0.2929, -0.6028,  0.2846,  0.8873, -0.6000],\n",
            "        [ 0.0588,  0.5276,  0.2787, -0.3131, -0.5957,  0.0194, -0.3040, -0.6000],\n",
            "        [ 0.0588,  0.4573,  0.3115, -0.0707, -0.6927,  0.1297, -0.5226, -0.3667],\n",
            "        [-0.6471,  0.7085,  0.0492, -0.2525, -0.4681,  0.0283, -0.7626, -0.7000],\n",
            "        [-0.6471, -0.1960,  0.3443, -0.3737, -0.8345,  0.0194,  0.0367, -0.8000],\n",
            "        [-0.2941, -0.0151, -0.0492, -0.3333, -0.5508,  0.0134, -0.6994, -0.2667],\n",
            "        [-0.0588,  0.2060,  0.4098,  0.0000,  0.0000, -0.1535, -0.8454, -0.9667],\n",
            "        [-0.4118,  0.5578,  0.3770, -0.1111,  0.2884,  0.1535, -0.5380, -0.5667],\n",
            "        [ 0.0000,  0.4171,  0.0000,  0.0000,  0.0000,  0.2638, -0.8915, -0.7333],\n",
            "        [-0.4118, -0.1156,  0.0820, -0.5758, -0.9456, -0.2727, -0.7746, -0.7000],\n",
            "        [ 0.0000,  0.0151,  0.0164,  0.0000,  0.0000, -0.3472, -0.7797, -0.8667],\n",
            "        [ 0.0000, -0.1357,  0.1148, -0.3535,  0.0000,  0.0671, -0.8634, -0.8667],\n",
            "        [-0.8824, -0.1156,  0.2787, -0.4141, -0.8203, -0.0462, -0.7549, -0.7333],\n",
            "        [-0.2941,  0.0251,  0.4754, -0.2121,  0.0000,  0.0641, -0.4910, -0.7667],\n",
            "        [-0.8824, -0.1457,  0.0820, -0.4141,  0.0000, -0.2072, -0.7669, -0.6667],\n",
            "        [ 0.0000,  0.2965,  0.3115,  0.0000,  0.0000, -0.0700, -0.4663, -0.7333],\n",
            "        [-0.5294, -0.0050,  0.1803, -0.6566,  0.0000, -0.2370, -0.8155, -0.7667],\n",
            "        [-0.5294,  0.2563,  0.3115,  0.0000,  0.0000, -0.0373, -0.6089, -0.8000],\n",
            "        [ 0.0000,  0.6181, -0.1803,  0.0000,  0.0000, -0.3472, -0.8497,  0.4667],\n",
            "        [-0.1765,  0.8492,  0.3770, -0.3333,  0.0000,  0.0581, -0.7635, -0.3333]]) | Labels tensor([[0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.]])\n",
            "Epoch:14 | Inputs tensor([[-0.1765,  0.1960,  0.0000,  0.0000,  0.0000, -0.2489, -0.8881, -0.4667],\n",
            "        [-0.0588, -0.0050,  0.3770,  0.0000,  0.0000,  0.0551, -0.7353, -0.0333],\n",
            "        [-0.7647, -0.0050, -0.1475, -0.6970, -0.7778, -0.2668, -0.5226,  0.0000],\n",
            "        [-0.4118,  0.3668,  0.3443,  0.0000,  0.0000,  0.0000, -0.5201,  0.6000],\n",
            "        [-0.7647,  0.2864,  0.0492, -0.1515,  0.0000,  0.1922, -0.1264, -0.9000],\n",
            "        [-0.8824, -0.0352,  0.0492, -0.4545, -0.7943, -0.0104, -0.8198,  0.0000],\n",
            "        [-0.2941,  0.2563,  0.2459,  0.0000,  0.0000,  0.0075, -0.9633,  0.1000],\n",
            "        [-0.8824,  0.4372,  0.2131, -0.5556, -0.8558, -0.2191, -0.8480,  0.0000],\n",
            "        [-0.8824,  0.6784,  0.2131, -0.6566, -0.6596, -0.3025, -0.6849, -0.6000],\n",
            "        [-0.8824,  0.0352,  0.3115, -0.7778, -0.8061, -0.4218, -0.6473, -0.9667],\n",
            "        [-0.8824, -0.0251,  0.0820, -0.6970, -0.6690, -0.3085, -0.6507, -0.9667],\n",
            "        [ 0.1765,  0.2261,  0.1148,  0.0000,  0.0000, -0.0700, -0.8463, -0.3333],\n",
            "        [-0.4118,  0.0000,  0.3115, -0.3535,  0.0000,  0.2221, -0.7711, -0.4667],\n",
            "        [-0.4118,  0.0352,  0.7705, -0.2525,  0.0000,  0.1684, -0.8061,  0.4667],\n",
            "        [-0.2941,  0.0251,  0.3443,  0.0000,  0.0000, -0.0820, -0.9129, -0.5000],\n",
            "        [-0.0588,  0.8191,  0.1148, -0.2727,  0.1702, -0.1028, -0.5414,  0.3000],\n",
            "        [-0.8824,  0.0352, -0.5082, -0.2323, -0.8038,  0.2906, -0.9103, -0.6000],\n",
            "        [-0.2941,  0.5176,  0.0164, -0.3737, -0.7163,  0.0581, -0.4757, -0.7667],\n",
            "        [ 0.6471,  0.0050,  0.2787, -0.4949, -0.5650,  0.0909, -0.7148, -0.1667],\n",
            "        [-0.8824,  0.9397, -0.1803, -0.6768, -0.1135, -0.2280, -0.5073, -0.9000],\n",
            "        [-0.5294,  0.8392,  0.0000,  0.0000,  0.0000, -0.1535, -0.8856, -0.5000],\n",
            "        [ 0.0000, -0.1558,  0.0492, -0.5556, -0.8440,  0.0671, -0.6012,  0.0000],\n",
            "        [-0.6471, -0.0352,  0.2787, -0.2121,  0.0000,  0.1118, -0.8634, -0.3667],\n",
            "        [-0.0588,  0.6784,  0.7377, -0.0707, -0.4539,  0.1207, -0.9257, -0.2667],\n",
            "        [-0.5294,  0.4673,  0.5082,  0.0000,  0.0000, -0.0700, -0.6063,  0.3333],\n",
            "        [ 0.0000,  0.0151,  0.2459,  0.0000,  0.0000,  0.0641, -0.8975, -0.8333],\n",
            "        [-0.8824, -0.0854, -0.1148, -0.4949, -0.7636, -0.2489, -0.8668, -0.9333],\n",
            "        [-0.8824, -0.2060,  0.2295, -0.3939,  0.0000, -0.0462, -0.7284, -0.9667],\n",
            "        [-0.4118,  0.0553,  0.1803, -0.4141, -0.2317,  0.0999, -0.9308, -0.7667],\n",
            "        [-0.6471,  0.1658,  0.2131, -0.6970, -0.7518, -0.2161, -0.9752, -0.9000],\n",
            "        [-0.4118, -0.0352,  0.2131, -0.6364, -0.8416,  0.0015, -0.2152, -0.2667],\n",
            "        [-0.0588, -0.1558,  0.2131, -0.3737,  0.0000,  0.1416, -0.6763, -0.4000]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:15 | Inputs tensor([[-0.8824,  0.0000,  0.2131, -0.5960, -0.9456, -0.1744, -0.8113,  0.0000],\n",
            "        [-0.6471,  0.2060,  0.1475, -0.3939, -0.6809,  0.2787, -0.6806, -0.7000],\n",
            "        [-0.7647, -0.1558, -0.1803, -0.5354, -0.8203, -0.0939, -0.2400,  0.0000],\n",
            "        [ 0.0000,  0.6281,  0.2459, -0.2727,  0.0000,  0.4784, -0.7558, -0.8333],\n",
            "        [ 0.0588,  0.3467,  0.2131, -0.3333, -0.8582, -0.2280, -0.6738,  1.0000],\n",
            "        [-0.6471,  0.2362,  0.6393, -0.2929, -0.4326,  0.7079, -0.3151, -0.9667],\n",
            "        [-0.8824,  0.1256,  0.3115, -0.0909, -0.6879,  0.0373, -0.8813, -0.9000],\n",
            "        [-0.4118, -0.1457,  0.2131, -0.5556,  0.0000, -0.1356, -0.0213, -0.6333],\n",
            "        [-0.8824,  0.1658,  0.1475, -0.4343,  0.0000, -0.1833, -0.8924,  0.0000],\n",
            "        [-0.7647,  0.7487,  0.4426, -0.2525, -0.7163,  0.3264, -0.5149, -0.9000],\n",
            "        [-0.5294,  0.7186,  0.1803,  0.0000,  0.0000,  0.2996, -0.6576, -0.8333],\n",
            "        [-0.4118,  0.1156,  0.1803, -0.4343,  0.0000, -0.2876, -0.7190, -0.8000],\n",
            "        [ 0.0588, -0.1055,  0.0164,  0.0000,  0.0000, -0.3294, -0.9453, -0.6000],\n",
            "        [ 0.0588,  0.2060,  0.1803, -0.5556, -0.8676, -0.3800, -0.4406, -0.1000],\n",
            "        [-0.8824,  0.2161,  0.2787, -0.2121, -0.8251,  0.1624, -0.8437, -0.7667],\n",
            "        [-0.7647,  0.1457,  0.1148, -0.5556,  0.0000, -0.1446, -0.9880, -0.8667],\n",
            "        [-0.5294,  0.1457,  0.0492,  0.0000,  0.0000, -0.1386, -0.9590, -0.9000],\n",
            "        [ 0.0000, -0.0151,  0.3443, -0.6970, -0.8014, -0.2489, -0.8113, -0.9667],\n",
            "        [ 0.0588,  0.3065,  0.1475,  0.0000,  0.0000,  0.0194, -0.5098, -0.2000],\n",
            "        [ 0.6471,  0.7588,  0.0164, -0.3939,  0.0000,  0.0015, -0.8856, -0.4333],\n",
            "        [-0.7647,  0.9799,  0.1475, -0.0909,  0.2837, -0.0909, -0.9317,  0.0667],\n",
            "        [-0.0588,  0.0553,  0.6393, -0.2727,  0.0000,  0.2906, -0.8625, -0.2000],\n",
            "        [-0.7647, -0.3166,  0.1475, -0.3535, -0.8440, -0.2548, -0.9069, -0.8667],\n",
            "        [ 0.0000, -0.0452,  0.0492, -0.2121, -0.7518,  0.3294, -0.7541, -0.9667],\n",
            "        [-0.4118,  0.5879,  0.3770, -0.1717, -0.5035,  0.1744, -0.7293, -0.7333],\n",
            "        [-0.5294,  0.4171,  0.2131,  0.0000,  0.0000, -0.1773, -0.8582, -0.3667],\n",
            "        [ 0.1765,  0.6281,  0.3770,  0.0000,  0.0000, -0.1744, -0.9112,  0.1000],\n",
            "        [-0.2941,  0.2965,  0.4754, -0.8586, -0.2293, -0.4158, -0.5696,  0.3000],\n",
            "        [-0.7647,  0.0553,  0.3115, -0.0909, -0.5485,  0.0045, -0.4594, -0.7333],\n",
            "        [ 0.5294,  0.0653,  0.1803,  0.0909,  0.0000,  0.0909, -0.9146, -0.2000],\n",
            "        [-0.2941,  0.4472,  0.1803, -0.4545, -0.4610,  0.0104, -0.8488, -0.3667],\n",
            "        [-0.5294,  0.1055,  0.0820,  0.0000,  0.0000, -0.0492, -0.6644, -0.7333]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:16 | Inputs tensor([[-0.8824,  0.3166,  0.0492, -0.7172, -0.0189, -0.2936, -0.7344,  0.0000],\n",
            "        [-0.7647, -0.1658,  0.0656, -0.4343, -0.8440,  0.0969, -0.5295, -0.9000],\n",
            "        [-0.7647,  0.4673,  0.2459, -0.2929, -0.5414,  0.1386, -0.7857, -0.7333],\n",
            "        [-0.5294,  0.1055,  0.2459, -0.5960, -0.7636, -0.1535, -0.9658, -0.8000],\n",
            "        [-0.5294, -0.1558,  0.4754, -0.5354, -0.8676,  0.1773, -0.9308, -0.8667],\n",
            "        [-0.5294,  0.4874, -0.0164, -0.4545, -0.2482, -0.0790, -0.9385, -0.7333],\n",
            "        [-0.8824,  0.2864,  0.6066, -0.1717, -0.8629, -0.0462,  0.0615, -0.6000],\n",
            "        [ 0.0000, -0.4271, -0.0164,  0.0000,  0.0000, -0.3532, -0.4389,  0.5333],\n",
            "        [-0.4118,  0.2261,  0.4098,  0.0000,  0.0000,  0.0343, -0.8190, -0.6000],\n",
            "        [-0.6471,  0.5879,  0.0492, -0.7374, -0.0851, -0.0700, -0.8147, -0.9000],\n",
            "        [-0.8824, -0.1960, -0.0984,  0.0000,  0.0000, -0.4307, -0.8463,  0.0000],\n",
            "        [ 0.4118, -0.1558,  0.1803, -0.3737,  0.0000, -0.1148, -0.8130, -0.1667],\n",
            "        [-0.1765,  0.0251,  0.2131, -0.1919, -0.7518,  0.1088, -0.8924, -0.2000],\n",
            "        [-0.0588,  0.1055,  0.2459,  0.0000,  0.0000, -0.1714, -0.8642,  0.2333],\n",
            "        [-0.6471,  0.5075,  0.2459,  0.0000,  0.0000, -0.3741, -0.8898, -0.4667],\n",
            "        [ 0.0000,  0.4673,  0.3443,  0.0000,  0.0000,  0.2072,  0.4543, -0.2333],\n",
            "        [-0.8824,  0.4472,  0.3443, -0.1919,  0.0000,  0.2310, -0.5482, -0.7667],\n",
            "        [-0.7647,  0.0854,  0.3115,  0.0000,  0.0000, -0.1952, -0.8454,  0.0333],\n",
            "        [ 0.0000,  0.1960,  0.0820, -0.4545,  0.0000,  0.1565, -0.8454, -0.9667],\n",
            "        [-0.7647, -0.0754,  0.0164, -0.4343,  0.0000, -0.0581, -0.9556, -0.9000],\n",
            "        [-0.8824, -0.1055,  0.2459, -0.3131, -0.9125, -0.0700, -0.9026, -0.9333],\n",
            "        [-0.8824, -0.0955,  0.0164, -0.6364, -0.8605, -0.2519,  0.0162, -0.8667],\n",
            "        [-0.4118, -0.0050,  0.2131, -0.4545,  0.0000, -0.1356, -0.8933, -0.6333],\n",
            "        [-0.2941,  0.3467,  0.3115, -0.2525, -0.1253,  0.3770, -0.8634, -0.1667],\n",
            "        [-0.6471, -0.2161, -0.1803, -0.3535, -0.7920, -0.0760, -0.8548, -0.8333],\n",
            "        [-0.0588,  0.7688,  0.4754, -0.3131, -0.2908,  0.0045, -0.6678,  0.2333],\n",
            "        [-0.7647, -0.4372, -0.0820, -0.4343, -0.8936, -0.2787, -0.7831, -0.9667],\n",
            "        [-0.8824, -0.0050, -0.0492, -0.7980,  0.0000, -0.2429, -0.5961,  0.0000],\n",
            "        [ 0.0588,  0.5477,  0.2787, -0.3939, -0.7636, -0.0790, -0.9266, -0.2000],\n",
            "        [-0.4118,  0.4472,  0.3443, -0.4747, -0.3262, -0.0462, -0.6806,  0.2333],\n",
            "        [-0.7647,  0.4673,  0.0000,  0.0000,  0.0000, -0.1803, -0.8617, -0.7667],\n",
            "        [-0.1765,  0.5980,  0.0820,  0.0000,  0.0000, -0.0939, -0.7395, -0.5000]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]])\n",
            "Epoch:17 | Inputs tensor([[ 0.0000,  0.0050,  0.1475, -0.4747, -0.8818, -0.0820, -0.5568,  0.0000],\n",
            "        [-0.5294,  0.5678,  0.2295,  0.0000,  0.0000,  0.4396, -0.8634, -0.6333],\n",
            "        [ 0.1765,  0.3970,  0.3115,  0.0000,  0.0000, -0.1922,  0.1640,  0.2000],\n",
            "        [ 0.0000,  0.7387,  0.2787, -0.3535, -0.3735,  0.3860, -0.0769,  0.2333],\n",
            "        [-0.8824, -0.0452, -0.0164, -0.6364, -0.8629, -0.2876, -0.8446, -0.9667],\n",
            "        [-0.2941,  0.1457,  0.4426,  0.0000,  0.0000, -0.1714, -0.8557,  0.5000],\n",
            "        [-0.8824,  0.3668,  0.2131,  0.0101, -0.5177,  0.1148, -0.7259, -0.9000],\n",
            "        [-0.5294,  0.1558,  0.1803,  0.0000,  0.0000, -0.1386, -0.7455, -0.1667],\n",
            "        [-0.7647, -0.0352,  0.1148, -0.7374, -0.8842, -0.3711, -0.5141, -0.8333],\n",
            "        [-0.4118,  0.0452,  0.2131,  0.0000,  0.0000, -0.1416, -0.9360, -0.1000],\n",
            "        [-0.0588, -0.1457, -0.0984, -0.5960,  0.0000, -0.2727, -0.9505, -0.3000],\n",
            "        [-0.7647,  0.2965,  0.2131, -0.4747, -0.5154, -0.0104, -0.5619, -0.8667],\n",
            "        [-0.8824,  0.2462, -0.0164, -0.3535,  0.0000,  0.0671, -0.6277,  0.0000],\n",
            "        [-0.2941,  0.9598,  0.1475,  0.0000,  0.0000, -0.0790, -0.7865, -0.6667],\n",
            "        [-0.8824, -0.0352,  1.0000,  0.0000,  0.0000, -0.3323, -0.8898, -0.8000],\n",
            "        [-0.4118,  0.3769,  0.7705,  0.0000,  0.0000,  0.4545, -0.8728, -0.4667],\n",
            "        [ 0.5294,  0.5377,  0.4426, -0.2525, -0.6690,  0.2101, -0.0640, -0.4000],\n",
            "        [-0.6471, -0.0050,  0.3115, -0.7778, -0.8487, -0.4247, -0.8241, -0.7000],\n",
            "        [-0.0588,  0.3367,  0.1803,  0.0000,  0.0000, -0.0194, -0.8360, -0.4000],\n",
            "        [-0.7647,  0.0553,  0.2295,  0.0000,  0.0000, -0.3055, -0.5884,  0.0667],\n",
            "        [-0.1765, -0.1658,  0.2787, -0.4747, -0.8322, -0.1267, -0.4116, -0.5000],\n",
            "        [-0.1765,  0.3367,  0.4426, -0.6970, -0.6336, -0.0343, -0.8429, -0.4667],\n",
            "        [-0.5294,  0.4573,  0.3443, -0.6364,  0.0000, -0.0313, -0.8659,  0.6333],\n",
            "        [-0.8824,  0.0050,  0.1803, -0.7576, -0.8345, -0.2459, -0.5047, -0.7667],\n",
            "        [-0.5294,  0.2362,  0.0164,  0.0000,  0.0000, -0.0462, -0.8736, -0.5333],\n",
            "        [-0.8824, -0.0251,  0.1148, -0.5758,  0.0000, -0.1893, -0.1315, -0.9667],\n",
            "        [-0.8824,  0.6482,  0.3443, -0.1313, -0.8416, -0.0224, -0.7754, -0.0333],\n",
            "        [-0.0588,  0.1859,  0.1803, -0.6162,  0.0000, -0.3115,  0.1939, -0.1667],\n",
            "        [-0.6471,  0.8794,  0.1475, -0.5556, -0.5272,  0.0849, -0.7182, -0.5000],\n",
            "        [ 0.0000, -0.0553,  0.0000,  0.0000,  0.0000,  0.0000, -0.8480, -0.8667],\n",
            "        [ 0.2941,  0.2060,  0.3115, -0.2525, -0.6454,  0.2608, -0.3962, -0.1000],\n",
            "        [ 0.0000,  0.3166,  0.0000,  0.0000,  0.0000,  0.2876, -0.8360, -0.8333]]) | Labels tensor([[1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.]])\n",
            "Epoch:18 | Inputs tensor([[-0.7647, -0.1156, -0.0492, -0.4747, -0.9622, -0.1535, -0.4125, -0.9667],\n",
            "        [-0.8824,  0.4975,  0.1148, -0.4141, -0.6998, -0.1267, -0.7686, -0.3000],\n",
            "        [-0.0588,  0.9497,  0.3115,  0.0000,  0.0000, -0.2221, -0.5961,  0.5333],\n",
            "        [ 0.0000,  0.3869,  0.0000,  0.0000,  0.0000,  0.0820, -0.2699, -0.8667],\n",
            "        [ 0.2941,  0.1156,  0.3770, -0.1919,  0.0000,  0.3949, -0.2767, -0.2000],\n",
            "        [ 0.0000,  0.8090,  0.0820, -0.2121,  0.0000,  0.2519,  0.5500, -0.8667],\n",
            "        [-0.5294,  0.1759,  0.0492, -0.4545, -0.7163, -0.0104, -0.8702, -0.9000],\n",
            "        [-0.7647,  0.1055,  0.2131, -0.4141, -0.7045, -0.0343, -0.4705, -0.8000],\n",
            "        [-0.8824,  0.1960, -0.1148, -0.7374, -0.8818, -0.3353, -0.8915, -0.9000],\n",
            "        [-0.2941,  0.0955, -0.0164, -0.4545,  0.0000, -0.2548, -0.8907, -0.8000],\n",
            "        [-0.7647,  0.1256,  0.0820, -0.5556,  0.0000, -0.2548, -0.8044, -0.9000],\n",
            "        [ 0.0000,  0.1759,  0.3115, -0.3737, -0.8747,  0.3472, -0.9906, -0.9000],\n",
            "        [-0.0588,  0.8392,  0.0492,  0.0000,  0.0000, -0.3055, -0.4927, -0.6333],\n",
            "        [-0.1765,  0.3367,  0.3770,  0.0000,  0.0000,  0.1982, -0.4722, -0.4667],\n",
            "        [-0.8824,  0.2261,  0.4754,  0.0303, -0.4799,  0.4814, -0.7891, -0.6667],\n",
            "        [-0.0588,  0.7990,  0.1803, -0.1515, -0.6927, -0.0253, -0.4526, -0.5000],\n",
            "        [ 0.0000,  0.3970,  0.0164, -0.6566, -0.5035, -0.3413, -0.8898,  0.0000],\n",
            "        [-0.8824,  0.3065, -0.0164, -0.5354, -0.5981, -0.1475, -0.4757,  0.0000],\n",
            "        [ 0.0000,  0.8995,  0.7049, -0.4949,  0.0000,  0.0224, -0.6951, -0.3333],\n",
            "        [-0.5294,  0.2563,  0.1475, -0.6364, -0.7116, -0.1386, -0.0897, -0.2000],\n",
            "        [-0.5294,  0.3266,  0.0000,  0.0000,  0.0000, -0.0194, -0.8087, -0.9333],\n",
            "        [-0.7647,  0.1256,  0.2295, -0.3535,  0.0000,  0.0641, -0.9402,  0.0000],\n",
            "        [-0.8824,  0.8191,  0.0492, -0.3939, -0.5745,  0.0164, -0.7865, -0.4333],\n",
            "        [-0.6471,  0.4271,  0.3115, -0.6970,  0.0000, -0.0343, -0.8958,  0.4000],\n",
            "        [-0.7647,  0.2965,  0.0000,  0.0000,  0.0000,  0.1475, -0.8070, -0.3333],\n",
            "        [-0.8824,  0.6884,  0.4426, -0.4141,  0.0000,  0.0432, -0.2938,  0.0333],\n",
            "        [-0.5294,  0.3668,  0.1475,  0.0000,  0.0000, -0.0700, -0.0572, -0.9667],\n",
            "        [-0.6471,  0.7186,  0.1803, -0.3333, -0.6809, -0.0075, -0.8967, -0.9000],\n",
            "        [ 0.4118,  0.5176,  0.1475, -0.1919, -0.3593,  0.2459, -0.4330, -0.4333],\n",
            "        [-0.8824,  0.6382,  0.1803,  0.0000,  0.0000,  0.1624, -0.0231, -0.6000],\n",
            "        [ 0.5294,  0.0452,  0.1803,  0.0000,  0.0000, -0.0700, -0.6695, -0.4333],\n",
            "        [ 0.0000,  0.2663,  0.4098, -0.4545, -0.7163, -0.1833, -0.6268,  0.0000]]) | Labels tensor([[1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.]])\n",
            "Epoch:19 | Inputs tensor([[-0.5294, -0.0050,  0.1148, -0.2323,  0.0000, -0.0224, -0.9428, -0.6000],\n",
            "        [ 0.0000,  0.3568,  0.1148, -0.1515, -0.4090,  0.2608, -0.7549, -0.9000],\n",
            "        [-0.8824,  0.0955, -0.0492, -0.6364, -0.7258, -0.1505, -0.8796, -0.9667],\n",
            "        [-0.8824,  0.4472,  0.3443, -0.0707, -0.5745,  0.3741, -0.7805, -0.1667],\n",
            "        [-0.8824,  0.1960,  0.4098, -0.2121, -0.4799,  0.3592, -0.3766, -0.7333],\n",
            "        [-0.1765,  0.0955,  0.3115, -0.3737,  0.0000,  0.0700, -0.1042, -0.2667],\n",
            "        [-0.6471,  0.7487, -0.0492, -0.5556, -0.5414, -0.0194, -0.5602, -0.5000],\n",
            "        [-0.7647,  0.0050,  0.1475,  0.0505, -0.8652,  0.2072, -0.4885, -0.8667],\n",
            "        [-0.4118,  0.0955,  0.2295, -0.4747,  0.0000,  0.0730, -0.6003,  0.3000],\n",
            "        [ 0.0000,  0.0955,  0.4426, -0.3939,  0.0000, -0.0313, -0.3365, -0.4333],\n",
            "        [-0.2941,  0.1759,  0.5738,  0.0000,  0.0000, -0.1446, -0.9325, -0.7000],\n",
            "        [-0.8824,  0.3970, -0.2459, -0.6162, -0.8038, -0.1446, -0.5081, -0.9667],\n",
            "        [ 0.0000,  0.1859,  0.3770, -0.0505, -0.4563,  0.3651, -0.5961, -0.6667],\n",
            "        [-0.6471,  0.1357, -0.1803, -0.7980, -0.7991, -0.1207, -0.5320, -0.8667],\n",
            "        [ 0.5294, -0.2362, -0.0164,  0.0000,  0.0000, -0.0224, -0.9129, -0.3333],\n",
            "        [-0.4118, -0.0050, -0.1148, -0.4343, -0.8038,  0.0134, -0.6405, -0.7000],\n",
            "        [-0.7647,  0.2864,  0.2787, -0.2525, -0.5697,  0.2906, -0.0213, -0.6667],\n",
            "        [-0.6471,  0.2864,  0.1803, -0.4949, -0.5508, -0.0343, -0.5978, -0.8000],\n",
            "        [-0.5294,  0.4673,  0.2787,  0.0000,  0.0000,  0.1475, -0.6225,  0.5333],\n",
            "        [-0.2941,  0.0754,  0.4426,  0.0000,  0.0000,  0.0969, -0.4458, -0.6667],\n",
            "        [-0.7647,  0.5779,  0.2131, -0.2929,  0.0402,  0.1744, -0.9522, -0.7000],\n",
            "        [-0.8824,  0.2663, -0.0164,  0.0000,  0.0000, -0.1028, -0.7686, -0.1333],\n",
            "        [ 0.1765,  0.0854,  0.0820,  0.0000,  0.0000, -0.0343, -0.8343, -0.3000],\n",
            "        [-0.6471,  0.1156,  0.0164,  0.0000,  0.0000, -0.3264, -0.9453,  0.0000],\n",
            "        [-0.5294,  0.2764,  0.4426, -0.7778, -0.6336,  0.0283, -0.5559, -0.7667],\n",
            "        [-0.8824,  0.3568, -0.1148,  0.0000,  0.0000, -0.2042, -0.4799,  0.3667],\n",
            "        [-0.6471, -0.3869,  0.3443, -0.4343,  0.0000,  0.0253, -0.8591, -0.1667],\n",
            "        [-0.7647,  0.2060,  0.2459, -0.2525, -0.7518,  0.1833, -0.8830, -0.7333],\n",
            "        [-0.7647,  0.0251,  0.4098, -0.2727, -0.7163,  0.3562, -0.9582, -0.9333],\n",
            "        [-0.2941,  0.1156,  0.0492, -0.2121,  0.0000,  0.0194, -0.8446, -0.9000],\n",
            "        [-0.8824,  0.4673, -0.0820,  0.0000,  0.0000, -0.1148, -0.5850, -0.7333],\n",
            "        [-0.8824,  0.0854, -0.0164, -0.0707, -0.5792,  0.0581, -0.7122, -0.9000]]) | Labels tensor([[1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:20 | Inputs tensor([[-0.5294,  0.2362,  0.3115, -0.6970, -0.5839, -0.0462, -0.6883, -0.5667],\n",
            "        [ 0.5294,  0.5879,  0.8689,  0.0000,  0.0000,  0.2608, -0.8471, -0.2333],\n",
            "        [ 0.0000,  0.4673,  0.1475,  0.0000,  0.0000,  0.1297, -0.7814, -0.7667],\n",
            "        [-0.2941,  0.6281,  0.0164,  0.0000,  0.0000, -0.2757, -0.9146, -0.0333],\n",
            "        [-0.1765,  0.3769,  0.4754, -0.1717,  0.0000, -0.0462, -0.7327, -0.4000],\n",
            "        [ 0.5294,  0.5276,  0.4754, -0.3333, -0.9314, -0.2012, -0.4424, -0.2667],\n",
            "        [-0.7647,  0.7588,  0.4426,  0.0000,  0.0000, -0.3174, -0.7882, -0.9667],\n",
            "        [-0.7647,  0.4271,  0.3443, -0.6364, -0.8487, -0.2638, -0.4167,  0.0000],\n",
            "        [ 0.0588,  0.2362,  0.1475, -0.1111, -0.7778, -0.0134, -0.7472, -0.3667],\n",
            "        [-0.5294, -0.1658,  0.4098, -0.6162,  0.0000, -0.1267, -0.7959, -0.5667],\n",
            "        [-0.5294, -0.0553,  0.0656, -0.5556,  0.0000, -0.2638, -0.9402,  0.0000],\n",
            "        [-0.4118,  0.6884,  0.0492,  0.0000,  0.0000, -0.0194, -0.9513, -0.3333],\n",
            "        [ 0.0000, -0.2563, -0.1475, -0.7980, -0.9149, -0.1714, -0.8369, -0.9667],\n",
            "        [-0.6471,  0.2261,  0.2787,  0.0000,  0.0000, -0.3145, -0.8497, -0.3667],\n",
            "        [-0.8824,  0.0754,  0.1803, -0.3939, -0.8061, -0.0820, -0.3655, -0.9000],\n",
            "        [-0.8824,  0.1960, -0.2787, -0.0505, -0.8511,  0.0581, -0.8275, -0.8667],\n",
            "        [-0.7647,  0.1156, -0.0164,  0.0000,  0.0000, -0.2191, -0.7737, -0.9333],\n",
            "        [-0.7647,  0.0653, -0.0820, -0.4545, -0.6099, -0.1356, -0.7028, -0.9667],\n",
            "        [ 0.1765,  0.6181,  0.1148, -0.5354, -0.6879, -0.2399, -0.7882, -0.1333],\n",
            "        [-0.7647,  0.0955,  0.5082,  0.0000,  0.0000,  0.2727, -0.3450,  0.1000],\n",
            "        [-0.1765,  0.0653,  0.5082, -0.6364,  0.0000, -0.3234, -0.8659, -0.1000],\n",
            "        [-0.8824,  0.2462,  0.2131, -0.2727,  0.0000, -0.1714, -0.9812, -0.7000],\n",
            "        [-0.4118,  0.4774,  0.2787,  0.0000,  0.0000,  0.0045, -0.8804,  0.4667],\n",
            "        [-0.7647, -0.0653,  0.0492, -0.3535, -0.6217,  0.1326, -0.4910, -0.9333],\n",
            "        [-0.8824, -0.2864,  0.0164,  0.0000,  0.0000, -0.3502, -0.7114, -0.8333],\n",
            "        [-0.4118,  0.1558,  0.2459,  0.0000,  0.0000, -0.0700, -0.7737, -0.2333],\n",
            "        [ 0.0000,  0.2864,  0.1148, -0.6162, -0.5745, -0.0909,  0.1213, -0.8667],\n",
            "        [-0.8824,  0.2563, -0.1803, -0.1919, -0.6052, -0.0075, -0.2451, -0.7667],\n",
            "        [-0.2941,  0.9497,  0.2787,  0.0000,  0.0000, -0.2996, -0.9564,  0.2667],\n",
            "        [-0.8824,  0.0050,  0.0820, -0.6970, -0.8676, -0.2966, -0.4979, -0.8333],\n",
            "        [-0.8824, -0.1256, -0.0164, -0.2525, -0.8227,  0.1088, -0.6319, -0.9667],\n",
            "        [ 0.0000, -0.0653, -0.0164, -0.4949, -0.7825, -0.1446, -0.6123, -0.9667]]) | Labels tensor([[1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:21 | Inputs tensor([[-0.1765,  0.4774,  0.2459,  0.0000,  0.0000,  0.1744, -0.8471, -0.2667],\n",
            "        [-0.0588,  0.5578,  0.0164, -0.4747,  0.1702,  0.0134, -0.6029, -0.1667],\n",
            "        [-0.7647,  0.0050,  0.1148, -0.4949, -0.8322,  0.1475, -0.7899, -0.8333],\n",
            "        [ 0.0000,  0.0754,  0.2459,  0.0000,  0.0000,  0.3502, -0.4808, -0.9000],\n",
            "        [-0.6471,  0.0251,  0.2131,  0.0000,  0.0000, -0.1207, -0.9633, -0.6333],\n",
            "        [-0.7647,  0.2161,  0.1475, -0.3535, -0.7754,  0.1654, -0.3100, -0.9333],\n",
            "        [-0.8824, -0.1658,  0.1148,  0.0000,  0.0000, -0.4575, -0.5337, -0.8000],\n",
            "        [-0.5294,  0.3266,  0.4098, -0.3737,  0.0000, -0.1654, -0.7088,  0.4000],\n",
            "        [ 0.0588,  0.1960,  0.3115, -0.2929,  0.0000, -0.1356, -0.8420, -0.7333],\n",
            "        [-0.8824, -0.0854,  0.0492, -0.5152,  0.0000, -0.1297, -0.9026,  0.0000],\n",
            "        [ 0.0588,  0.2261, -0.0820,  0.0000,  0.0000, -0.0075, -0.1153, -0.6000],\n",
            "        [ 0.0000,  0.5176,  0.4754, -0.0707,  0.0000,  0.2548, -0.7498,  0.0000],\n",
            "        [ 0.1765,  0.1558,  0.6066,  0.0000,  0.0000, -0.2846, -0.1939, -0.5667],\n",
            "        [ 0.0588,  0.1256,  0.3443, -0.3535, -0.5863,  0.0194, -0.8446, -0.5000],\n",
            "        [-0.8824, -0.1859,  0.1803, -0.6364, -0.9054, -0.2072, -0.8249, -0.9000],\n",
            "        [-0.6471,  0.3065,  0.0492,  0.0000,  0.0000, -0.3115, -0.7985, -0.9667],\n",
            "        [-0.7647, -0.1256,  0.0000, -0.5354,  0.0000, -0.1386, -0.4065, -0.8667],\n",
            "        [ 0.0000,  0.3568,  0.5410, -0.0707, -0.6572,  0.2101, -0.8241, -0.8333],\n",
            "        [-0.6471,  0.2563, -0.0492,  0.0000,  0.0000, -0.0581, -0.9377, -0.9000],\n",
            "        [ 0.2941,  0.3869,  0.2459,  0.0000,  0.0000, -0.0104, -0.7079, -0.5333],\n",
            "        [-0.7647,  0.1256,  0.2787,  0.0101, -0.6690,  0.1744, -0.9172, -0.9000],\n",
            "        [-0.6471,  0.1156,  0.4754, -0.7576, -0.8156, -0.1535, -0.6439, -0.7333],\n",
            "        [ 0.1765,  0.3367,  0.1148,  0.0000,  0.0000, -0.1952, -0.8574, -0.5000],\n",
            "        [-0.2941, -0.1960,  0.3115, -0.2727,  0.0000,  0.1863, -0.9155, -0.7667],\n",
            "        [-0.2941,  0.9095,  0.5082,  0.0000,  0.0000,  0.0581, -0.8292,  0.5000],\n",
            "        [-0.0588,  0.2060,  0.2787,  0.0000,  0.0000, -0.2548, -0.7173,  0.4333],\n",
            "        [-0.0588,  0.2462,  0.2459, -0.5152,  0.4184, -0.1446, -0.4799,  0.0333],\n",
            "        [-0.6471,  0.0251, -0.2787, -0.5960, -0.7778, -0.0820, -0.7250, -0.8333],\n",
            "        [-0.1765,  0.4271, -0.0164, -0.3333, -0.5508, -0.1416, -0.4799,  0.3333],\n",
            "        [-0.1765,  0.5980,  0.0492,  0.0000,  0.0000, -0.1833, -0.8155, -0.3667],\n",
            "        [-0.5294,  0.5176,  0.4754, -0.2323,  0.0000, -0.1148, -0.8155, -0.5000],\n",
            "        [-0.8824,  0.3367,  0.6721, -0.4343, -0.6690, -0.0224, -0.8668, -0.2000]]) | Labels tensor([[0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]])\n",
            "Epoch:22 | Inputs tensor([[ 0.0000,  0.6583,  0.4754, -0.3333,  0.6076,  0.5589, -0.7020, -0.9333],\n",
            "        [-0.5294,  0.1055,  0.5082,  0.0000,  0.0000,  0.1207, -0.9035, -0.7000],\n",
            "        [-0.8824, -0.0955,  0.1148, -0.8384,  0.0000, -0.2697, -0.0948, -0.5000],\n",
            "        [-0.7647, -0.0553,  0.2459, -0.6364, -0.8440, -0.0581, -0.5124, -0.9333],\n",
            "        [ 0.0588,  0.4573,  0.4426, -0.3131, -0.6099, -0.0969, -0.4082,  0.0667],\n",
            "        [-0.7647, -0.0754,  0.2459, -0.5960,  0.0000, -0.2787,  0.3834, -0.7667],\n",
            "        [ 0.0000,  0.0452,  0.0492, -0.5354, -0.7258, -0.1714, -0.6789, -0.9333],\n",
            "        [-0.0588,  0.9799,  0.2131,  0.0000,  0.0000, -0.2280, -0.0495, -0.4000],\n",
            "        [-0.5294,  0.5477,  0.0164, -0.3737, -0.3286, -0.0224, -0.8642, -0.9333],\n",
            "        [-0.7647, -0.1658,  0.0820, -0.5354, -0.8818, -0.0402, -0.6422, -0.9667],\n",
            "        [-0.7647, -0.0955, -0.0164,  0.0000,  0.0000, -0.2996, -0.9035, -0.8667],\n",
            "        [-0.8824,  0.1357,  0.0492, -0.2929,  0.0000,  0.0015, -0.6029,  0.0000],\n",
            "        [-0.7647,  0.2362, -0.2131, -0.3535, -0.6099,  0.2548, -0.6225, -0.8333],\n",
            "        [-0.4118,  0.3065,  0.3443,  0.0000,  0.0000,  0.1654, -0.2502, -0.4667],\n",
            "        [-0.7647, -0.1055,  0.4754, -0.3939,  0.0000, -0.0015, -0.8173, -0.3000],\n",
            "        [-0.6471,  0.6382,  0.1475, -0.6364, -0.7518, -0.0581, -0.8377, -0.7667],\n",
            "        [-0.2941, -0.1960,  0.0820, -0.3939,  0.0000, -0.2191, -0.7993, -0.3333],\n",
            "        [-0.4118,  0.3266,  0.3115,  0.0000,  0.0000, -0.2012, -0.9078,  0.6000],\n",
            "        [-0.7647,  0.4472, -0.0492, -0.3333, -0.6809, -0.0581, -0.7062, -0.8667],\n",
            "        [-0.4118,  0.1055,  0.1148,  0.0000,  0.0000, -0.2250, -0.8173, -0.7000],\n",
            "        [-0.2941,  0.2362,  0.1803, -0.0909, -0.4563,  0.0015, -0.4406, -0.5667],\n",
            "        [ 0.1765,  0.1558,  0.0000,  0.0000,  0.0000,  0.0000, -0.8437, -0.7000],\n",
            "        [-0.0588, -0.0854,  0.3443,  0.0000,  0.0000,  0.0611, -0.5653,  0.5667],\n",
            "        [-0.4118,  0.2462,  0.2131,  0.0000,  0.0000,  0.0134, -0.8787, -0.4333],\n",
            "        [-0.6471,  0.0653,  0.1803,  0.0000,  0.0000, -0.2310, -0.8898, -0.8000],\n",
            "        [-0.6471,  0.0754,  0.0164, -0.7374, -0.8865, -0.3174, -0.4876, -0.9333],\n",
            "        [-0.6471,  0.1256,  0.2131, -0.3939,  0.0000, -0.0581, -0.8984, -0.8667],\n",
            "        [ 0.0000,  0.1759,  0.0000,  0.0000,  0.0000,  0.0075, -0.2707, -0.2333],\n",
            "        [-0.8824, -0.1256,  0.2787, -0.4545, -0.9244,  0.0313, -0.9804, -0.9667],\n",
            "        [-0.8824,  0.0955, -0.0820, -0.5758, -0.6809, -0.2489, -0.3553, -0.9333],\n",
            "        [-0.4118,  0.3970,  0.3115, -0.2929, -0.6217, -0.0581, -0.7583, -0.8667],\n",
            "        [-0.8824, -0.0955,  0.0164, -0.7576, -0.8983, -0.1893, -0.5713, -0.9000]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])\n",
            "Epoch:23 | Inputs tensor([[-0.4118,  0.1457,  0.2131,  0.0000,  0.0000, -0.2578, -0.4313,  0.2000],\n",
            "        [ 0.0588,  0.6482,  0.2787,  0.0000,  0.0000, -0.0224, -0.9402, -0.2000],\n",
            "        [-0.2941, -0.0854,  0.0000,  0.0000,  0.0000, -0.1118, -0.6388, -0.6667],\n",
            "        [-0.8824,  0.0553, -0.0492,  0.0000,  0.0000, -0.2757, -0.9069,  0.0000],\n",
            "        [-0.7647, -0.0955,  0.1475, -0.6566,  0.0000, -0.1863, -0.9940, -0.9667],\n",
            "        [-0.6471,  0.9196,  0.1148, -0.6970, -0.6927, -0.0790, -0.8113, -0.5667],\n",
            "        [-0.8824,  0.1558,  0.1475, -0.3939, -0.7731,  0.0313, -0.6149, -0.6333],\n",
            "        [ 0.0000,  0.3769,  0.1475, -0.2323,  0.0000, -0.0104, -0.9214, -0.9667],\n",
            "        [ 0.4118,  0.4070,  0.3443, -0.1313, -0.2317,  0.1684, -0.6157,  0.2333],\n",
            "        [-0.6471,  0.0854,  0.0164, -0.5152,  0.0000, -0.2250, -0.8762, -0.8667],\n",
            "        [ 0.0000,  0.3869, -0.0164, -0.2929, -0.6052,  0.0313, -0.6106,  0.0000],\n",
            "        [-0.2941,  0.0553,  0.3115, -0.4343,  0.0000, -0.0313, -0.3168, -0.8333],\n",
            "        [-0.8824,  0.0050,  0.0820, -0.4141, -0.5366, -0.0462, -0.6874, -0.3000],\n",
            "        [-0.0588,  0.9698,  0.2459, -0.4141, -0.3381,  0.1177, -0.5500,  0.2000],\n",
            "        [ 0.1765,  0.0151,  0.2459, -0.0303, -0.5745, -0.0194, -0.9206,  0.4000],\n",
            "        [ 0.0588,  0.6482,  0.3770, -0.5758,  0.0000, -0.0820, -0.3570, -0.6333],\n",
            "        [-0.7647,  0.2261, -0.1475, -0.1313, -0.6265,  0.0790, -0.3698, -0.7667],\n",
            "        [-0.4118,  0.5879,  0.1475,  0.0000,  0.0000, -0.1118, -0.8898,  0.4000],\n",
            "        [ 0.0000,  0.1457,  0.3115, -0.3131, -0.3262,  0.3174, -0.9240, -0.8000],\n",
            "        [-0.1765,  0.6080, -0.1148, -0.3535, -0.5863, -0.0909, -0.5645, -0.4000],\n",
            "        [-0.7647,  0.0854, -0.1475, -0.4747, -0.8511, -0.0313, -0.7950, -0.9667],\n",
            "        [-0.8824,  0.4774,  0.5410, -0.1717,  0.0000,  0.4694, -0.7609, -0.8000],\n",
            "        [-0.5294,  0.7387,  0.1475, -0.7172, -0.6028, -0.1148, -0.7583, -0.6000]]) | Labels tensor([[1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:0 | Inputs tensor([[ 0.1765, -0.3166,  0.7377, -0.5354, -0.8842,  0.0581, -0.8232, -0.1333],\n",
            "        [-0.8824, -0.2864, -0.2131, -0.6364, -0.8203, -0.3920, -0.7908, -0.9667],\n",
            "        [ 0.0588,  0.6482,  0.2787,  0.0000,  0.0000, -0.0224, -0.9402, -0.2000],\n",
            "        [-0.0588,  0.5477,  0.2787, -0.3535,  0.0000, -0.0343, -0.6883, -0.2000],\n",
            "        [-0.7647,  0.5779,  0.2131, -0.2929,  0.0402,  0.1744, -0.9522, -0.7000],\n",
            "        [ 0.0000,  0.4673,  0.3443,  0.0000,  0.0000,  0.2072,  0.4543, -0.2333],\n",
            "        [-0.1765,  0.1457,  0.2459, -0.6566, -0.7400, -0.2906, -0.6687, -0.6667],\n",
            "        [ 0.0000,  0.3869, -0.0164, -0.2929, -0.6052,  0.0313, -0.6106,  0.0000],\n",
            "        [-0.7647, -0.2563,  0.0000,  0.0000,  0.0000,  0.0000, -0.9795, -0.9667],\n",
            "        [-0.8824, -0.0854, -0.1148, -0.4949, -0.7636, -0.2489, -0.8668, -0.9333],\n",
            "        [-0.6471,  0.2864,  0.1803, -0.4949, -0.5508, -0.0343, -0.5978, -0.8000],\n",
            "        [-0.4118,  0.2864,  0.3115,  0.0000,  0.0000,  0.0313, -0.9436, -0.2000],\n",
            "        [-0.4118, -0.2161, -0.2131,  0.0000,  0.0000,  0.0045, -0.5081, -0.8667],\n",
            "        [-0.8824,  0.1960,  0.4426, -0.1717, -0.5981,  0.3502, -0.6336, -0.8333],\n",
            "        [-0.8824,  0.4070,  0.2131, -0.4747, -0.5745, -0.2817, -0.3595, -0.9333],\n",
            "        [-0.7647, -0.1256, -0.0492, -0.6768, -0.8771, -0.0253, -0.9249, -0.8667],\n",
            "        [-0.0588,  0.9799,  0.2131,  0.0000,  0.0000, -0.2280, -0.0495, -0.4000],\n",
            "        [-0.8824, -0.0251,  0.1475, -0.6970,  0.0000, -0.4575, -0.9411,  0.0000],\n",
            "        [-0.0588,  0.8392,  0.0492,  0.0000,  0.0000, -0.3055, -0.4927, -0.6333],\n",
            "        [ 0.0000, -0.2161,  0.4426, -0.4141, -0.9054,  0.0999, -0.6960,  0.0000],\n",
            "        [-0.6471, -0.2161, -0.1803, -0.3535, -0.7920, -0.0760, -0.8548, -0.8333],\n",
            "        [-0.4118,  0.0955,  0.0164, -0.1717, -0.6950,  0.0671, -0.6277, -0.8667],\n",
            "        [-0.2941,  0.5477,  0.2787, -0.1717, -0.6690,  0.3741, -0.5790, -0.8000],\n",
            "        [-0.0588,  0.8693,  0.4754, -0.2929, -0.4681,  0.0283, -0.7054, -0.4667],\n",
            "        [-0.8824, -0.1055, -0.6066, -0.6162, -0.9409, -0.1714, -0.5892,  0.0000],\n",
            "        [ 0.0588,  0.8492,  0.3934, -0.6970,  0.0000, -0.1058, -0.0307, -0.0667],\n",
            "        [-0.2941, -0.0754,  0.0164, -0.3535, -0.7021, -0.0462, -0.9940, -0.1667],\n",
            "        [ 0.0000,  0.2764,  0.3115, -0.2525, -0.5035,  0.0820, -0.3800, -0.9333],\n",
            "        [ 0.0000,  0.1960,  0.0492, -0.6364, -0.7825,  0.0402, -0.4475, -0.9333],\n",
            "        [ 0.0000,  0.3568,  0.5410, -0.0707, -0.6572,  0.2101, -0.8241, -0.8333],\n",
            "        [ 0.0000,  0.3166,  0.0000,  0.0000,  0.0000,  0.2876, -0.8360, -0.8333],\n",
            "        [-0.7647,  0.4673,  0.2459, -0.2929, -0.5414,  0.1386, -0.7857, -0.7333]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])\n",
            "Epoch:1 | Inputs tensor([[-0.7647,  0.0151, -0.0492, -0.2929, -0.7872, -0.3502, -0.9342, -0.9667],\n",
            "        [-0.6471,  0.2563, -0.0492,  0.0000,  0.0000, -0.0581, -0.9377, -0.9000],\n",
            "        [ 0.0000,  0.2462, -0.0820, -0.7374, -0.7518, -0.3502, -0.6806,  0.0000],\n",
            "        [-0.2941,  0.5477,  0.2131, -0.3535, -0.5437, -0.1267, -0.3501, -0.4000],\n",
            "        [-0.0588,  0.4372,  0.0820,  0.0000,  0.0000,  0.0402, -0.9564, -0.3333],\n",
            "        [-0.7647, -0.1457,  0.0656,  0.0000,  0.0000,  0.1803, -0.2724, -0.8000],\n",
            "        [-0.5294, -0.0050,  0.1803, -0.6566,  0.0000, -0.2370, -0.8155, -0.7667],\n",
            "        [-0.6471,  0.0754,  0.0164, -0.7374, -0.8865, -0.3174, -0.4876, -0.9333],\n",
            "        [-0.0588,  0.8191,  0.1148, -0.2727,  0.1702, -0.1028, -0.5414,  0.3000],\n",
            "        [-0.8824,  0.1256,  0.3115, -0.0909, -0.6879,  0.0373, -0.8813, -0.9000],\n",
            "        [-0.7647, -0.0955, -0.0164,  0.0000,  0.0000, -0.2996, -0.9035, -0.8667],\n",
            "        [-0.7647, -0.0754,  0.0164, -0.4343,  0.0000, -0.0581, -0.9556, -0.9000],\n",
            "        [-0.1765,  0.4774,  0.2459,  0.0000,  0.0000,  0.1744, -0.8471, -0.2667],\n",
            "        [-0.6471,  0.2864,  0.2787,  0.0000,  0.0000, -0.3711, -0.8377,  0.1333],\n",
            "        [-0.8824,  0.6382,  0.1803,  0.0000,  0.0000,  0.1624, -0.0231, -0.6000],\n",
            "        [ 0.0000,  0.0955,  0.4426, -0.3939,  0.0000, -0.0313, -0.3365, -0.4333],\n",
            "        [-0.8824,  0.2563,  0.1475, -0.5152, -0.7400, -0.2757, -0.8779, -0.8667],\n",
            "        [-0.6471,  0.2261,  0.2787,  0.0000,  0.0000, -0.3145, -0.8497, -0.3667],\n",
            "        [ 0.1765,  0.1156,  0.1475, -0.4545,  0.0000, -0.1803, -0.9462, -0.3667],\n",
            "        [ 0.0000, -0.1558,  0.0492, -0.5556, -0.8440,  0.0671, -0.6012,  0.0000],\n",
            "        [-0.7647, -0.2864,  0.1475, -0.4545,  0.0000, -0.1654, -0.5662, -0.9667],\n",
            "        [ 0.0588, -0.2764,  0.2787, -0.4949,  0.0000, -0.0581, -0.8275, -0.4333],\n",
            "        [-0.8824,  0.5377,  0.3443, -0.1515,  0.1466,  0.2101, -0.4799, -0.9333],\n",
            "        [-0.7647, -0.1658,  0.0656, -0.4343, -0.8440,  0.0969, -0.5295, -0.9000],\n",
            "        [-0.4118,  0.4372,  0.2787,  0.0000,  0.0000,  0.3413, -0.9044, -0.1333],\n",
            "        [ 0.0588,  0.2462,  0.1475, -0.3333, -0.0496,  0.0551, -0.8258, -0.5667],\n",
            "        [ 0.0000,  0.2663,  0.3770, -0.4141, -0.4917, -0.0849, -0.6225, -0.9000],\n",
            "        [-0.7647, -0.0955,  0.1475, -0.6566,  0.0000, -0.1863, -0.9940, -0.9667],\n",
            "        [-0.7647,  0.0050,  0.0492, -0.5354,  0.0000, -0.1148, -0.7523,  0.0000],\n",
            "        [ 0.0000,  0.3769,  0.1148, -0.7172, -0.6501, -0.2608, -0.9445,  0.0000],\n",
            "        [ 0.0000, -0.0854,  0.1148, -0.3535, -0.5035,  0.1893, -0.7412, -0.8667],\n",
            "        [-0.4118,  0.1558,  0.2459,  0.0000,  0.0000, -0.0700, -0.7737, -0.2333]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]])\n",
            "Epoch:2 | Inputs tensor([[-0.4118,  0.2161,  0.1803, -0.5354, -0.7352, -0.2191, -0.8574, -0.7000],\n",
            "        [-0.5294,  0.5477,  0.1803, -0.4141, -0.7021, -0.0671, -0.7780, -0.4667],\n",
            "        [ 0.5294, -0.2362, -0.0164,  0.0000,  0.0000, -0.0224, -0.9129, -0.3333],\n",
            "        [-0.8824,  0.2462, -0.0164, -0.3535,  0.0000,  0.0671, -0.6277,  0.0000],\n",
            "        [-0.1765,  0.8794,  0.1148, -0.2121, -0.2813,  0.1237, -0.8497, -0.3333],\n",
            "        [-0.6471, -0.1558,  0.1148, -0.3939, -0.7494, -0.0492, -0.5619, -0.8667],\n",
            "        [-0.7647,  0.0854,  0.0164, -0.7980, -0.3428, -0.2459, -0.3143, -0.9667],\n",
            "        [ 0.5294,  0.2663,  0.4754,  0.0000,  0.0000,  0.2936, -0.5687, -0.3000],\n",
            "        [-0.8824,  0.3166,  0.0492, -0.7172, -0.0189, -0.2936, -0.7344,  0.0000],\n",
            "        [-0.2941,  0.0352,  0.0820,  0.0000,  0.0000, -0.2757, -0.8540, -0.7333],\n",
            "        [ 0.0000, -0.0653, -0.0164,  0.0000,  0.0000,  0.0522, -0.8420, -0.8667],\n",
            "        [-0.8824,  0.1558,  0.1475, -0.3939, -0.7731,  0.0313, -0.6149, -0.6333],\n",
            "        [-0.4118,  0.1759,  0.4098, -0.3939, -0.7518,  0.1654, -0.8523, -0.3000],\n",
            "        [-0.1765, -0.0553,  0.0492, -0.4949, -0.8132, -0.0075, -0.4364, -0.3333],\n",
            "        [ 0.0000, -0.0553,  0.1475, -0.4545, -0.7281,  0.2966, -0.7703,  0.0000],\n",
            "        [ 0.0588,  0.1256,  0.3443, -0.5152,  0.0000, -0.1595,  0.0282, -0.0333],\n",
            "        [-0.8824, -0.1859,  0.1803, -0.6364, -0.9054, -0.2072, -0.8249, -0.9000],\n",
            "        [-0.8824,  0.2462,  0.2131, -0.2727,  0.0000, -0.1714, -0.9812, -0.7000],\n",
            "        [-0.8824,  0.4372,  0.2131, -0.5556, -0.8558, -0.2191, -0.8480,  0.0000],\n",
            "        [-0.6471,  0.5075,  0.2459,  0.0000,  0.0000, -0.3741, -0.8898, -0.4667],\n",
            "        [ 0.0000,  0.0553,  0.0492, -0.1717, -0.6643,  0.2370, -0.9189, -0.9667],\n",
            "        [-0.8824, -0.0452,  0.3443, -0.4949, -0.5745,  0.0432, -0.8676, -0.2667],\n",
            "        [ 0.0000,  0.2563,  0.1148,  0.0000,  0.0000, -0.2638, -0.8907,  0.0000],\n",
            "        [-0.8824, -0.1156, -0.5082, -0.1515, -0.7660,  0.6393, -0.6430, -0.8333],\n",
            "        [-0.8824,  0.4372,  0.4098, -0.3939, -0.2199, -0.1028, -0.3049, -0.9333],\n",
            "        [-0.8824,  0.0050,  0.0820, -0.4141, -0.5366, -0.0462, -0.6874, -0.3000],\n",
            "        [-0.7647, -0.4372, -0.0820, -0.4343, -0.8936, -0.2787, -0.7831, -0.9667],\n",
            "        [-0.8824,  0.0653,  0.1475, -0.4343, -0.6809,  0.0194, -0.9453, -0.9667],\n",
            "        [ 0.5294,  0.0452,  0.1803,  0.0000,  0.0000, -0.0700, -0.6695, -0.4333],\n",
            "        [-0.4118,  0.0553,  0.1803, -0.4141, -0.2317,  0.0999, -0.9308, -0.7667],\n",
            "        [-0.8824, -0.0352,  0.0492, -0.4545, -0.7943, -0.0104, -0.8198,  0.0000],\n",
            "        [-0.6471, -0.2563,  0.1148, -0.4343, -0.8936, -0.1148, -0.8164, -0.9333]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:3 | Inputs tensor([[ 0.4118,  0.0653,  0.3115,  0.0000,  0.0000, -0.2966, -0.9496, -0.2333],\n",
            "        [ 0.1765, -0.0553,  0.1803, -0.6364,  0.0000, -0.3115, -0.5585,  0.1667],\n",
            "        [-0.5294,  0.2764,  0.4426, -0.7778, -0.6336,  0.0283, -0.5559, -0.7667],\n",
            "        [-0.5294,  0.4874, -0.0164, -0.4545, -0.2482, -0.0790, -0.9385, -0.7333],\n",
            "        [-0.7647,  0.1558,  0.0492, -0.5556,  0.0000, -0.0820, -0.7071,  0.0000],\n",
            "        [-0.8824,  0.6784,  0.2131, -0.6566, -0.6596, -0.3025, -0.6849, -0.6000],\n",
            "        [ 0.1765,  0.6181,  0.1148, -0.5354, -0.6879, -0.2399, -0.7882, -0.1333],\n",
            "        [ 0.2941,  0.2060,  0.3115, -0.2525, -0.6454,  0.2608, -0.3962, -0.1000],\n",
            "        [-0.7647,  0.0854,  0.0164, -0.3535, -0.8676, -0.2489, -0.9573,  0.0000],\n",
            "        [-0.2941,  0.9598,  0.1475,  0.0000,  0.0000, -0.0790, -0.7865, -0.6667],\n",
            "        [ 0.0588, -0.0854,  0.1148,  0.0000,  0.0000, -0.2787, -0.8958,  0.2333],\n",
            "        [ 0.5294,  0.4573,  0.3443, -0.6162, -0.7400, -0.3383, -0.8574,  0.2000],\n",
            "        [-0.2941,  0.4472,  0.1803, -0.4545, -0.4610,  0.0104, -0.8488, -0.3667],\n",
            "        [ 0.1765,  0.0151,  0.2459, -0.0303, -0.5745, -0.0194, -0.9206,  0.4000],\n",
            "        [-0.8824, -0.1055,  0.0820, -0.5354, -0.7778, -0.1624, -0.9240,  0.0000],\n",
            "        [-0.7647, -0.0452, -0.1148, -0.7172, -0.7920, -0.2221, -0.4278, -0.9667],\n",
            "        [-0.8824,  0.2864,  0.3443, -0.6566, -0.5674, -0.1803, -0.9684, -0.9667],\n",
            "        [-0.0588,  0.2060,  0.4098,  0.0000,  0.0000, -0.1535, -0.8454, -0.9667],\n",
            "        [ 0.0000,  0.3970,  0.0164, -0.6566, -0.5035, -0.3413, -0.8898,  0.0000],\n",
            "        [-0.1765,  0.3769,  0.4754, -0.1717,  0.0000, -0.0462, -0.7327, -0.4000],\n",
            "        [-0.8824,  0.0251,  0.2131,  0.0000,  0.0000,  0.1773, -0.8164, -0.3000],\n",
            "        [-0.7647, -0.0955,  0.3115, -0.7172, -0.8700, -0.2727, -0.8540, -0.9000],\n",
            "        [-0.7647, -0.0854,  0.0164,  0.0000,  0.0000, -0.1863, -0.6183, -0.9667],\n",
            "        [-0.8824,  0.5779,  0.1803, -0.5758, -0.6028, -0.2370, -0.9616, -0.9000],\n",
            "        [-0.7647,  0.5879,  0.4754,  0.0000,  0.0000, -0.0581, -0.3792,  0.5000],\n",
            "        [ 0.0000,  0.0553,  0.1148, -0.5556,  0.0000, -0.4039, -0.8651, -0.9667],\n",
            "        [-0.8824,  0.3970,  0.0164, -0.1717,  0.1348,  0.2131, -0.6089,  0.0000],\n",
            "        [-0.7647,  0.2261, -0.1475, -0.1313, -0.6265,  0.0790, -0.3698, -0.7667],\n",
            "        [-0.8824, -0.1859,  0.2131, -0.1717, -0.8652,  0.3800, -0.1307, -0.6333],\n",
            "        [-0.2941,  0.3467,  0.1475, -0.5354, -0.6927,  0.0551, -0.6038, -0.7333],\n",
            "        [-0.7647,  0.0251,  0.4098, -0.2727, -0.7163,  0.3562, -0.9582, -0.9333],\n",
            "        [-0.1765,  0.0653,  0.5082, -0.6364,  0.0000, -0.3234, -0.8659, -0.1000]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.]])\n",
            "Epoch:4 | Inputs tensor([[-0.5294, -0.0452, -0.0164, -0.3535,  0.0000,  0.0551, -0.8241, -0.7667],\n",
            "        [-0.8824,  0.4774,  0.5410, -0.1717,  0.0000,  0.4694, -0.7609, -0.8000],\n",
            "        [-0.8824,  0.3668,  0.2131,  0.0101, -0.5177,  0.1148, -0.7259, -0.9000],\n",
            "        [-0.5294,  0.7186,  0.1803,  0.0000,  0.0000,  0.2996, -0.6576, -0.8333],\n",
            "        [-0.8824, -0.0452,  0.2131, -0.5758, -0.8274, -0.2280, -0.4919, -0.5000],\n",
            "        [ 0.4118,  0.0050,  0.3770, -0.3333, -0.7518, -0.1058, -0.6499, -0.1667],\n",
            "        [ 0.0000,  0.5276,  0.3443, -0.2121, -0.3570,  0.2370, -0.8360, -0.8000],\n",
            "        [-0.5294,  0.1156,  0.1803, -0.0505, -0.5106,  0.1058,  0.1204,  0.1667],\n",
            "        [-0.1765,  0.0955,  0.3115, -0.3737,  0.0000,  0.0700, -0.1042, -0.2667],\n",
            "        [-0.7647,  0.3065,  0.5738,  0.0000,  0.0000, -0.3264, -0.8377,  0.0000],\n",
            "        [ 0.0000,  0.1859,  0.3770, -0.0505, -0.4563,  0.3651, -0.5961, -0.6667],\n",
            "        [-0.2941,  0.9095,  0.5082,  0.0000,  0.0000,  0.0581, -0.8292,  0.5000],\n",
            "        [ 0.0000, -0.0452,  0.3115, -0.0909, -0.7825,  0.0879, -0.7848, -0.8333],\n",
            "        [-0.5294,  0.3166,  0.1148, -0.5758, -0.6076, -0.0134, -0.9300, -0.7667],\n",
            "        [ 0.1765, -0.0955,  0.3934, -0.3535,  0.0000,  0.0402, -0.3621,  0.1667],\n",
            "        [-0.2941, -0.0854,  0.0000,  0.0000,  0.0000, -0.1118, -0.6388, -0.6667],\n",
            "        [-0.0588,  0.2462,  0.2459, -0.5152,  0.4184, -0.1446, -0.4799,  0.0333],\n",
            "        [-0.4118,  0.2663,  0.2787, -0.4545, -0.9480, -0.1177, -0.6917, -0.3667],\n",
            "        [-0.5294,  0.4472, -0.0492, -0.4343, -0.6690, -0.1207, -0.8215, -0.4667],\n",
            "        [-0.7647,  0.3970,  0.2295,  0.0000,  0.0000, -0.2370, -0.9240, -0.7333],\n",
            "        [ 0.0000,  0.4774,  0.3934,  0.0909,  0.0000,  0.2757, -0.7464, -0.9000],\n",
            "        [-0.8824,  0.1156,  0.5410,  0.0000,  0.0000, -0.0224, -0.8403, -0.2000],\n",
            "        [ 0.0588,  0.5678,  0.4098,  0.0000,  0.0000, -0.2608, -0.8702,  0.0667],\n",
            "        [-0.5294, -0.0050,  0.1148, -0.2323,  0.0000, -0.0224, -0.9428, -0.6000],\n",
            "        [ 0.0000,  0.7990, -0.1803, -0.2727, -0.6241,  0.1267, -0.6781, -0.9667],\n",
            "        [-0.7647,  0.3467,  0.1475,  0.0000,  0.0000, -0.1386, -0.6038, -0.9333],\n",
            "        [-0.5294, -0.0352, -0.0820, -0.6566, -0.8842, -0.3800, -0.7763, -0.8333],\n",
            "        [ 0.1765,  0.7990,  0.1475,  0.0000,  0.0000,  0.0462, -0.8958, -0.4667],\n",
            "        [ 0.0000,  0.0251,  0.4098, -0.6566, -0.7518, -0.1267, -0.4731, -0.8000],\n",
            "        [-0.8824, -0.0653, -0.0820, -0.7778,  0.0000, -0.3294, -0.7105, -0.9667],\n",
            "        [ 0.0000,  0.1759,  0.0820, -0.3737, -0.5556, -0.0820, -0.6456, -0.9667],\n",
            "        [-0.5294, -0.1558,  0.4754, -0.5354, -0.8676,  0.1773, -0.9308, -0.8667]]) | Labels tensor([[1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:5 | Inputs tensor([[-0.7647,  0.1156, -0.0164,  0.0000,  0.0000, -0.2191, -0.7737, -0.9333],\n",
            "        [ 0.0000, -0.3266,  0.2459,  0.0000,  0.0000,  0.3502, -0.9009, -0.1667],\n",
            "        [-0.8824,  0.0151, -0.1803, -0.6970, -0.9149, -0.2787, -0.6174, -0.8333],\n",
            "        [-0.6471,  0.1658,  0.0000,  0.0000,  0.0000, -0.2996, -0.9069, -0.9333],\n",
            "        [-0.8824, -0.1256,  0.1148, -0.3131, -0.8180,  0.1207, -0.7242, -0.9000],\n",
            "        [-0.4118, -0.2261,  0.3443, -0.1717, -0.9007,  0.0671, -0.9334, -0.5333],\n",
            "        [ 0.0000,  0.0151,  0.0164,  0.0000,  0.0000, -0.3472, -0.7797, -0.8667],\n",
            "        [ 0.0000, -0.4271, -0.0164,  0.0000,  0.0000, -0.3532, -0.4389,  0.5333],\n",
            "        [-0.0588,  0.7688,  0.4754, -0.3131, -0.2908,  0.0045, -0.6678,  0.2333],\n",
            "        [-0.8824, -0.0251,  0.0820, -0.6970, -0.6690, -0.3085, -0.6507, -0.9667],\n",
            "        [-0.7647,  0.0955,  0.5082,  0.0000,  0.0000,  0.2727, -0.3450,  0.1000],\n",
            "        [-0.6471,  0.3065,  0.0492,  0.0000,  0.0000, -0.3115, -0.7985, -0.9667],\n",
            "        [-0.7647, -0.0754, -0.1475,  0.0000,  0.0000, -0.1028, -0.9462, -0.9667],\n",
            "        [-0.4118,  0.4472,  0.3443, -0.4747, -0.3262, -0.0462, -0.6806,  0.2333],\n",
            "        [-0.6471,  0.8794,  0.1475, -0.5556, -0.5272,  0.0849, -0.7182, -0.5000],\n",
            "        [ 0.6471,  0.7588,  0.0164, -0.3939,  0.0000,  0.0015, -0.8856, -0.4333],\n",
            "        [-0.7647,  0.1256,  0.1148, -0.5556, -0.7778,  0.0164, -0.7976, -0.8333],\n",
            "        [-0.5294,  0.4171,  0.2131,  0.0000,  0.0000, -0.1773, -0.8582, -0.3667],\n",
            "        [ 0.5294,  0.5879,  0.8689,  0.0000,  0.0000,  0.2608, -0.8471, -0.2333],\n",
            "        [-0.4118,  0.1759,  0.5082,  0.0000,  0.0000,  0.0164, -0.7788, -0.4333],\n",
            "        [-0.2941,  0.4774,  0.3115,  0.0000,  0.0000, -0.1207, -0.9146, -0.0333],\n",
            "        [-0.1765,  0.0754,  0.2131,  0.0000,  0.0000, -0.1177, -0.8497, -0.6667],\n",
            "        [-0.5294,  0.3769,  0.3770,  0.0000,  0.0000, -0.0700, -0.8514, -0.7000],\n",
            "        [-0.4118, -0.5578,  0.0164,  0.0000,  0.0000, -0.2548, -0.5653, -0.5000],\n",
            "        [-0.0588,  0.9698,  0.2459, -0.4141, -0.3381,  0.1177, -0.5500,  0.2000],\n",
            "        [ 0.0000, -0.0050,  0.0000,  0.0000,  0.0000, -0.2548, -0.8506, -0.9667],\n",
            "        [-0.6471, -0.0050, -0.1148, -0.6162, -0.7967, -0.2370, -0.9351, -0.9000],\n",
            "        [ 0.7647,  0.3668,  0.1475, -0.3535, -0.7400,  0.1058, -0.9360, -0.2667],\n",
            "        [-0.1765,  0.1457,  0.0820,  0.0000,  0.0000, -0.0224, -0.8463, -0.3000],\n",
            "        [-0.1765,  0.1457,  0.0492,  0.0000,  0.0000, -0.1833, -0.4415, -0.5667],\n",
            "        [ 0.0000,  0.6583,  0.2459, -0.1313, -0.3972,  0.4277, -0.8454, -0.8333],\n",
            "        [-0.7647,  0.0653, -0.0820, -0.4545, -0.6099, -0.1356, -0.7028, -0.9667]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:6 | Inputs tensor([[-0.4118, -0.0251,  0.2459, -0.4545,  0.0000,  0.0611, -0.7438,  0.0333],\n",
            "        [-0.5294,  0.4573,  0.3443, -0.6364,  0.0000, -0.0313, -0.8659,  0.6333],\n",
            "        [ 0.0000,  0.1960,  0.0820, -0.4545,  0.0000,  0.1565, -0.8454, -0.9667],\n",
            "        [ 0.0000,  0.0452,  0.0492, -0.5354, -0.7258, -0.1714, -0.6789, -0.9333],\n",
            "        [-0.8824,  0.1960, -0.1148, -0.7374, -0.8818, -0.3353, -0.8915, -0.9000],\n",
            "        [ 0.4118, -0.1156,  0.2131, -0.1919, -0.8723,  0.0522, -0.7438, -0.1000],\n",
            "        [-0.7647,  0.1759,  0.4754, -0.6162, -0.8322, -0.2489, -0.7993,  0.0000],\n",
            "        [-0.8824,  0.1357,  0.0492, -0.2929,  0.0000,  0.0015, -0.6029,  0.0000],\n",
            "        [ 0.0000, -0.2563, -0.1475, -0.7980, -0.9149, -0.1714, -0.8369, -0.9667],\n",
            "        [ 0.0000,  0.0754,  0.0164, -0.3939, -0.8251,  0.0909, -0.4202, -0.8667],\n",
            "        [ 0.0000,  0.1859,  0.0492, -0.5354, -0.7896,  0.0000,  0.4116,  0.0000],\n",
            "        [-0.0588,  0.2060,  0.0000,  0.0000,  0.0000, -0.1058, -0.9103, -0.4333],\n",
            "        [-0.5294,  0.2965,  0.4098, -0.5960, -0.3617,  0.0462, -0.8693, -0.9333],\n",
            "        [ 0.5294,  0.0653,  0.1475,  0.0000,  0.0000,  0.0194, -0.8523,  0.0333],\n",
            "        [ 0.0000, -0.0151,  0.3443, -0.6970, -0.8014, -0.2489, -0.8113, -0.9667],\n",
            "        [-0.5294, -0.0955,  0.4426, -0.0505, -0.8723,  0.1237, -0.7575, -0.7333],\n",
            "        [-0.5294,  0.5678,  0.2295,  0.0000,  0.0000,  0.4396, -0.8634, -0.6333],\n",
            "        [-0.8824,  0.0653,  0.2459,  0.0000,  0.0000,  0.1177, -0.8984, -0.8333],\n",
            "        [-0.2941,  0.2563,  0.2459,  0.0000,  0.0000,  0.0075, -0.9633,  0.1000],\n",
            "        [ 0.0000,  0.0251,  0.2295, -0.5354,  0.0000,  0.0000, -0.5781,  0.0000],\n",
            "        [ 0.1765, -0.0754,  0.0164,  0.0000,  0.0000, -0.2280, -0.9240, -0.6667],\n",
            "        [-0.8824,  0.0854,  0.4426, -0.6162,  0.0000, -0.1922, -0.7250, -0.9000],\n",
            "        [-0.2941, -0.1256,  0.3115,  0.0000,  0.0000, -0.3085, -0.9949, -0.6333],\n",
            "        [ 0.0000, -0.0653, -0.0164, -0.4949, -0.7825, -0.1446, -0.6123, -0.9667],\n",
            "        [-0.6471,  0.1156,  0.0164,  0.0000,  0.0000, -0.3264, -0.9453,  0.0000],\n",
            "        [-0.7647,  0.2764, -0.2459, -0.5758, -0.2080,  0.0253, -0.9163, -0.9667],\n",
            "        [-0.6471,  0.7186,  0.1803, -0.3333, -0.6809, -0.0075, -0.8967, -0.9000],\n",
            "        [ 0.0000,  0.2663,  0.4098, -0.4545, -0.7163, -0.1833, -0.6268,  0.0000],\n",
            "        [ 0.2941,  0.3869,  0.2459,  0.0000,  0.0000, -0.0104, -0.7079, -0.5333],\n",
            "        [-0.8824,  0.8090,  0.0000,  0.0000,  0.0000,  0.2906, -0.8258, -0.3333],\n",
            "        [-0.6471, -0.1256, -0.0164, -0.6364,  0.0000, -0.3502, -0.6874,  0.0000],\n",
            "        [-0.0588,  0.7990,  0.1803, -0.1515, -0.6927, -0.0253, -0.4526, -0.5000]]) | Labels tensor([[0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.]])\n",
            "Epoch:7 | Inputs tensor([[-0.5294,  0.4774,  0.2131, -0.4949, -0.3073,  0.0402, -0.7378, -0.7000],\n",
            "        [-0.4118, -0.1457,  0.2131, -0.5556,  0.0000, -0.1356, -0.0213, -0.6333],\n",
            "        [ 0.1765,  0.2261,  0.2787, -0.3737,  0.0000, -0.1773, -0.6294, -0.2000],\n",
            "        [-0.6471,  0.2462,  0.3115, -0.3333, -0.6927, -0.0104, -0.8061, -0.8333],\n",
            "        [-0.4118, -0.0352,  0.2131, -0.6364, -0.8416,  0.0015, -0.2152, -0.2667],\n",
            "        [-0.5294,  0.2261,  0.1148,  0.0000,  0.0000,  0.0432, -0.7301, -0.7333],\n",
            "        [-0.0588, -0.2563,  0.1475, -0.1919, -0.8842,  0.0522, -0.4646, -0.4000],\n",
            "        [-0.4118,  0.5578,  0.3770, -0.1111,  0.2884,  0.1535, -0.5380, -0.5667],\n",
            "        [ 0.0588,  0.5477,  0.2787, -0.3939, -0.7636, -0.0790, -0.9266, -0.2000],\n",
            "        [-0.7647, -0.1859,  0.1803, -0.6970, -0.8203, -0.1028, -0.5995, -0.8667],\n",
            "        [-0.6471,  0.7487, -0.0492, -0.5556, -0.5414, -0.0194, -0.5602, -0.5000],\n",
            "        [ 0.0588,  0.6482,  0.3770, -0.5758,  0.0000, -0.0820, -0.3570, -0.6333],\n",
            "        [-0.8824,  0.2563, -0.1803, -0.1919, -0.6052, -0.0075, -0.2451, -0.7667],\n",
            "        [-0.5294,  0.4673,  0.2787,  0.0000,  0.0000,  0.1475, -0.6225,  0.5333],\n",
            "        [-0.5294, -0.2362,  0.0164,  0.0000,  0.0000,  0.0134, -0.7327, -0.8667],\n",
            "        [-0.6471,  0.1357, -0.2787, -0.7374,  0.0000, -0.3323, -0.9471, -0.9667],\n",
            "        [-0.7647, -0.0553,  0.2459, -0.6364, -0.8440, -0.0581, -0.5124, -0.9333],\n",
            "        [-0.6471,  0.1658,  0.2131, -0.6970, -0.7518, -0.2161, -0.9752, -0.9000],\n",
            "        [-0.1765,  0.6080, -0.1148, -0.3535, -0.5863, -0.0909, -0.5645, -0.4000],\n",
            "        [-0.7647,  0.2060,  0.2459, -0.2525, -0.7518,  0.1833, -0.8830, -0.7333],\n",
            "        [ 0.0588,  0.3065,  0.1475,  0.0000,  0.0000,  0.0194, -0.5098, -0.2000],\n",
            "        [ 0.0588,  0.0251,  0.2459, -0.2525,  0.0000, -0.0194, -0.4987, -0.1667],\n",
            "        [ 0.0000,  0.4673,  0.1475,  0.0000,  0.0000,  0.1297, -0.7814, -0.7667],\n",
            "        [-0.6471,  0.5879,  0.2459, -0.2727, -0.4208, -0.0581, -0.3399, -0.7667],\n",
            "        [ 0.0000,  0.1357,  0.2459,  0.0000,  0.0000, -0.0075, -0.8292, -0.9333],\n",
            "        [ 0.0000,  0.2060,  0.2131, -0.6364, -0.8511, -0.0909, -0.8232, -0.8333],\n",
            "        [-0.4118, -0.0452,  0.1803, -0.3333,  0.0000,  0.1237, -0.7506, -0.8000],\n",
            "        [-0.6471,  0.1357, -0.1803, -0.7980, -0.7991, -0.1207, -0.5320, -0.8667],\n",
            "        [-0.8824,  0.5176, -0.0164,  0.0000,  0.0000, -0.2221, -0.9137, -0.9667],\n",
            "        [-0.6471, -0.1558,  0.1803, -0.3535,  0.0000,  0.1088, -0.8386, -0.7667],\n",
            "        [-0.8824,  0.3065, -0.0164, -0.5354, -0.5981, -0.1475, -0.4757,  0.0000],\n",
            "        [ 0.0000,  0.2965,  0.8033, -0.0707, -0.6927,  1.0000, -0.7942, -0.8333]]) | Labels tensor([[1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]])\n",
            "Epoch:8 | Inputs tensor([[-0.7647, -0.1658,  0.0820, -0.5354, -0.8818, -0.0402, -0.6422, -0.9667],\n",
            "        [ 0.0000,  0.7789, -0.0164, -0.4141,  0.1300,  0.0313, -0.1512,  0.0000],\n",
            "        [ 0.0588,  0.2060,  0.1803, -0.5556, -0.8676, -0.3800, -0.4406, -0.1000],\n",
            "        [ 0.0000, -0.0553,  0.0000,  0.0000,  0.0000,  0.0000, -0.8480, -0.8667],\n",
            "        [-0.5294,  0.9799,  0.1475, -0.2121,  0.7589,  0.0939,  0.9223, -0.6667],\n",
            "        [-0.7647, -0.0050,  0.0000,  0.0000,  0.0000, -0.3383, -0.9744, -0.9333],\n",
            "        [-0.6471,  0.4171,  0.0000,  0.0000,  0.0000, -0.1058, -0.4167, -0.8000],\n",
            "        [-0.8824,  0.3367,  0.6721, -0.4343, -0.6690, -0.0224, -0.8668, -0.2000],\n",
            "        [-0.6471, -0.1658, -0.0492, -0.3737, -0.9574,  0.0224, -0.7797, -0.8667],\n",
            "        [-0.7647, -0.0151, -0.0164, -0.6566, -0.7163,  0.0343, -0.8975, -0.9667],\n",
            "        [-0.8824,  0.2261,  0.0492, -0.3535, -0.6312,  0.0462, -0.4757, -0.7000],\n",
            "        [-0.6471, -0.1960,  0.0000,  0.0000,  0.0000,  0.0000, -0.9180, -0.9667],\n",
            "        [-0.7647,  0.1256,  0.0820, -0.5556,  0.0000, -0.2548, -0.8044, -0.9000],\n",
            "        [-0.1765,  0.5980,  0.0492,  0.0000,  0.0000, -0.1833, -0.8155, -0.3667],\n",
            "        [ 0.0000,  0.3266,  0.2787,  0.0000,  0.0000, -0.0343, -0.7310,  0.0000],\n",
            "        [-0.5294,  0.4673,  0.3934, -0.4545, -0.7636, -0.1386, -0.9052, -0.8000],\n",
            "        [-0.7647,  0.0653,  0.0492, -0.2929, -0.7187, -0.0909,  0.1289, -0.5667],\n",
            "        [-0.6471,  0.3065,  0.2787, -0.5354, -0.8132, -0.1535, -0.7908, -0.5667],\n",
            "        [-0.8824,  0.2261,  0.4754,  0.0303, -0.4799,  0.4814, -0.7891, -0.6667],\n",
            "        [-0.0588, -0.0452,  0.1803,  0.0000,  0.0000,  0.0969, -0.6524,  0.2000],\n",
            "        [-0.1765,  0.3367,  0.3770,  0.0000,  0.0000,  0.1982, -0.4722, -0.4667],\n",
            "        [-0.2941,  0.0251,  0.4754, -0.2121,  0.0000,  0.0641, -0.4910, -0.7667],\n",
            "        [ 0.0000,  0.1357,  0.3115, -0.6768,  0.0000, -0.0760, -0.3202,  0.0000],\n",
            "        [ 0.0000,  0.2462,  0.1475, -0.5960,  0.0000, -0.1833, -0.8497, -0.5000],\n",
            "        [-0.1765,  0.9497,  0.1148, -0.4343,  0.0000,  0.0700, -0.4304, -0.3333],\n",
            "        [-0.8824,  0.6482,  0.3443, -0.1313, -0.8416, -0.0224, -0.7754, -0.0333],\n",
            "        [-0.8824,  0.4472,  0.3443, -0.1919,  0.0000,  0.2310, -0.5482, -0.7667],\n",
            "        [-0.1765,  0.5075,  0.2787, -0.4141, -0.7021,  0.0492, -0.4757,  0.1000],\n",
            "        [-0.5294,  0.2060,  0.1148,  0.0000,  0.0000, -0.1177, -0.4611, -0.5667],\n",
            "        [-0.5294,  0.3266,  0.4098, -0.3737,  0.0000, -0.1654, -0.7088,  0.4000],\n",
            "        [-0.8824,  0.1960, -0.2787, -0.0505, -0.8511,  0.0581, -0.8275, -0.8667],\n",
            "        [-0.6471,  0.3970, -0.1148,  0.0000,  0.0000, -0.2370, -0.7233, -0.9667]]) | Labels tensor([[1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]])\n",
            "Epoch:9 | Inputs tensor([[-0.7647,  0.2864,  0.0492, -0.1515,  0.0000,  0.1922, -0.1264, -0.9000],\n",
            "        [-0.8824, -0.1960,  0.2131, -0.7778, -0.8582, -0.1058, -0.6166, -0.9667],\n",
            "        [ 0.0000,  0.0754,  0.2459,  0.0000,  0.0000,  0.3502, -0.4808, -0.9000],\n",
            "        [-0.2941,  0.0854, -0.2787, -0.5960, -0.6927, -0.2846, -0.3723, -0.5333],\n",
            "        [-0.6471,  0.0251,  0.2131,  0.0000,  0.0000, -0.1207, -0.9633, -0.6333],\n",
            "        [-0.6471, -0.3869,  0.3443, -0.4343,  0.0000,  0.0253, -0.8591, -0.1667],\n",
            "        [-0.2941, -0.0050, -0.0164, -0.6162, -0.8723, -0.1982, -0.6422, -0.6333],\n",
            "        [-0.7647,  0.0553, -0.0492, -0.1919, -0.7778,  0.0402, -0.8745, -0.8667],\n",
            "        [-0.0588,  0.3367,  0.1803,  0.0000,  0.0000, -0.0194, -0.8360, -0.4000],\n",
            "        [-0.5294,  0.8492,  0.2787, -0.2121, -0.3452,  0.1028, -0.8412, -0.6667],\n",
            "        [-0.5294,  0.5176,  0.4754, -0.2323,  0.0000, -0.1148, -0.8155, -0.5000],\n",
            "        [ 0.4118,  0.2161,  0.2787, -0.6566,  0.0000, -0.2101, -0.8454,  0.3667],\n",
            "        [-0.8824,  0.0000,  0.1148, -0.2929,  0.0000, -0.0462, -0.7344, -0.9667],\n",
            "        [-0.1765, -0.1859,  0.2787, -0.1919, -0.8865,  0.3920, -0.8437, -0.3000],\n",
            "        [-0.8824, -0.0754,  0.0164, -0.4949, -0.9031, -0.4188, -0.6550, -0.8667],\n",
            "        [-0.8824,  0.0352, -0.5082, -0.2323, -0.8038,  0.2906, -0.9103, -0.6000],\n",
            "        [-0.5294,  0.1256,  0.2787, -0.1919,  0.0000,  0.1744, -0.8651, -0.4333],\n",
            "        [-0.6471, -0.1859,  0.4098, -0.6768, -0.8440, -0.1803, -0.8053, -0.9667],\n",
            "        [-0.8824,  0.2060,  0.3115, -0.0303, -0.5272,  0.1595, -0.0743, -0.3333],\n",
            "        [ 0.1765,  0.3970,  0.3115,  0.0000,  0.0000, -0.1922,  0.1640,  0.2000],\n",
            "        [-0.5294,  0.4472,  0.3443, -0.3535,  0.0000,  0.1475, -0.5935, -0.4667],\n",
            "        [ 0.5294,  0.5276,  0.4754, -0.3333, -0.9314, -0.2012, -0.4424, -0.2667],\n",
            "        [-0.7647,  0.0553,  0.2295,  0.0000,  0.0000, -0.3055, -0.5884,  0.0667],\n",
            "        [-0.5294,  0.3668,  0.1475,  0.0000,  0.0000, -0.0700, -0.0572, -0.9667],\n",
            "        [-0.5294,  0.1055,  0.0820,  0.0000,  0.0000, -0.0492, -0.6644, -0.7333],\n",
            "        [ 0.0000,  0.1156,  0.0656,  0.0000,  0.0000, -0.2668, -0.5030, -0.6667],\n",
            "        [-0.2941, -0.0352,  0.0000,  0.0000,  0.0000, -0.2936, -0.9044, -0.7667],\n",
            "        [-0.8824, -0.0452,  0.0820, -0.7374, -0.9102, -0.4158, -0.7814, -0.8667],\n",
            "        [-0.2941,  0.0553,  0.3115, -0.4343,  0.0000, -0.0313, -0.3168, -0.8333],\n",
            "        [-0.7647,  0.2161,  0.1475, -0.3535, -0.7754,  0.1654, -0.3100, -0.9333],\n",
            "        [-0.4118,  0.0955,  0.2295, -0.4747,  0.0000,  0.0730, -0.6003,  0.3000],\n",
            "        [-0.1765,  0.4271,  0.4754, -0.5152,  0.1348, -0.0939, -0.9573, -0.2667]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]])\n",
            "Epoch:10 | Inputs tensor([[-0.6471,  0.8291,  0.2131,  0.0000,  0.0000, -0.0909, -0.7720, -0.7333],\n",
            "        [-0.1765,  0.1960,  0.0000,  0.0000,  0.0000, -0.2489, -0.8881, -0.4667],\n",
            "        [-0.5294, -0.0955,  0.0000,  0.0000,  0.0000, -0.1654, -0.5457, -0.6667],\n",
            "        [-0.2941, -0.0653, -0.1803, -0.3939, -0.8487, -0.1446, -0.7626, -0.9333],\n",
            "        [-0.2941,  0.2462,  0.1803,  0.0000,  0.0000, -0.1773, -0.7523, -0.7333],\n",
            "        [-0.1765,  0.0653, -0.0164, -0.5152,  0.0000, -0.2101, -0.8138, -0.7333],\n",
            "        [-0.7647,  0.1256,  0.2295, -0.3535,  0.0000,  0.0641, -0.9402,  0.0000],\n",
            "        [-0.6471,  0.1256,  0.2131, -0.3939,  0.0000, -0.0581, -0.8984, -0.8667],\n",
            "        [ 0.0000,  0.0251, -0.1475,  0.0000,  0.0000, -0.2519,  0.0000,  0.0000],\n",
            "        [-0.7647,  0.1960,  0.0000,  0.0000,  0.0000, -0.4158, -0.3561,  0.7000],\n",
            "        [ 0.0000,  0.0553,  0.4754,  0.0000,  0.0000, -0.1177, -0.8984, -0.1667],\n",
            "        [-0.7647, -0.1156, -0.0492, -0.4747, -0.9622, -0.1535, -0.4125, -0.9667],\n",
            "        [ 0.0000,  0.0151,  0.0656, -0.4343,  0.0000, -0.2668, -0.8642, -0.9667],\n",
            "        [-0.5294,  0.8995,  0.8033, -0.3737,  0.0000, -0.1505, -0.4859, -0.4667],\n",
            "        [-0.4118,  0.0653,  0.3443, -0.3939,  0.0000,  0.1773, -0.8224, -0.4333],\n",
            "        [-0.5294, -0.0050,  0.2459, -0.6970, -0.8794, -0.3085, -0.8762,  0.0000],\n",
            "        [-0.2941,  0.0754,  0.4426,  0.0000,  0.0000,  0.0969, -0.4458, -0.6667],\n",
            "        [-0.8824, -0.0050, -0.0492, -0.7980,  0.0000, -0.2429, -0.5961,  0.0000],\n",
            "        [-0.2941,  0.1960, -0.1803, -0.5556, -0.5839, -0.1922,  0.0589, -0.6000],\n",
            "        [-0.4118,  0.0352,  0.7705, -0.2525,  0.0000,  0.1684, -0.8061,  0.4667],\n",
            "        [-0.5294, -0.0553,  0.0656, -0.5556,  0.0000, -0.2638, -0.9402,  0.0000],\n",
            "        [-0.6471,  0.8090,  0.0492, -0.4949, -0.8345,  0.0134, -0.8352, -0.8333],\n",
            "        [ 0.0000,  0.1759,  0.0000,  0.0000,  0.0000,  0.0075, -0.2707, -0.2333],\n",
            "        [-0.6471,  0.9196,  0.1148, -0.6970, -0.6927, -0.0790, -0.8113, -0.5667],\n",
            "        [-0.6471,  0.9397,  0.1475, -0.3737,  0.0000,  0.0402, -0.8608, -0.8667],\n",
            "        [-0.6471,  0.0653, -0.1148, -0.5758, -0.6265, -0.0790, -0.8173, -0.9000],\n",
            "        [-0.8824, -0.0251,  0.1148, -0.5758,  0.0000, -0.1893, -0.1315, -0.9667],\n",
            "        [ 0.0000,  0.2563,  0.5738,  0.0000,  0.0000, -0.3294, -0.8429,  0.0000],\n",
            "        [ 0.0000, -0.1558,  0.3443, -0.3737, -0.7045,  0.1386, -0.8676, -0.9333],\n",
            "        [-0.2941,  0.1759,  0.5738,  0.0000,  0.0000, -0.1446, -0.9325, -0.7000],\n",
            "        [-0.6471,  0.1156, -0.0820, -0.2121,  0.0000, -0.1028, -0.5909, -0.7000],\n",
            "        [-0.5294,  0.1859,  0.1475,  0.0000,  0.0000,  0.3264, -0.2946, -0.8333]]) | Labels tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:11 | Inputs tensor([[-0.8824,  0.2663, -0.0820, -0.4141, -0.6407, -0.1446, -0.3826,  0.0000],\n",
            "        [-0.7647,  0.9799,  0.1475,  1.0000,  0.0000,  0.0343, -0.5756,  0.3667],\n",
            "        [-0.6471,  0.6985,  0.2131, -0.6162, -0.7045, -0.1088, -0.8377, -0.6667],\n",
            "        [-0.5294,  0.2563,  0.3115,  0.0000,  0.0000, -0.0373, -0.6089, -0.8000],\n",
            "        [-0.4118,  0.3065,  0.3443,  0.0000,  0.0000,  0.1654, -0.2502, -0.4667],\n",
            "        [ 0.0000,  0.0854,  0.1148, -0.5960,  0.0000, -0.1863, -0.3945, -0.6333],\n",
            "        [-0.8824,  0.3065,  0.1475, -0.7374, -0.7518, -0.2280, -0.6635, -0.9667],\n",
            "        [ 0.2941,  0.1156,  0.3770, -0.1919,  0.0000,  0.3949, -0.2767, -0.2000],\n",
            "        [ 0.0000,  0.4171,  0.0000,  0.0000,  0.0000,  0.2638, -0.8915, -0.7333],\n",
            "        [-0.2941, -0.1960,  0.0820, -0.3939,  0.0000, -0.2191, -0.7993, -0.3333],\n",
            "        [ 0.0588,  0.5276,  0.2787, -0.3131, -0.5957,  0.0194, -0.3040, -0.6000],\n",
            "        [-0.7647, -0.0050, -0.1475, -0.6970, -0.7778, -0.2668, -0.5226,  0.0000],\n",
            "        [-0.7647,  0.0050,  0.1148, -0.4949, -0.8322,  0.1475, -0.7899, -0.8333],\n",
            "        [-0.5294,  0.1055,  0.5082,  0.0000,  0.0000,  0.1207, -0.9035, -0.7000],\n",
            "        [-0.8824,  0.0352,  0.3115, -0.7778, -0.8061, -0.4218, -0.6473, -0.9667],\n",
            "        [-0.6471,  0.4874,  0.0820, -0.4949,  0.0000, -0.0313, -0.8480, -0.9667],\n",
            "        [-0.5294, -0.1658,  0.4098, -0.6162,  0.0000, -0.1267, -0.7959, -0.5667],\n",
            "        [-0.7647,  0.4472, -0.0492, -0.3333, -0.6809, -0.0581, -0.7062, -0.8667],\n",
            "        [-0.5294,  0.1558,  0.1803,  0.0000,  0.0000, -0.1386, -0.7455, -0.1667],\n",
            "        [-0.8824, -0.2060,  0.2295, -0.3939,  0.0000, -0.0462, -0.7284, -0.9667],\n",
            "        [-0.8824,  0.6884,  0.4426, -0.4141,  0.0000,  0.0432, -0.2938,  0.0333],\n",
            "        [-0.5294,  0.4673,  0.5082,  0.0000,  0.0000, -0.0700, -0.6063,  0.3333],\n",
            "        [ 0.0000, -0.0452,  0.0492, -0.2121, -0.7518,  0.3294, -0.7541, -0.9667],\n",
            "        [-0.0588,  0.0050,  0.2459,  0.0000,  0.0000,  0.1535, -0.9044, -0.3000],\n",
            "        [ 0.1765,  0.6884,  0.2131,  0.0000,  0.0000,  0.1326, -0.6080, -0.5667],\n",
            "        [-0.6471,  0.1558,  0.0820, -0.2121, -0.6690,  0.1356, -0.9385, -0.7667],\n",
            "        [-0.1765,  0.2965,  0.1148, -0.0101, -0.7045,  0.1475, -0.6917, -0.2667],\n",
            "        [-0.1765,  0.3668,  0.4754,  0.0000,  0.0000, -0.1088, -0.8873, -0.0333],\n",
            "        [-0.8824,  0.0955, -0.0820, -0.5758, -0.6809, -0.2489, -0.3553, -0.9333],\n",
            "        [-0.0588,  0.6784,  0.7377, -0.0707, -0.4539,  0.1207, -0.9257, -0.2667],\n",
            "        [-0.1765,  0.0251,  0.2131, -0.1919, -0.7518,  0.1088, -0.8924, -0.2000],\n",
            "        [ 0.0000,  0.6181, -0.1803,  0.0000,  0.0000, -0.3472, -0.8497,  0.4667]]) | Labels tensor([[1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:12 | Inputs tensor([[-0.4118,  0.3266,  0.3115,  0.0000,  0.0000, -0.2012, -0.9078,  0.6000],\n",
            "        [-0.6471,  0.0050,  0.1148, -0.5354, -0.8085, -0.0581, -0.2562, -0.7667],\n",
            "        [-0.2941,  0.2362,  0.1803, -0.0909, -0.4563,  0.0015, -0.4406, -0.5667],\n",
            "        [-0.1765,  0.2462,  0.1475, -0.3333, -0.4917, -0.2399, -0.9291, -0.4667],\n",
            "        [-0.8824, -0.0955,  0.1148, -0.8384,  0.0000, -0.2697, -0.0948, -0.5000],\n",
            "        [-0.8824,  0.1256,  0.1803, -0.3939, -0.5839,  0.0253, -0.6157, -0.8667],\n",
            "        [-0.7647, -0.1055,  0.4754, -0.3939,  0.0000, -0.0015, -0.8173, -0.3000],\n",
            "        [ 0.0000,  0.0050,  0.4426,  0.2121, -0.7400,  0.3949, -0.2451, -0.6667],\n",
            "        [-0.8824, -0.0050,  0.1803, -0.3939, -0.9574,  0.1505, -0.7148,  0.0000],\n",
            "        [-0.6471, -0.0955,  0.2787,  0.0000,  0.0000,  0.2727, -0.5892,  0.0000],\n",
            "        [-0.7647,  0.2965,  0.3770,  0.0000,  0.0000, -0.1654, -0.8241, -0.8000],\n",
            "        [-0.7647,  0.4171, -0.0492, -0.3131, -0.6974, -0.2429, -0.4697, -0.9000],\n",
            "        [-0.8824,  1.0000,  0.2459, -0.1313,  0.0000,  0.2787,  0.1238, -0.9667],\n",
            "        [-0.8824,  0.2864, -0.2131, -0.0909, -0.5414,  0.2072, -0.5431, -0.9000],\n",
            "        [ 0.0000,  0.1960,  0.0000,  0.0000,  0.0000, -0.0343, -0.9462, -0.9000],\n",
            "        [-0.7647, -0.0553,  0.1148, -0.6364, -0.8203, -0.2250, -0.5875,  0.0000],\n",
            "        [-0.6471,  0.7387,  0.3443, -0.0303,  0.0993,  0.1446,  0.7583, -0.8667],\n",
            "        [-0.4118, -0.1156,  0.2787, -0.3939,  0.0000, -0.1773, -0.8463, -0.4667],\n",
            "        [ 0.1765,  0.0854,  0.0820,  0.0000,  0.0000, -0.0343, -0.8343, -0.3000],\n",
            "        [-0.8824,  0.2864,  0.6066, -0.1717, -0.8629, -0.0462,  0.0615, -0.6000],\n",
            "        [ 0.0000,  0.7990,  0.4754, -0.4545,  0.0000,  0.3145, -0.4808, -0.9333],\n",
            "        [ 0.0588,  0.2261, -0.0820,  0.0000,  0.0000, -0.0075, -0.1153, -0.6000],\n",
            "        [-0.7647, -0.0050, -0.0164, -0.6566, -0.6217,  0.0909, -0.6798,  0.0000],\n",
            "        [-0.1765,  0.3367,  0.4426, -0.6970, -0.6336, -0.0343, -0.8429, -0.4667],\n",
            "        [-0.6471, -0.1156, -0.0492, -0.7778, -0.8723, -0.2608, -0.8386, -0.9667],\n",
            "        [-0.1765,  0.7889,  0.3770,  0.0000,  0.0000,  0.1893, -0.7839, -0.3333],\n",
            "        [-0.5294,  0.1457,  0.0492,  0.0000,  0.0000, -0.1386, -0.9590, -0.9000],\n",
            "        [-0.7647, -0.1256,  0.0000, -0.5354,  0.0000, -0.1386, -0.4065, -0.8667],\n",
            "        [-0.7647,  0.0754,  0.2131, -0.3939, -0.7636,  0.0015, -0.7216, -0.9333],\n",
            "        [-0.1765,  0.9598,  0.1475, -0.3333, -0.6572, -0.2519, -0.9274,  0.1333],\n",
            "        [-0.4118,  0.1457,  0.2131,  0.0000,  0.0000, -0.2578, -0.4313,  0.2000],\n",
            "        [-0.7647, -0.1558,  0.0000,  0.0000,  0.0000,  0.0000, -0.8070,  0.0000]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:13 | Inputs tensor([[-0.7647,  0.2864,  0.2787, -0.2525, -0.5697,  0.2906, -0.0213, -0.6667],\n",
            "        [-0.5294,  0.3266,  0.0000,  0.0000,  0.0000, -0.0194, -0.8087, -0.9333],\n",
            "        [-0.2941,  0.6281,  0.0164,  0.0000,  0.0000, -0.2757, -0.9146, -0.0333],\n",
            "        [-0.0588,  0.1055,  0.2459,  0.0000,  0.0000, -0.1714, -0.8642,  0.2333],\n",
            "        [-0.7647, -0.1859, -0.0164, -0.5556,  0.0000, -0.1744, -0.8190, -0.8667],\n",
            "        [ 0.0588,  0.1256,  0.3443, -0.3535, -0.5863,  0.0194, -0.8446, -0.5000],\n",
            "        [-0.7647,  0.1256,  0.4098, -0.1515, -0.6217,  0.1446, -0.8565, -0.7667],\n",
            "        [-0.5294,  0.1658,  0.1803, -0.7576, -0.7943, -0.3413, -0.6712, -0.4667],\n",
            "        [-0.2941,  0.2563,  0.1148, -0.3939, -0.7163, -0.1058, -0.6704, -0.6333],\n",
            "        [ 0.0000,  0.3568,  0.1148, -0.1515, -0.4090,  0.2608, -0.7549, -0.9000],\n",
            "        [-0.7647,  0.0854, -0.1475, -0.4747, -0.8511, -0.0313, -0.7950, -0.9667],\n",
            "        [-0.8824, -0.1256,  0.2787, -0.4545, -0.9244,  0.0313, -0.9804, -0.9667],\n",
            "        [ 0.0000,  0.0251,  0.0492, -0.0707, -0.8156,  0.2101, -0.6430,  0.0000],\n",
            "        [ 0.0000,  0.6784,  0.0000,  0.0000,  0.0000, -0.0373, -0.3501, -0.7000],\n",
            "        [-0.6471, -0.1759,  0.1475,  0.0000,  0.0000, -0.3711, -0.7344, -0.8667],\n",
            "        [ 1.0000,  0.6382,  0.1803, -0.1717, -0.7305,  0.2191, -0.3689, -0.1333],\n",
            "        [-0.1765,  0.0050,  0.0000,  0.0000,  0.0000, -0.1058, -0.6533, -0.6333],\n",
            "        [-0.0588, -0.1457, -0.0984, -0.5960,  0.0000, -0.2727, -0.9505, -0.3000],\n",
            "        [ 0.1765,  0.1558,  0.6066,  0.0000,  0.0000, -0.2846, -0.1939, -0.5667],\n",
            "        [-0.5294,  0.0955,  0.0492, -0.1111, -0.7660,  0.0373, -0.2938, -0.8333],\n",
            "        [-0.2941,  0.1457,  0.0000,  0.0000,  0.0000,  0.0000, -0.9052, -0.8333],\n",
            "        [-0.6471, -0.0352, -0.0820, -0.3131, -0.7281, -0.2638, -0.2605, -0.4000],\n",
            "        [-0.8824,  0.3568, -0.1148,  0.0000,  0.0000, -0.2042, -0.4799,  0.3667],\n",
            "        [-0.6471,  0.4271,  0.3115, -0.6970,  0.0000, -0.0343, -0.8958,  0.4000],\n",
            "        [-0.8824,  0.0050,  0.2131, -0.7576, -0.8913, -0.4188, -0.9394, -0.7667],\n",
            "        [ 0.4118,  0.4070,  0.3934, -0.3333,  0.0000,  0.1148, -0.8582, -0.3333],\n",
            "        [-0.6471, -0.0352,  0.2787, -0.2121,  0.0000,  0.1118, -0.8634, -0.3667],\n",
            "        [-0.8824, -0.1457,  0.0820, -0.4141,  0.0000, -0.2072, -0.7669, -0.6667],\n",
            "        [-0.7647, -0.1156,  0.2131, -0.6162, -0.8747, -0.1356, -0.8711, -0.9667],\n",
            "        [ 0.0000,  0.2864,  0.1148, -0.6162, -0.5745, -0.0909,  0.1213, -0.8667],\n",
            "        [-0.4118,  0.1658,  0.2131, -0.4141,  0.0000, -0.0373, -0.5030, -0.5333],\n",
            "        [ 0.0588,  0.5678,  0.4098, -0.4343, -0.6336,  0.0224, -0.0512, -0.3000]]) | Labels tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]])\n",
            "Epoch:14 | Inputs tensor([[-0.8824,  0.0050,  0.1803, -0.7576, -0.8345, -0.2459, -0.5047, -0.7667],\n",
            "        [ 0.0000,  0.0151,  0.0492, -0.6566,  0.0000, -0.3741, -0.8514,  0.0000],\n",
            "        [-0.6471, -0.0050,  0.3115, -0.7778, -0.8487, -0.4247, -0.8241, -0.7000],\n",
            "        [-0.7647,  0.0553,  0.3115, -0.0909, -0.5485,  0.0045, -0.4594, -0.7333],\n",
            "        [-0.7647,  0.1859,  0.3115,  0.0000,  0.0000,  0.2787, -0.4748,  0.0000],\n",
            "        [-0.7647,  0.7588,  0.4426,  0.0000,  0.0000, -0.3174, -0.7882, -0.9667],\n",
            "        [-0.6471,  0.2965,  0.5082, -0.0101, -0.6336,  0.0849, -0.2400, -0.6333],\n",
            "        [ 0.1765,  0.3367,  0.1148,  0.0000,  0.0000, -0.1952, -0.8574, -0.5000],\n",
            "        [-0.8824,  0.3970, -0.2459, -0.6162, -0.8038, -0.1446, -0.5081, -0.9667],\n",
            "        [ 0.4118,  0.4070,  0.3443, -0.1313, -0.2317,  0.1684, -0.6157,  0.2333],\n",
            "        [-0.7647,  0.2462,  0.1148, -0.4343, -0.5154, -0.0194, -0.3194, -0.7000],\n",
            "        [-0.6471,  0.1156, -0.0492, -0.3737, -0.8960, -0.1207, -0.6994, -0.9667],\n",
            "        [-0.7647, -0.1759, -0.1475, -0.5556, -0.7281, -0.1505,  0.3843, -0.8667],\n",
            "        [ 0.1765,  0.2563,  0.1475, -0.4747, -0.7281, -0.0730, -0.8915, -0.3333],\n",
            "        [-0.5294,  0.1759,  0.0164, -0.7576,  0.0000, -0.1148, -0.7421, -0.7000],\n",
            "        [-0.5294,  0.7387,  0.1475, -0.7172, -0.6028, -0.1148, -0.7583, -0.6000],\n",
            "        [-0.0588,  0.0754,  0.3115,  0.0000,  0.0000, -0.2668, -0.3356, -0.5667],\n",
            "        [-0.6471,  0.2663,  0.4426, -0.1717, -0.4444,  0.1714, -0.4654, -0.8000],\n",
            "        [-0.4118,  0.1658,  0.2131,  0.0000,  0.0000, -0.2370, -0.8950, -0.7000],\n",
            "        [-0.0588,  0.1256,  0.1803,  0.0000,  0.0000, -0.2966, -0.3493,  0.2333],\n",
            "        [-0.2941,  0.0000,  0.1148, -0.1717,  0.0000,  0.1624, -0.4458, -0.3333],\n",
            "        [-0.0588, -0.1558,  0.2131, -0.3737,  0.0000,  0.1416, -0.6763, -0.4000],\n",
            "        [-0.4118,  0.3970,  0.0492, -0.2929, -0.6690, -0.1475, -0.7156, -0.8333],\n",
            "        [-0.7647,  0.1256,  0.2787,  0.0101, -0.6690,  0.1744, -0.9172, -0.9000],\n",
            "        [ 0.0588,  0.0653, -0.1475,  0.0000,  0.0000, -0.0700, -0.7421, -0.3000],\n",
            "        [ 0.0000,  0.0754, -0.0164, -0.4949,  0.0000, -0.2131, -0.9530, -0.9333],\n",
            "        [-0.7647,  0.2965,  0.0000,  0.0000,  0.0000,  0.1475, -0.8070, -0.3333],\n",
            "        [-0.8824,  0.8995, -0.0164, -0.5354,  1.0000, -0.1028, -0.7267,  0.2667],\n",
            "        [-0.8824,  0.1759, -0.0164, -0.5354, -0.7494,  0.0075, -0.6687, -0.8000],\n",
            "        [-0.5294,  0.5879,  0.2787,  0.0000,  0.0000, -0.0194, -0.3809, -0.6667],\n",
            "        [ 0.0000,  0.0050,  0.1475, -0.4747, -0.8818, -0.0820, -0.5568,  0.0000],\n",
            "        [-0.5294,  0.3467,  0.1803,  0.0000,  0.0000, -0.2906, -0.8301,  0.3000]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.]])\n",
            "Epoch:15 | Inputs tensor([[ 0.0588,  0.3467,  0.2131, -0.3333, -0.8582, -0.2280, -0.6738,  1.0000],\n",
            "        [-0.4118,  0.5879,  0.3770, -0.1717, -0.5035,  0.1744, -0.7293, -0.7333],\n",
            "        [-0.8824,  0.1960,  0.4098, -0.2121, -0.4799,  0.3592, -0.3766, -0.7333],\n",
            "        [-0.8824, -0.2864,  0.2787,  0.0101, -0.8936, -0.0104, -0.7062,  0.0000],\n",
            "        [ 0.4118,  0.5176,  0.1475, -0.1919, -0.3593,  0.2459, -0.4330, -0.4333],\n",
            "        [-0.8824,  0.9698,  0.2459, -0.2727, -0.4113,  0.0879, -0.3194, -0.7333],\n",
            "        [ 0.0000,  0.4070,  0.0656, -0.4747, -0.6927,  0.2697, -0.6985, -0.9000],\n",
            "        [-0.4118,  0.2462,  0.2131,  0.0000,  0.0000,  0.0134, -0.8787, -0.4333],\n",
            "        [-0.7647,  0.7487,  0.4426, -0.2525, -0.7163,  0.3264, -0.5149, -0.9000],\n",
            "        [-0.8824, -0.0352,  1.0000,  0.0000,  0.0000, -0.3323, -0.8898, -0.8000],\n",
            "        [-0.4118, -0.1357,  0.1148, -0.4343, -0.8322, -0.0999, -0.7558, -0.9000],\n",
            "        [-0.6471,  0.0251, -0.2787, -0.5960, -0.7778, -0.0820, -0.7250, -0.8333],\n",
            "        [ 0.0000,  0.0653,  0.1475, -0.2525, -0.6501,  0.1744, -0.5500, -0.9667],\n",
            "        [-0.7647,  0.0854,  0.3115,  0.0000,  0.0000, -0.1952, -0.8454,  0.0333],\n",
            "        [-0.7647,  0.5578, -0.1475, -0.4545,  0.2766,  0.1535, -0.8617, -0.8667],\n",
            "        [-0.1765,  0.5276,  0.4426, -0.1111,  0.0000,  0.4903, -0.7788, -0.5000],\n",
            "        [ 0.2941,  0.3568,  0.0000,  0.0000,  0.0000,  0.5589, -0.5730, -0.3667],\n",
            "        [-0.7647,  0.2965,  0.2131, -0.4747, -0.5154, -0.0104, -0.5619, -0.8667],\n",
            "        [-0.8824,  0.7387,  0.2131,  0.0000,  0.0000,  0.0969, -0.9915, -0.4333],\n",
            "        [ 0.6471,  0.0050,  0.2787, -0.4949, -0.5650,  0.0909, -0.7148, -0.1667],\n",
            "        [ 0.0000, -0.0452,  0.3934, -0.4949, -0.9149,  0.1148, -0.8557, -0.9000],\n",
            "        [-0.4118,  0.8995,  0.0492, -0.3333, -0.2317, -0.0700, -0.5687, -0.7333],\n",
            "        [-0.7647, -0.1558, -0.1803, -0.5354, -0.8203, -0.0939, -0.2400,  0.0000],\n",
            "        [ 0.1765,  0.1558,  0.0000,  0.0000,  0.0000,  0.0000, -0.8437, -0.7000],\n",
            "        [-0.1765,  0.6181,  0.4098,  0.0000,  0.0000, -0.0939, -0.9257, -0.1333],\n",
            "        [-0.1765,  0.7990,  0.5574, -0.3737,  0.0000,  0.0194, -0.9266,  0.3000],\n",
            "        [-0.4118, -0.1156,  0.0820, -0.5758, -0.9456, -0.2727, -0.7746, -0.7000],\n",
            "        [-0.8824,  0.4472,  0.3443, -0.0707, -0.5745,  0.3741, -0.7805, -0.1667],\n",
            "        [-0.2941,  0.2965,  0.4754, -0.8586, -0.2293, -0.4158, -0.5696,  0.3000],\n",
            "        [ 0.0588,  0.4573,  0.4426, -0.3131, -0.6099, -0.0969, -0.4082,  0.0667],\n",
            "        [-0.4118,  0.0452,  0.2131,  0.0000,  0.0000, -0.1416, -0.9360, -0.1000],\n",
            "        [ 0.0000,  0.0452,  0.2459,  0.0000,  0.0000, -0.4516, -0.5696, -0.8000]]) | Labels tensor([[1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:16 | Inputs tensor([[-0.2941, -0.0151, -0.0492, -0.3333, -0.5508,  0.0134, -0.6994, -0.2667],\n",
            "        [-0.7647,  0.0050,  0.1475,  0.0505, -0.8652,  0.2072, -0.4885, -0.8667],\n",
            "        [-0.4118,  0.3668,  0.3770, -0.1717, -0.7920,  0.0432, -0.8224, -0.5333],\n",
            "        [ 0.0588,  0.4070,  0.5410,  0.0000,  0.0000, -0.0253, -0.4398, -0.2000],\n",
            "        [-0.8824,  0.3869,  0.3443,  0.0000,  0.0000,  0.1952, -0.8651, -0.7667],\n",
            "        [ 0.5294,  0.5377,  0.4426, -0.2525, -0.6690,  0.2101, -0.0640, -0.4000],\n",
            "        [-0.8824, -0.0955,  0.0164, -0.7576, -0.8983, -0.1893, -0.5713, -0.9000],\n",
            "        [-0.6471,  0.2060,  0.1475, -0.3939, -0.6809,  0.2787, -0.6806, -0.7000],\n",
            "        [-0.6471,  0.1156,  0.4754, -0.7576, -0.8156, -0.1535, -0.6439, -0.7333],\n",
            "        [-0.5294,  0.2965, -0.0164, -0.7576, -0.4539, -0.1803, -0.6166, -0.6667],\n",
            "        [-0.6471, -0.1055,  0.2131, -0.6768, -0.7991, -0.0939, -0.5961, -0.4333],\n",
            "        [-0.5294,  0.5477,  0.0164, -0.3737, -0.3286, -0.0224, -0.8642, -0.9333],\n",
            "        [-0.0588,  0.0050,  0.2131, -0.1919, -0.4917,  0.1744, -0.5021, -0.2667],\n",
            "        [-0.6471,  0.3266,  0.3115,  0.0000,  0.0000,  0.0253, -0.7233, -0.2333],\n",
            "        [-0.7647,  0.1055,  0.2131, -0.4141, -0.7045, -0.0343, -0.4705, -0.8000],\n",
            "        [-0.6471,  0.5879,  0.1475, -0.3939, -0.2246,  0.0581, -0.7728, -0.5333],\n",
            "        [-0.2941,  0.1457,  0.4426,  0.0000,  0.0000, -0.1714, -0.8557,  0.5000],\n",
            "        [-0.6471,  0.2965,  0.0492, -0.4141, -0.7281, -0.2131, -0.8796, -0.7667],\n",
            "        [-0.1765,  0.8794, -0.1803, -0.3333, -0.0733,  0.0104, -0.3612, -0.5667],\n",
            "        [-0.1765, -0.0251,  0.2459, -0.3535, -0.7849,  0.2191, -0.3228, -0.6333],\n",
            "        [-0.8824,  0.0854, -0.0164, -0.0707, -0.5792,  0.0581, -0.7122, -0.9000],\n",
            "        [-0.2941,  0.0452,  0.2131, -0.6364, -0.6312, -0.1088, -0.4500, -0.3333],\n",
            "        [-0.6471,  0.2362,  0.6393, -0.2929, -0.4326,  0.7079, -0.3151, -0.9667],\n",
            "        [-0.8824,  0.8191,  0.0492, -0.3939, -0.5745,  0.0164, -0.7865, -0.4333],\n",
            "        [-0.2941,  0.0251,  0.3443,  0.0000,  0.0000, -0.0820, -0.9129, -0.5000],\n",
            "        [-0.8824, -0.1156,  0.0164, -0.5152, -0.8960, -0.1088, -0.7062, -0.9333],\n",
            "        [-0.4118,  0.1156,  0.1803, -0.4343,  0.0000, -0.2876, -0.7190, -0.8000],\n",
            "        [-0.2941,  0.1558, -0.0164, -0.2121,  0.0000,  0.0045, -0.8574, -0.3667],\n",
            "        [-0.8824,  0.4673, -0.0820,  0.0000,  0.0000, -0.1148, -0.5850, -0.7333],\n",
            "        [-0.0588,  0.5578,  0.0164, -0.4747,  0.1702,  0.0134, -0.6029, -0.1667],\n",
            "        [-0.4118,  0.6281,  0.7049,  0.0000,  0.0000,  0.1237, -0.9377,  0.0333],\n",
            "        [ 0.1765,  0.6281,  0.3770,  0.0000,  0.0000, -0.1744, -0.9112,  0.1000]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.]])\n",
            "Epoch:17 | Inputs tensor([[-0.7647,  0.2060, -0.1148,  0.0000,  0.0000, -0.2012, -0.6781, -0.8000],\n",
            "        [ 0.0000,  0.7387,  0.2787, -0.3535, -0.3735,  0.3860, -0.0769,  0.2333],\n",
            "        [-0.7647,  0.0151, -0.0492, -0.6566, -0.3735, -0.2787, -0.5423, -0.9333],\n",
            "        [-0.5294,  0.1457,  0.0656,  0.0000,  0.0000, -0.3472, -0.6977, -0.4667],\n",
            "        [ 0.0000,  0.3467, -0.0492, -0.5960, -0.3121, -0.2131, -0.7660,  0.0000],\n",
            "        [-0.8824,  0.1156,  0.0164, -0.7374, -0.5697, -0.2846, -0.9488, -0.9333],\n",
            "        [ 0.0000,  0.1457,  0.3115, -0.3131, -0.3262,  0.3174, -0.9240, -0.8000],\n",
            "        [-0.1765,  0.5075,  0.0820, -0.1515, -0.1915,  0.0343, -0.4535, -0.3000],\n",
            "        [-0.8824, -0.1558,  0.0492, -0.5354, -0.7281,  0.0999, -0.6644, -0.7667],\n",
            "        [-0.7647,  0.4673,  0.1475, -0.2323, -0.1489, -0.1654, -0.7788, -0.7333],\n",
            "        [-0.5294, -0.1457, -0.0492, -0.5556, -0.8842, -0.1714, -0.8053, -0.7667],\n",
            "        [-0.0588, -0.0050,  0.3770,  0.0000,  0.0000,  0.0551, -0.7353, -0.0333],\n",
            "        [-0.8824, -0.2864,  0.0164,  0.0000,  0.0000, -0.3502, -0.7114, -0.8333],\n",
            "        [-0.8824, -0.0251,  0.1475, -0.1919,  0.0000,  0.1356, -0.8804, -0.7000],\n",
            "        [ 0.4118, -0.1558,  0.1803, -0.3737,  0.0000, -0.1148, -0.8130, -0.1667],\n",
            "        [-0.7647, -0.3166,  0.0164, -0.7374, -0.9645, -0.4009, -0.8471, -0.9333],\n",
            "        [-0.7647,  0.0050, -0.1148, -0.4343, -0.7518,  0.1267, -0.6413, -0.9000],\n",
            "        [-0.7647, -0.3166,  0.1475, -0.3535, -0.8440, -0.2548, -0.9069, -0.8667],\n",
            "        [-0.4118,  0.3769,  0.7705,  0.0000,  0.0000,  0.4545, -0.8728, -0.4667],\n",
            "        [-0.1765,  0.6884,  0.4426, -0.1515, -0.2411,  0.1386, -0.3945, -0.3667],\n",
            "        [-0.0588,  0.2663,  0.2131, -0.2323, -0.8227, -0.2280, -0.9283, -0.4000],\n",
            "        [-0.5294,  0.2563,  0.1475, -0.6364, -0.7116, -0.1386, -0.0897, -0.2000],\n",
            "        [-0.4118,  0.8794,  0.2459, -0.4545, -0.5106,  0.2996, -0.1836,  0.0667],\n",
            "        [ 0.1765,  0.2261,  0.1148,  0.0000,  0.0000, -0.0700, -0.8463, -0.3333],\n",
            "        [-0.6471,  0.7688,  0.4098, -0.4545, -0.6312, -0.0075, -0.0811,  0.0333],\n",
            "        [-0.8824,  0.2864,  0.4426, -0.2121, -0.7400,  0.0879, -0.1640, -0.4667],\n",
            "        [ 0.0000,  0.8090,  0.4754, -0.4747, -0.7872,  0.0879, -0.7985, -0.5333],\n",
            "        [-0.6471,  0.7085,  0.0492, -0.2525, -0.4681,  0.0283, -0.7626, -0.7000],\n",
            "        [ 0.0000,  0.3166,  0.4426,  0.0000,  0.0000, -0.0581, -0.4321, -0.6333],\n",
            "        [-0.5294,  0.4271,  0.4098,  0.0000,  0.0000,  0.3115, -0.5158, -0.9667],\n",
            "        [-0.4118,  0.5879,  0.1475,  0.0000,  0.0000, -0.1118, -0.8898,  0.4000],\n",
            "        [ 0.0000,  0.9900,  0.0820, -0.3535, -0.3522,  0.2310, -0.6379, -0.7667]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.]])\n",
            "Epoch:18 | Inputs tensor([[-0.8824,  0.0955, -0.0492, -0.6364, -0.7258, -0.1505, -0.8796, -0.9667],\n",
            "        [-0.0588,  0.1859,  0.1803, -0.6162,  0.0000, -0.3115,  0.1939, -0.1667],\n",
            "        [-0.5294,  0.1055,  0.2459, -0.5960, -0.7636, -0.1535, -0.9658, -0.8000],\n",
            "        [-0.8824,  0.1156,  0.4098, -0.6162,  0.0000, -0.1028, -0.9445, -0.9333],\n",
            "        [-0.4118,  0.6884,  0.0492,  0.0000,  0.0000, -0.0194, -0.9513, -0.3333],\n",
            "        [-0.6471,  0.5879,  0.0492, -0.7374, -0.0851, -0.0700, -0.8147, -0.9000],\n",
            "        [-0.8824, -0.0653,  0.1475, -0.3737,  0.0000, -0.0939, -0.7976, -0.9333],\n",
            "        [-0.6471,  0.2161, -0.1475,  0.0000,  0.0000,  0.0730, -0.9582, -0.8667],\n",
            "        [-0.7647, -0.0352,  0.1148, -0.7374, -0.8842, -0.3711, -0.5141, -0.8333],\n",
            "        [-0.6471,  0.7387,  0.2787, -0.2121, -0.5626,  0.0075, -0.2383, -0.6667],\n",
            "        [-0.4118,  0.0854,  0.1803, -0.1313, -0.8227,  0.0760, -0.8420, -0.6000],\n",
            "        [-0.8824,  0.8191,  0.2787, -0.1515, -0.3073,  0.1922,  0.0077, -0.9667],\n",
            "        [ 0.0000,  0.6281,  0.2459, -0.2727,  0.0000,  0.4784, -0.7558, -0.8333],\n",
            "        [-0.8824, -0.1357,  0.0820,  0.0505, -0.8463,  0.2310, -0.2835, -0.7333],\n",
            "        [-0.2941,  0.3467,  0.3115, -0.2525, -0.1253,  0.3770, -0.8634, -0.1667],\n",
            "        [-0.8824,  0.4372,  0.3770, -0.5354, -0.2671,  0.2638, -0.1477, -0.9667],\n",
            "        [-0.5294, -0.0452,  0.1475, -0.3535,  0.0000, -0.0432, -0.5440, -0.9000],\n",
            "        [ 0.0588,  0.6583,  0.4426,  0.0000,  0.0000, -0.0939, -0.8087, -0.0667],\n",
            "        [ 0.4118, -0.0754,  0.0164, -0.8586, -0.3901, -0.1773, -0.2758, -0.2333],\n",
            "        [-0.7647,  0.5578,  0.2131, -0.6566, -0.7731, -0.2072, -0.6968, -0.8000],\n",
            "        [-0.2941, -0.1457,  0.2787,  0.0000,  0.0000, -0.0700, -0.7404, -0.3000],\n",
            "        [ 0.0000,  0.2965,  0.3115,  0.0000,  0.0000, -0.0700, -0.4663, -0.7333],\n",
            "        [ 0.0000,  0.2362,  0.4426, -0.2525,  0.0000,  0.0492, -0.8984, -0.7333],\n",
            "        [-0.8824,  0.2161,  0.2787, -0.2121, -0.8251,  0.1624, -0.8437, -0.7667],\n",
            "        [-0.0588,  0.2663,  0.4426, -0.2727, -0.7447,  0.1475, -0.7686, -0.0667],\n",
            "        [ 0.0000,  0.3166,  0.0820, -0.1919,  0.0000,  0.0224, -0.8992, -0.9667],\n",
            "        [-0.4118,  0.1055,  0.1148,  0.0000,  0.0000, -0.2250, -0.8173, -0.7000],\n",
            "        [-0.8824,  0.9397, -0.1803, -0.6768, -0.1135, -0.2280, -0.5073, -0.9000],\n",
            "        [-0.5294,  0.0352, -0.0164, -0.3333, -0.5461, -0.2846, -0.2417, -0.6000],\n",
            "        [-0.6471, -0.2161,  0.1475,  0.0000,  0.0000, -0.0313, -0.8360, -0.4000],\n",
            "        [-0.0588,  0.2060,  0.2787,  0.0000,  0.0000, -0.2548, -0.7173,  0.4333],\n",
            "        [-0.1765,  0.4271, -0.0164, -0.3333, -0.5508, -0.1416, -0.4799,  0.3333]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:19 | Inputs tensor([[-0.1765,  0.9698,  0.4754,  0.0000,  0.0000,  0.1863, -0.6815, -0.3333],\n",
            "        [ 0.2941, -0.1457,  0.2131,  0.0000,  0.0000, -0.1028, -0.8104, -0.5333],\n",
            "        [-0.8824, -0.1658,  0.1148,  0.0000,  0.0000, -0.4575, -0.5337, -0.8000],\n",
            "        [-0.4118,  0.1256,  0.0820,  0.0000,  0.0000,  0.1267, -0.8437, -0.3333],\n",
            "        [-0.6471,  0.0653,  0.1803,  0.0000,  0.0000, -0.2310, -0.8898, -0.8000],\n",
            "        [-0.2941,  0.2563,  0.2787, -0.3737,  0.0000, -0.1773, -0.5841, -0.0667],\n",
            "        [-0.8824,  0.0000,  0.2131, -0.5960, -0.9456, -0.1744, -0.8113,  0.0000],\n",
            "        [-0.7647,  0.1457,  0.1148, -0.5556,  0.0000, -0.1446, -0.9880, -0.8667],\n",
            "        [-0.8824, -0.2261, -0.0820, -0.3939, -0.8676, -0.0075,  0.0017, -0.9000],\n",
            "        [-0.8824,  0.0050,  0.0820, -0.6970, -0.8676, -0.2966, -0.4979, -0.8333],\n",
            "        [-0.0588,  0.0553,  0.6393, -0.2727,  0.0000,  0.2906, -0.8625, -0.2000],\n",
            "        [ 0.0000,  0.4171,  0.3770, -0.4747,  0.0000, -0.0343, -0.6968, -0.9667],\n",
            "        [ 0.0000,  0.3769,  0.3770, -0.4545,  0.0000, -0.1863, -0.8693,  0.2667],\n",
            "        [-0.8824,  0.4975,  0.1148, -0.4141, -0.6998, -0.1267, -0.7686, -0.3000],\n",
            "        [-0.8824, -0.0251,  0.0492, -0.6162, -0.8061, -0.4575, -0.8113,  0.0000],\n",
            "        [-0.2941,  0.0553,  0.1475, -0.3535, -0.8392, -0.0820, -0.9624, -0.4667],\n",
            "        [-0.8824, -0.1960, -0.0984,  0.0000,  0.0000, -0.4307, -0.8463,  0.0000],\n",
            "        [-0.2941,  0.8392,  0.5410,  0.0000,  0.0000,  0.2161,  0.1810, -0.2000],\n",
            "        [ 0.0000,  0.5176,  0.4754, -0.0707,  0.0000,  0.2548, -0.7498,  0.0000],\n",
            "        [-0.5294,  0.8392,  0.0000,  0.0000,  0.0000, -0.1535, -0.8856, -0.5000],\n",
            "        [-0.7647,  0.0854,  0.0492,  0.0000,  0.0000, -0.0820, -0.9317,  0.0000],\n",
            "        [-0.5294, -0.0452,  0.0492,  0.0000,  0.0000, -0.0462, -0.9291, -0.6667],\n",
            "        [-0.2941,  0.4874,  0.1803, -0.2929,  0.0000,  0.0015, -0.5312, -0.0333],\n",
            "        [-0.6471,  0.6281, -0.1475, -0.2323,  0.0000,  0.1088, -0.5098, -0.9000],\n",
            "        [ 0.0000,  0.8090,  0.0820, -0.2121,  0.0000,  0.2519,  0.5500, -0.8667],\n",
            "        [-0.2941,  0.0352,  0.1803, -0.3535, -0.5508,  0.1237, -0.7899,  0.1333],\n",
            "        [-0.4118,  0.4774,  0.2295,  0.0000,  0.0000, -0.1088, -0.6960, -0.7667],\n",
            "        [-0.5294, -0.0754,  0.3115,  0.0000,  0.0000,  0.2578, -0.8642, -0.7333],\n",
            "        [ 0.0000,  0.6583,  0.4754, -0.3333,  0.6076,  0.5589, -0.7020, -0.9333],\n",
            "        [-0.7647,  0.4673,  0.0000,  0.0000,  0.0000, -0.1803, -0.8617, -0.7667],\n",
            "        [-0.7647,  0.2764, -0.0492, -0.5152, -0.3499, -0.1744,  0.2997, -0.8667],\n",
            "        [ 0.0000,  0.6281,  0.2459,  0.1313, -0.7636,  0.5857, -0.4184, -0.8667]]) | Labels tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.]])\n",
            "Epoch:20 | Inputs tensor([[-0.0588,  0.5176,  0.2787, -0.3535, -0.5035,  0.2787, -0.6260, -0.5000],\n",
            "        [-0.2941,  0.1156,  0.0492, -0.2121,  0.0000,  0.0194, -0.8446, -0.9000],\n",
            "        [-0.7647,  0.2563, -0.0164, -0.5960, -0.6690,  0.0075, -0.9915, -0.6667],\n",
            "        [ 0.0000, -0.0854,  0.3115,  0.0000,  0.0000, -0.0343, -0.5534, -0.8000],\n",
            "        [-0.4118,  0.3668,  0.3443,  0.0000,  0.0000,  0.0000, -0.5201,  0.6000],\n",
            "        [ 0.0588, -0.1055,  0.0164,  0.0000,  0.0000, -0.3294, -0.9453, -0.6000],\n",
            "        [-0.0588,  0.2563,  0.5738,  0.0000,  0.0000,  0.0000, -0.8685,  0.1000],\n",
            "        [ 0.2941,  0.3668,  0.3770, -0.2929, -0.6927, -0.1565, -0.8446, -0.3000],\n",
            "        [ 0.0000, -0.0251,  0.0492, -0.2727, -0.7636,  0.0969, -0.5542, -0.8667],\n",
            "        [-0.7647,  0.2261, -0.0164, -0.6364, -0.7494, -0.1118, -0.4543, -0.9667],\n",
            "        [ 0.0588,  0.7186,  0.8033, -0.5152, -0.4326,  0.3532, -0.4509,  0.1000],\n",
            "        [-0.4118,  0.2362,  0.2131, -0.1919, -0.8180,  0.0164, -0.8369, -0.7667],\n",
            "        [-0.7647,  0.2261,  0.1475, -0.4545,  0.0000,  0.0969, -0.7763, -0.8000],\n",
            "        [-0.8824,  0.0754,  0.1803, -0.3939, -0.8061, -0.0820, -0.3655, -0.9000],\n",
            "        [ 0.0000, -0.1357,  0.1148, -0.3535,  0.0000,  0.0671, -0.8634, -0.8667],\n",
            "        [ 0.5294,  0.0653,  0.1803,  0.0909,  0.0000,  0.0909, -0.9146, -0.2000],\n",
            "        [-0.4118,  0.1558,  0.6066,  0.0000,  0.0000,  0.5768, -0.8881, -0.7667],\n",
            "        [ 0.0000,  0.2362,  0.1803,  0.0000,  0.0000,  0.0820, -0.8463,  0.0333],\n",
            "        [ 0.0000,  0.3869,  0.0000,  0.0000,  0.0000,  0.0820, -0.2699, -0.8667],\n",
            "        [-0.7647, -0.0754,  0.2459, -0.5960,  0.0000, -0.2787,  0.3834, -0.7667],\n",
            "        [-0.2941,  0.9497,  0.2787,  0.0000,  0.0000, -0.2996, -0.9564,  0.2667],\n",
            "        [-0.4118,  0.4774,  0.2787,  0.0000,  0.0000,  0.0045, -0.8804,  0.4667],\n",
            "        [-0.8824, -0.0452, -0.0164, -0.6364, -0.8629, -0.2876, -0.8446, -0.9667],\n",
            "        [-0.6471, -0.1960,  0.3443, -0.3737, -0.8345,  0.0194,  0.0367, -0.8000],\n",
            "        [-0.0588, -0.0854,  0.3443,  0.0000,  0.0000,  0.0611, -0.5653,  0.5667],\n",
            "        [-0.8824,  0.0955, -0.3770, -0.6364, -0.7163, -0.3115, -0.7190, -0.8333],\n",
            "        [-0.8824, -0.1156,  0.2787, -0.4141, -0.8203, -0.0462, -0.7549, -0.7333],\n",
            "        [-0.7647,  0.4271,  0.3443, -0.6364, -0.8487, -0.2638, -0.4167,  0.0000],\n",
            "        [-0.0588,  0.8894,  0.2787,  0.0000,  0.0000,  0.4277, -0.9496, -0.2667],\n",
            "        [ 0.0000,  0.0553,  0.3770,  0.0000,  0.0000, -0.1684, -0.4338,  0.3667],\n",
            "        [ 0.1765,  0.1558,  0.0000,  0.0000,  0.0000,  0.0522, -0.9522, -0.7333],\n",
            "        [ 0.0000,  0.0251,  0.2787, -0.1919, -0.7872,  0.0283, -0.8634, -0.9000]]) | Labels tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:21 | Inputs tensor([[ 0.0000,  0.4573,  0.0000,  0.0000,  0.0000,  0.3174, -0.5286, -0.6667],\n",
            "        [-0.4118, -0.2663, -0.0164,  0.0000,  0.0000, -0.2012, -0.8377, -0.8000],\n",
            "        [ 0.0000,  0.8090,  0.2787,  0.2727, -0.9669,  0.7705,  1.0000, -0.8667],\n",
            "        [-0.0588, -0.3467,  0.1803, -0.5354,  0.0000, -0.0462, -0.5542, -0.3000],\n",
            "        [ 0.0000,  0.8894,  0.3443, -0.7172, -0.5626, -0.0462, -0.4842, -0.9667],\n",
            "        [-0.8824,  0.2663, -0.0164,  0.0000,  0.0000, -0.1028, -0.7686, -0.1333],\n",
            "        [-0.5294,  0.2362,  0.0164,  0.0000,  0.0000, -0.0462, -0.8736, -0.5333],\n",
            "        [ 0.0588,  0.4573,  0.3115, -0.0707, -0.6927,  0.1297, -0.5226, -0.3667],\n",
            "        [ 0.0588, -0.4271,  0.3115, -0.2525,  0.0000, -0.0224, -0.9846, -0.3333],\n",
            "        [-0.7647,  0.2362, -0.2131, -0.3535, -0.6099,  0.2548, -0.6225, -0.8333],\n",
            "        [-0.7647,  0.2261,  0.2459, -0.4545, -0.5272,  0.0700, -0.6541, -0.8333],\n",
            "        [-0.8824,  0.0754,  0.1148, -0.6162,  0.0000, -0.2101, -0.9257, -0.9000],\n",
            "        [-0.1765, -0.3769,  0.2787,  0.0000,  0.0000, -0.0283, -0.7327, -0.3333],\n",
            "        [-0.8824, -0.0955,  0.0164, -0.6364, -0.8605, -0.2519,  0.0162, -0.8667],\n",
            "        [-0.4118, -0.0050, -0.1148, -0.4343, -0.8038,  0.0134, -0.6405, -0.7000],\n",
            "        [-0.8824,  0.0955, -0.0164, -0.8384, -0.5697, -0.2429, -0.2579,  0.0000],\n",
            "        [-0.6471,  0.6382,  0.1475, -0.6364, -0.7518, -0.0581, -0.8377, -0.7667],\n",
            "        [-0.8824, -0.0854,  0.0492, -0.5152,  0.0000, -0.1297, -0.9026,  0.0000],\n",
            "        [-0.8824,  0.0000, -0.2131, -0.5960,  0.0000, -0.2638, -0.9471, -0.9667],\n",
            "        [ 0.0588,  0.7085,  0.2131, -0.3737,  0.0000,  0.3115, -0.7225, -0.2667],\n",
            "        [-0.6471,  0.0352,  0.1803, -0.3939, -0.6407, -0.1773, -0.4432, -0.8000],\n",
            "        [-0.6471,  0.7387,  0.3770, -0.3333,  0.1206,  0.0641, -0.8463, -0.9667],\n",
            "        [-0.1765,  0.0553,  0.0000,  0.0000,  0.0000,  0.0000, -0.8061, -0.9000],\n",
            "        [-0.5294, -0.0854,  0.1475, -0.3535, -0.7920, -0.0134, -0.6857, -0.9667],\n",
            "        [ 0.0000, -0.2663,  0.0000,  0.0000,  0.0000, -0.3711, -0.7746, -0.8667],\n",
            "        [-0.7647, -0.2462,  0.0492, -0.5152, -0.8700, -0.1148, -0.7506, -0.6000],\n",
            "        [-0.5294,  0.2362,  0.3115, -0.6970, -0.5839, -0.0462, -0.6883, -0.5667],\n",
            "        [-0.5294, -0.0251, -0.0164, -0.5354,  0.0000, -0.1595, -0.6883, -0.9667],\n",
            "        [-0.8824,  0.7286,  0.1148, -0.0101,  0.3688,  0.2638, -0.4671, -0.7667],\n",
            "        [-0.8824,  0.0553, -0.0492,  0.0000,  0.0000, -0.2757, -0.9069,  0.0000],\n",
            "        [-0.2941,  0.6683,  0.2131,  0.0000,  0.0000, -0.2072, -0.8070,  0.5000],\n",
            "        [-0.1765, -0.1658,  0.2787, -0.4747, -0.8322, -0.1267, -0.4116, -0.5000]]) | Labels tensor([[0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "Epoch:22 | Inputs tensor([[ 0.2941,  0.0352,  0.1148, -0.1919,  0.0000,  0.3770, -0.9590, -0.3000],\n",
            "        [-0.8824, -0.1256, -0.0164, -0.2525, -0.8227,  0.1088, -0.6319, -0.9667],\n",
            "        [-0.0588,  0.9497,  0.3115,  0.0000,  0.0000, -0.2221, -0.5961,  0.5333],\n",
            "        [-0.2941,  0.5176,  0.0164, -0.3737, -0.7163,  0.0581, -0.4757, -0.7667],\n",
            "        [ 0.0000,  0.2161,  0.0820, -0.3939, -0.6099,  0.0224, -0.8933, -0.6000],\n",
            "        [ 0.0588,  0.2362,  0.1475, -0.1111, -0.7778, -0.0134, -0.7472, -0.3667],\n",
            "        [-0.8824,  0.1658,  0.1475, -0.4343,  0.0000, -0.1833, -0.8924,  0.0000],\n",
            "        [ 0.0000,  0.1759,  0.3115, -0.3737, -0.8747,  0.3472, -0.9906, -0.9000],\n",
            "        [-0.8824,  0.1658,  0.2787, -0.4141, -0.5745,  0.0760, -0.6430, -0.8667],\n",
            "        [ 0.1765,  0.2965,  0.0164, -0.2727,  0.0000,  0.2280, -0.6900, -0.4333],\n",
            "        [ 0.0000, -0.0653,  0.6393, -0.2121, -0.8298,  0.2936, -0.1947, -0.5333],\n",
            "        [-0.8824,  0.0754, -0.1803, -0.6162,  0.0000, -0.1565, -0.9120, -0.7333],\n",
            "        [-0.4118,  0.2261,  0.4098,  0.0000,  0.0000,  0.0343, -0.8190, -0.6000],\n",
            "        [-0.1765,  0.0352,  0.0820, -0.3535,  0.0000,  0.1654, -0.7728, -0.6667],\n",
            "        [-0.7647, -0.0050,  0.1475, -0.6768, -0.8960, -0.3920, -0.8659, -0.8000],\n",
            "        [ 0.0000,  0.8995,  0.7049, -0.4949,  0.0000,  0.0224, -0.6951, -0.3333],\n",
            "        [ 0.1765,  0.0151,  0.4098, -0.2525,  0.0000,  0.3592, -0.0965, -0.4333],\n",
            "        [-0.8824, -0.2060, -0.0164, -0.1515, -0.8865,  0.2966, -0.4876, -0.9333],\n",
            "        [-0.5294,  0.2864,  0.1475,  0.0000,  0.0000,  0.0224, -0.8079, -0.9000],\n",
            "        [ 0.1765,  0.2965,  0.2459, -0.4343, -0.7116,  0.0700, -0.8275, -0.4000],\n",
            "        [-0.2941, -0.1960,  0.3115, -0.2727,  0.0000,  0.1863, -0.9155, -0.7667],\n",
            "        [-0.4118, -0.0050,  0.2131, -0.4545,  0.0000, -0.1356, -0.8933, -0.6333],\n",
            "        [-0.6471, -0.0050,  0.0164, -0.6162, -0.8251, -0.3502, -0.8284, -0.8333],\n",
            "        [-0.0588,  0.0955,  0.2459, -0.2121, -0.7305, -0.1684, -0.5201, -0.6667],\n",
            "        [ 0.0000,  0.3769, -0.3443, -0.2929, -0.6028,  0.2846,  0.8873, -0.6000],\n",
            "        [-0.8824, -0.2060,  0.3115, -0.4949, -0.9125, -0.2429, -0.5687, -0.9667],\n",
            "        [-0.6471,  0.0854,  0.0164, -0.5152,  0.0000, -0.2250, -0.8762, -0.8667],\n",
            "        [ 0.0000,  0.8191,  0.4426, -0.1111,  0.2057,  0.2906, -0.8770, -0.8333],\n",
            "        [-0.8824, -0.2663, -0.1803, -0.7980,  0.0000, -0.3145, -0.8548,  0.0000],\n",
            "        [-0.5294,  0.1759,  0.0492, -0.4545, -0.7163, -0.0104, -0.8702, -0.9000],\n",
            "        [ 0.5294,  0.2965,  0.0000, -0.3939,  0.0000,  0.1893, -0.5807, -0.2333],\n",
            "        [-0.2941,  0.0955, -0.0164, -0.4545,  0.0000, -0.2548, -0.8907, -0.8000]]) | Labels tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])\n",
            "Epoch:23 | Inputs tensor([[-0.8824,  0.1457,  0.0820, -0.2727, -0.5272,  0.1356, -0.8198,  0.0000],\n",
            "        [-0.7647,  0.0050,  0.0820, -0.5960, -0.7872, -0.0194, -0.3262, -0.7667],\n",
            "        [-0.8824,  0.1759,  0.4426, -0.5152, -0.6572,  0.0283, -0.7225, -0.3667],\n",
            "        [ 0.0000,  0.3769,  0.1475, -0.2323,  0.0000, -0.0104, -0.9214, -0.9667],\n",
            "        [-0.1765,  0.8492,  0.3770, -0.3333,  0.0000,  0.0581, -0.7635, -0.3333],\n",
            "        [-0.4118,  0.0000,  0.3115, -0.3535,  0.0000,  0.2221, -0.7711, -0.4667],\n",
            "        [ 0.0000,  0.0151,  0.2459,  0.0000,  0.0000,  0.0641, -0.8975, -0.8333],\n",
            "        [-0.2941,  0.6583,  0.1148, -0.4747, -0.6028,  0.0015, -0.5278, -0.0667],\n",
            "        [-0.7647,  0.9799,  0.1475, -0.0909,  0.2837, -0.0909, -0.9317,  0.0667],\n",
            "        [-0.2941, -0.0754,  0.5082,  0.0000,  0.0000, -0.4069, -0.9061, -0.7667],\n",
            "        [ 0.0000,  0.0452,  0.0492, -0.2525, -0.8487,  0.0015, -0.6311, -0.9667],\n",
            "        [-0.4118,  0.6683,  0.2459,  0.0000,  0.0000,  0.3621, -0.7763, -0.8000],\n",
            "        [-0.8824, -0.1055,  0.2459, -0.3131, -0.9125, -0.0700, -0.9026, -0.9333],\n",
            "        [ 0.1765, -0.2462,  0.3443,  0.0000,  0.0000, -0.0075, -0.8420, -0.4333],\n",
            "        [-0.0588,  0.0854,  0.1475,  0.0000,  0.0000, -0.0909, -0.2511, -0.6000],\n",
            "        [-0.8824, -0.1759,  0.0492, -0.7374, -0.7754, -0.3681, -0.7122, -0.9333],\n",
            "        [-0.7647, -0.0955,  0.1148, -0.1515,  0.0000,  0.1386, -0.6371, -0.8000],\n",
            "        [-0.8824,  0.1859, -0.0492, -0.2727, -0.7778, -0.0075, -0.8437, -0.9333],\n",
            "        [-0.1765,  0.5980,  0.0820,  0.0000,  0.0000, -0.0939, -0.7395, -0.5000],\n",
            "        [ 0.2941,  0.3869,  0.2131, -0.4747, -0.6596,  0.0760, -0.5909, -0.0333],\n",
            "        [-0.4118,  0.3970,  0.3115, -0.2929, -0.6217, -0.0581, -0.7583, -0.8667],\n",
            "        [-0.7647, -0.0653,  0.0492, -0.3535, -0.6217,  0.1326, -0.4910, -0.9333],\n",
            "        [ 0.0588,  0.1960,  0.3115, -0.2929,  0.0000, -0.1356, -0.8420, -0.7333]]) | Labels tensor([[1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]])\n",
            "Epoch 1 | Batch: 1 | Loss: 23.2212\n",
            "Epoch 1 | Batch: 2 | Loss: 19.8851\n",
            "Epoch 1 | Batch: 3 | Loss: 22.2599\n",
            "Epoch 1 | Batch: 4 | Loss: 20.9617\n",
            "Epoch 1 | Batch: 5 | Loss: 23.0547\n",
            "Epoch 1 | Batch: 6 | Loss: 20.3585\n",
            "Epoch 1 | Batch: 7 | Loss: 14.3361\n",
            "Epoch 1 | Batch: 8 | Loss: 25.7262\n",
            "Epoch 1 | Batch: 9 | Loss: 19.6967\n",
            "Epoch 1 | Batch: 10 | Loss: 24.4254\n",
            "Epoch 1 | Batch: 11 | Loss: 22.2662\n",
            "Epoch 1 | Batch: 12 | Loss: 19.2771\n",
            "Epoch 1 | Batch: 13 | Loss: 21.7688\n",
            "Epoch 1 | Batch: 14 | Loss: 19.5586\n",
            "Epoch 1 | Batch: 15 | Loss: 21.7376\n",
            "Epoch 1 | Batch: 16 | Loss: 22.3228\n",
            "Epoch 1 | Batch: 17 | Loss: 21.4840\n",
            "Epoch 1 | Batch: 18 | Loss: 26.0722\n",
            "Epoch 1 | Batch: 19 | Loss: 25.3863\n",
            "Epoch 1 | Batch: 20 | Loss: 22.1003\n",
            "Epoch 1 | Batch: 21 | Loss: 21.3133\n",
            "Epoch 1 | Batch: 22 | Loss: 19.5654\n",
            "Epoch 1 | Batch: 23 | Loss: 22.9143\n",
            "Epoch 1 | Batch: 24 | Loss: 15.4441\n",
            "Epoch 2 | Batch: 1 | Loss: 20.3639\n",
            "Epoch 2 | Batch: 2 | Loss: 22.3806\n",
            "Epoch 2 | Batch: 3 | Loss: 20.9857\n",
            "Epoch 2 | Batch: 4 | Loss: 17.8520\n",
            "Epoch 2 | Batch: 5 | Loss: 20.6021\n",
            "Epoch 2 | Batch: 6 | Loss: 19.8979\n",
            "Epoch 2 | Batch: 7 | Loss: 16.7406\n",
            "Epoch 2 | Batch: 8 | Loss: 23.9032\n",
            "Epoch 2 | Batch: 9 | Loss: 20.6597\n",
            "Epoch 2 | Batch: 10 | Loss: 21.2550\n",
            "Epoch 2 | Batch: 11 | Loss: 22.1714\n",
            "Epoch 2 | Batch: 12 | Loss: 21.4979\n",
            "Epoch 2 | Batch: 13 | Loss: 19.5548\n",
            "Epoch 2 | Batch: 14 | Loss: 20.9267\n",
            "Epoch 2 | Batch: 15 | Loss: 19.9560\n",
            "Epoch 2 | Batch: 16 | Loss: 23.0588\n",
            "Epoch 2 | Batch: 17 | Loss: 21.9412\n",
            "Epoch 2 | Batch: 18 | Loss: 21.1688\n",
            "Epoch 2 | Batch: 19 | Loss: 20.5967\n",
            "Epoch 2 | Batch: 20 | Loss: 21.8892\n",
            "Epoch 2 | Batch: 21 | Loss: 21.9795\n",
            "Epoch 2 | Batch: 22 | Loss: 20.0461\n",
            "Epoch 2 | Batch: 23 | Loss: 21.0546\n",
            "Epoch 2 | Batch: 24 | Loss: 18.4202\n",
            "Epoch 3 | Batch: 1 | Loss: 21.9820\n",
            "Epoch 3 | Batch: 2 | Loss: 20.8956\n",
            "Epoch 3 | Batch: 3 | Loss: 23.0682\n",
            "Epoch 3 | Batch: 4 | Loss: 21.2260\n",
            "Epoch 3 | Batch: 5 | Loss: 19.9365\n",
            "Epoch 3 | Batch: 6 | Loss: 19.0987\n",
            "Epoch 3 | Batch: 7 | Loss: 24.5776\n",
            "Epoch 3 | Batch: 8 | Loss: 21.8927\n",
            "Epoch 3 | Batch: 9 | Loss: 21.6158\n",
            "Epoch 3 | Batch: 10 | Loss: 20.4834\n",
            "Epoch 3 | Batch: 11 | Loss: 19.0918\n",
            "Epoch 3 | Batch: 12 | Loss: 25.4840\n",
            "Epoch 3 | Batch: 13 | Loss: 22.2076\n",
            "Epoch 3 | Batch: 14 | Loss: 22.1556\n",
            "Epoch 3 | Batch: 15 | Loss: 21.1756\n",
            "Epoch 3 | Batch: 16 | Loss: 20.1489\n",
            "Epoch 3 | Batch: 17 | Loss: 18.3529\n",
            "Epoch 3 | Batch: 18 | Loss: 22.1877\n",
            "Epoch 3 | Batch: 19 | Loss: 19.4957\n",
            "Epoch 3 | Batch: 20 | Loss: 14.5353\n",
            "Epoch 3 | Batch: 21 | Loss: 28.1935\n",
            "Epoch 3 | Batch: 22 | Loss: 20.2767\n",
            "Epoch 3 | Batch: 23 | Loss: 19.8787\n",
            "Epoch 3 | Batch: 24 | Loss: 16.5048\n",
            "Epoch 4 | Batch: 1 | Loss: 22.4881\n",
            "Epoch 4 | Batch: 2 | Loss: 21.8497\n",
            "Epoch 4 | Batch: 3 | Loss: 22.7252\n",
            "Epoch 4 | Batch: 4 | Loss: 22.1200\n",
            "Epoch 4 | Batch: 5 | Loss: 21.6125\n",
            "Epoch 4 | Batch: 6 | Loss: 20.0770\n",
            "Epoch 4 | Batch: 7 | Loss: 17.6016\n",
            "Epoch 4 | Batch: 8 | Loss: 21.4697\n",
            "Epoch 4 | Batch: 9 | Loss: 19.8776\n",
            "Epoch 4 | Batch: 10 | Loss: 20.6646\n",
            "Epoch 4 | Batch: 11 | Loss: 19.2643\n",
            "Epoch 4 | Batch: 12 | Loss: 19.0069\n",
            "Epoch 4 | Batch: 13 | Loss: 17.1511\n",
            "Epoch 4 | Batch: 14 | Loss: 27.4833\n",
            "Epoch 4 | Batch: 15 | Loss: 21.9808\n",
            "Epoch 4 | Batch: 16 | Loss: 21.6836\n",
            "Epoch 4 | Batch: 17 | Loss: 20.1342\n",
            "Epoch 4 | Batch: 18 | Loss: 20.7594\n",
            "Epoch 4 | Batch: 19 | Loss: 21.2770\n",
            "Epoch 4 | Batch: 20 | Loss: 18.5232\n",
            "Epoch 4 | Batch: 21 | Loss: 17.9989\n",
            "Epoch 4 | Batch: 22 | Loss: 26.8068\n",
            "Epoch 4 | Batch: 23 | Loss: 21.4355\n",
            "Epoch 4 | Batch: 24 | Loss: 14.8820\n",
            "Epoch 5 | Batch: 1 | Loss: 23.8949\n",
            "Epoch 5 | Batch: 2 | Loss: 22.0112\n",
            "Epoch 5 | Batch: 3 | Loss: 19.8415\n",
            "Epoch 5 | Batch: 4 | Loss: 15.1506\n",
            "Epoch 5 | Batch: 5 | Loss: 22.5526\n",
            "Epoch 5 | Batch: 6 | Loss: 19.0354\n",
            "Epoch 5 | Batch: 7 | Loss: 21.7684\n",
            "Epoch 5 | Batch: 8 | Loss: 21.1890\n",
            "Epoch 5 | Batch: 9 | Loss: 20.1271\n",
            "Epoch 5 | Batch: 10 | Loss: 18.3816\n",
            "Epoch 5 | Batch: 11 | Loss: 23.1010\n",
            "Epoch 5 | Batch: 12 | Loss: 21.6586\n",
            "Epoch 5 | Batch: 13 | Loss: 22.3928\n",
            "Epoch 5 | Batch: 14 | Loss: 21.9677\n",
            "Epoch 5 | Batch: 15 | Loss: 21.6868\n",
            "Epoch 5 | Batch: 16 | Loss: 22.3445\n",
            "Epoch 5 | Batch: 17 | Loss: 20.9441\n",
            "Epoch 5 | Batch: 18 | Loss: 21.1565\n",
            "Epoch 5 | Batch: 19 | Loss: 20.6157\n",
            "Epoch 5 | Batch: 20 | Loss: 21.2548\n",
            "Epoch 5 | Batch: 21 | Loss: 20.6390\n",
            "Epoch 5 | Batch: 22 | Loss: 19.9632\n",
            "Epoch 5 | Batch: 23 | Loss: 19.1166\n",
            "Epoch 5 | Batch: 24 | Loss: 12.3501\n",
            "Epoch 6 | Batch: 1 | Loss: 20.1792\n",
            "Epoch 6 | Batch: 2 | Loss: 19.8866\n",
            "Epoch 6 | Batch: 3 | Loss: 23.9025\n",
            "Epoch 6 | Batch: 4 | Loss: 21.7207\n",
            "Epoch 6 | Batch: 5 | Loss: 20.1595\n",
            "Epoch 6 | Batch: 6 | Loss: 21.5530\n",
            "Epoch 6 | Batch: 7 | Loss: 18.9024\n",
            "Epoch 6 | Batch: 8 | Loss: 20.9681\n",
            "Epoch 6 | Batch: 9 | Loss: 20.6052\n",
            "Epoch 6 | Batch: 10 | Loss: 22.5687\n",
            "Epoch 6 | Batch: 11 | Loss: 20.7149\n",
            "Epoch 6 | Batch: 12 | Loss: 19.1734\n",
            "Epoch 6 | Batch: 13 | Loss: 19.9118\n",
            "Epoch 6 | Batch: 14 | Loss: 17.4415\n",
            "Epoch 6 | Batch: 15 | Loss: 21.4084\n",
            "Epoch 6 | Batch: 16 | Loss: 22.1738\n",
            "Epoch 6 | Batch: 17 | Loss: 19.8682\n",
            "Epoch 6 | Batch: 18 | Loss: 21.5743\n",
            "Epoch 6 | Batch: 19 | Loss: 22.8956\n",
            "Epoch 6 | Batch: 20 | Loss: 21.0580\n",
            "Epoch 6 | Batch: 21 | Loss: 19.0553\n",
            "Epoch 6 | Batch: 22 | Loss: 23.5569\n",
            "Epoch 6 | Batch: 23 | Loss: 22.3381\n",
            "Epoch 6 | Batch: 24 | Loss: 15.3280\n",
            "Epoch 7 | Batch: 1 | Loss: 18.9299\n",
            "Epoch 7 | Batch: 2 | Loss: 20.9596\n",
            "Epoch 7 | Batch: 3 | Loss: 25.6350\n",
            "Epoch 7 | Batch: 4 | Loss: 23.1470\n",
            "Epoch 7 | Batch: 5 | Loss: 19.0927\n",
            "Epoch 7 | Batch: 6 | Loss: 19.0214\n",
            "Epoch 7 | Batch: 7 | Loss: 22.7059\n",
            "Epoch 7 | Batch: 8 | Loss: 20.1937\n",
            "Epoch 7 | Batch: 9 | Loss: 22.0781\n",
            "Epoch 7 | Batch: 10 | Loss: 21.1877\n",
            "Epoch 7 | Batch: 11 | Loss: 18.6747\n",
            "Epoch 7 | Batch: 12 | Loss: 16.9248\n",
            "Epoch 7 | Batch: 13 | Loss: 19.2124\n",
            "Epoch 7 | Batch: 14 | Loss: 26.1940\n",
            "Epoch 7 | Batch: 15 | Loss: 22.1273\n",
            "Epoch 7 | Batch: 16 | Loss: 20.9195\n",
            "Epoch 7 | Batch: 17 | Loss: 21.3725\n",
            "Epoch 7 | Batch: 18 | Loss: 21.4196\n",
            "Epoch 7 | Batch: 19 | Loss: 18.9216\n",
            "Epoch 7 | Batch: 20 | Loss: 22.8694\n",
            "Epoch 7 | Batch: 21 | Loss: 23.1750\n",
            "Epoch 7 | Batch: 22 | Loss: 21.6527\n",
            "Epoch 7 | Batch: 23 | Loss: 23.4729\n",
            "Epoch 7 | Batch: 24 | Loss: 15.4050\n",
            "Epoch 8 | Batch: 1 | Loss: 20.7862\n",
            "Epoch 8 | Batch: 2 | Loss: 20.5882\n",
            "Epoch 8 | Batch: 3 | Loss: 18.6652\n",
            "Epoch 8 | Batch: 4 | Loss: 16.0761\n",
            "Epoch 8 | Batch: 5 | Loss: 15.5089\n",
            "Epoch 8 | Batch: 6 | Loss: 18.2169\n",
            "Epoch 8 | Batch: 7 | Loss: 28.9130\n",
            "Epoch 8 | Batch: 8 | Loss: 21.6801\n",
            "Epoch 8 | Batch: 9 | Loss: 20.2645\n",
            "Epoch 8 | Batch: 10 | Loss: 22.0379\n",
            "Epoch 8 | Batch: 11 | Loss: 20.2865\n",
            "Epoch 8 | Batch: 12 | Loss: 24.1931\n",
            "Epoch 8 | Batch: 13 | Loss: 21.7588\n",
            "Epoch 8 | Batch: 14 | Loss: 18.4614\n",
            "Epoch 8 | Batch: 15 | Loss: 26.0943\n",
            "Epoch 8 | Batch: 16 | Loss: 19.8477\n",
            "Epoch 8 | Batch: 17 | Loss: 25.4353\n",
            "Epoch 8 | Batch: 18 | Loss: 21.2719\n",
            "Epoch 8 | Batch: 19 | Loss: 19.9205\n",
            "Epoch 8 | Batch: 20 | Loss: 20.6343\n",
            "Epoch 8 | Batch: 21 | Loss: 21.9324\n",
            "Epoch 8 | Batch: 22 | Loss: 21.1863\n",
            "Epoch 8 | Batch: 23 | Loss: 22.6569\n",
            "Epoch 8 | Batch: 24 | Loss: 15.2137\n",
            "Epoch 9 | Batch: 1 | Loss: 20.6195\n",
            "Epoch 9 | Batch: 2 | Loss: 22.4597\n",
            "Epoch 9 | Batch: 3 | Loss: 21.9399\n",
            "Epoch 9 | Batch: 4 | Loss: 21.3996\n",
            "Epoch 9 | Batch: 5 | Loss: 19.7654\n",
            "Epoch 9 | Batch: 6 | Loss: 16.5515\n",
            "Epoch 9 | Batch: 7 | Loss: 24.1972\n",
            "Epoch 9 | Batch: 8 | Loss: 21.7988\n",
            "Epoch 9 | Batch: 9 | Loss: 21.1944\n",
            "Epoch 9 | Batch: 10 | Loss: 21.1560\n",
            "Epoch 9 | Batch: 11 | Loss: 19.6305\n",
            "Epoch 9 | Batch: 12 | Loss: 19.0300\n",
            "Epoch 9 | Batch: 13 | Loss: 21.7340\n",
            "Epoch 9 | Batch: 14 | Loss: 23.0155\n",
            "Epoch 9 | Batch: 15 | Loss: 20.9075\n",
            "Epoch 9 | Batch: 16 | Loss: 22.9934\n",
            "Epoch 9 | Batch: 17 | Loss: 19.1090\n",
            "Epoch 9 | Batch: 18 | Loss: 21.3902\n",
            "Epoch 9 | Batch: 19 | Loss: 21.4341\n",
            "Epoch 9 | Batch: 20 | Loss: 19.4535\n",
            "Epoch 9 | Batch: 21 | Loss: 21.5726\n",
            "Epoch 9 | Batch: 22 | Loss: 21.1823\n",
            "Epoch 9 | Batch: 23 | Loss: 19.5710\n",
            "Epoch 9 | Batch: 24 | Loss: 14.9654\n",
            "Epoch 10 | Batch: 1 | Loss: 19.8752\n",
            "Epoch 10 | Batch: 2 | Loss: 17.5387\n",
            "Epoch 10 | Batch: 3 | Loss: 17.9732\n",
            "Epoch 10 | Batch: 4 | Loss: 27.9068\n",
            "Epoch 10 | Batch: 5 | Loss: 22.1054\n",
            "Epoch 10 | Batch: 6 | Loss: 21.8572\n",
            "Epoch 10 | Batch: 7 | Loss: 21.9470\n",
            "Epoch 10 | Batch: 8 | Loss: 20.0445\n",
            "Epoch 10 | Batch: 9 | Loss: 17.0114\n",
            "Epoch 10 | Batch: 10 | Loss: 19.1665\n",
            "Epoch 10 | Batch: 11 | Loss: 22.0723\n",
            "Epoch 10 | Batch: 12 | Loss: 20.5719\n",
            "Epoch 10 | Batch: 13 | Loss: 19.9301\n",
            "Epoch 10 | Batch: 14 | Loss: 24.3674\n",
            "Epoch 10 | Batch: 15 | Loss: 21.4217\n",
            "Epoch 10 | Batch: 16 | Loss: 19.2429\n",
            "Epoch 10 | Batch: 17 | Loss: 21.6106\n",
            "Epoch 10 | Batch: 18 | Loss: 19.9743\n",
            "Epoch 10 | Batch: 19 | Loss: 21.3490\n",
            "Epoch 10 | Batch: 20 | Loss: 21.7392\n",
            "Epoch 10 | Batch: 21 | Loss: 20.7612\n",
            "Epoch 10 | Batch: 22 | Loss: 21.7748\n",
            "Epoch 10 | Batch: 23 | Loss: 20.7478\n",
            "Epoch 10 | Batch: 24 | Loss: 13.6404\n",
            "Epoch 11 | Batch: 1 | Loss: 23.1848\n",
            "Epoch 11 | Batch: 2 | Loss: 21.2042\n",
            "Epoch 11 | Batch: 3 | Loss: 20.6513\n",
            "Epoch 11 | Batch: 4 | Loss: 22.4185\n",
            "Epoch 11 | Batch: 5 | Loss: 20.3318\n",
            "Epoch 11 | Batch: 6 | Loss: 19.8453\n",
            "Epoch 11 | Batch: 7 | Loss: 21.4197\n",
            "Epoch 11 | Batch: 8 | Loss: 20.5757\n",
            "Epoch 11 | Batch: 9 | Loss: 17.4086\n",
            "Epoch 11 | Batch: 10 | Loss: 19.1622\n",
            "Epoch 11 | Batch: 11 | Loss: 23.0739\n",
            "Epoch 11 | Batch: 12 | Loss: 20.0877\n",
            "Epoch 11 | Batch: 13 | Loss: 19.1132\n",
            "Epoch 11 | Batch: 14 | Loss: 21.6486\n",
            "Epoch 11 | Batch: 15 | Loss: 21.1793\n",
            "Epoch 11 | Batch: 16 | Loss: 19.5582\n",
            "Epoch 11 | Batch: 17 | Loss: 21.4909\n",
            "Epoch 11 | Batch: 18 | Loss: 20.5554\n",
            "Epoch 11 | Batch: 19 | Loss: 19.2718\n",
            "Epoch 11 | Batch: 20 | Loss: 19.8325\n",
            "Epoch 11 | Batch: 21 | Loss: 23.8807\n",
            "Epoch 11 | Batch: 22 | Loss: 22.3921\n",
            "Epoch 11 | Batch: 23 | Loss: 21.8893\n",
            "Epoch 11 | Batch: 24 | Loss: 14.1702\n",
            "Epoch 12 | Batch: 1 | Loss: 23.5536\n",
            "Epoch 12 | Batch: 2 | Loss: 21.8589\n",
            "Epoch 12 | Batch: 3 | Loss: 20.6347\n",
            "Epoch 12 | Batch: 4 | Loss: 22.9822\n",
            "Epoch 12 | Batch: 5 | Loss: 21.5506\n",
            "Epoch 12 | Batch: 6 | Loss: 19.2758\n",
            "Epoch 12 | Batch: 7 | Loss: 17.9226\n",
            "Epoch 12 | Batch: 8 | Loss: 14.7406\n",
            "Epoch 12 | Batch: 9 | Loss: 23.8631\n",
            "Epoch 12 | Batch: 10 | Loss: 21.3609\n",
            "Epoch 12 | Batch: 11 | Loss: 22.2444\n",
            "Epoch 12 | Batch: 12 | Loss: 20.0560\n",
            "Epoch 12 | Batch: 13 | Loss: 19.8375\n",
            "Epoch 12 | Batch: 14 | Loss: 22.2250\n",
            "Epoch 12 | Batch: 15 | Loss: 22.9773\n",
            "Epoch 12 | Batch: 16 | Loss: 21.9650\n",
            "Epoch 12 | Batch: 17 | Loss: 20.4349\n",
            "Epoch 12 | Batch: 18 | Loss: 21.6674\n",
            "Epoch 12 | Batch: 19 | Loss: 21.0620\n",
            "Epoch 12 | Batch: 20 | Loss: 20.4976\n",
            "Epoch 12 | Batch: 21 | Loss: 17.9359\n",
            "Epoch 12 | Batch: 22 | Loss: 13.4667\n",
            "Epoch 12 | Batch: 23 | Loss: 26.2097\n",
            "Epoch 12 | Batch: 24 | Loss: 17.5717\n",
            "Epoch 13 | Batch: 1 | Loss: 21.1849\n",
            "Epoch 13 | Batch: 2 | Loss: 20.5342\n",
            "Epoch 13 | Batch: 3 | Loss: 23.0036\n",
            "Epoch 13 | Batch: 4 | Loss: 21.1374\n",
            "Epoch 13 | Batch: 5 | Loss: 18.0494\n",
            "Epoch 13 | Batch: 6 | Loss: 15.6859\n",
            "Epoch 13 | Batch: 7 | Loss: 21.8403\n",
            "Epoch 13 | Batch: 8 | Loss: 20.5829\n",
            "Epoch 13 | Batch: 9 | Loss: 17.7920\n",
            "Epoch 13 | Batch: 10 | Loss: 24.4069\n",
            "Epoch 13 | Batch: 11 | Loss: 19.3001\n",
            "Epoch 13 | Batch: 12 | Loss: 24.3914\n",
            "Epoch 13 | Batch: 13 | Loss: 21.1033\n",
            "Epoch 13 | Batch: 14 | Loss: 22.9092\n",
            "Epoch 13 | Batch: 15 | Loss: 21.9713\n",
            "Epoch 13 | Batch: 16 | Loss: 21.1655\n",
            "Epoch 13 | Batch: 17 | Loss: 22.3365\n",
            "Epoch 13 | Batch: 18 | Loss: 20.6953\n",
            "Epoch 13 | Batch: 19 | Loss: 21.4360\n",
            "Epoch 13 | Batch: 20 | Loss: 19.2914\n",
            "Epoch 13 | Batch: 21 | Loss: 20.5180\n",
            "Epoch 13 | Batch: 22 | Loss: 18.7969\n",
            "Epoch 13 | Batch: 23 | Loss: 20.5011\n",
            "Epoch 13 | Batch: 24 | Loss: 13.1654\n",
            "Epoch 14 | Batch: 1 | Loss: 20.3018\n",
            "Epoch 14 | Batch: 2 | Loss: 18.1031\n",
            "Epoch 14 | Batch: 3 | Loss: 20.8719\n",
            "Epoch 14 | Batch: 4 | Loss: 21.3997\n",
            "Epoch 14 | Batch: 5 | Loss: 19.6835\n",
            "Epoch 14 | Batch: 6 | Loss: 20.5778\n",
            "Epoch 14 | Batch: 7 | Loss: 21.6709\n",
            "Epoch 14 | Batch: 8 | Loss: 19.9194\n",
            "Epoch 14 | Batch: 9 | Loss: 22.1693\n",
            "Epoch 14 | Batch: 10 | Loss: 20.0080\n",
            "Epoch 14 | Batch: 11 | Loss: 20.0642\n",
            "Epoch 14 | Batch: 12 | Loss: 18.8730\n",
            "Epoch 14 | Batch: 13 | Loss: 21.9482\n",
            "Epoch 14 | Batch: 14 | Loss: 21.1600\n",
            "Epoch 14 | Batch: 15 | Loss: 20.5894\n",
            "Epoch 14 | Batch: 16 | Loss: 21.6794\n",
            "Epoch 14 | Batch: 17 | Loss: 20.2653\n",
            "Epoch 14 | Batch: 18 | Loss: 21.4655\n",
            "Epoch 14 | Batch: 19 | Loss: 18.3248\n",
            "Epoch 14 | Batch: 20 | Loss: 15.8794\n",
            "Epoch 14 | Batch: 21 | Loss: 21.7680\n",
            "Epoch 14 | Batch: 22 | Loss: 18.9891\n",
            "Epoch 14 | Batch: 23 | Loss: 17.4772\n",
            "Epoch 14 | Batch: 24 | Loss: 13.9613\n",
            "Epoch 15 | Batch: 1 | Loss: 20.2378\n",
            "Epoch 15 | Batch: 2 | Loss: 19.0330\n",
            "Epoch 15 | Batch: 3 | Loss: 23.3060\n",
            "Epoch 15 | Batch: 4 | Loss: 21.3938\n",
            "Epoch 15 | Batch: 5 | Loss: 21.4350\n",
            "Epoch 15 | Batch: 6 | Loss: 18.7438\n",
            "Epoch 15 | Batch: 7 | Loss: 17.1667\n",
            "Epoch 15 | Batch: 8 | Loss: 16.0309\n",
            "Epoch 15 | Batch: 9 | Loss: 18.8929\n",
            "Epoch 15 | Batch: 10 | Loss: 16.5263\n",
            "Epoch 15 | Batch: 11 | Loss: 17.9150\n",
            "Epoch 15 | Batch: 12 | Loss: 20.9512\n",
            "Epoch 15 | Batch: 13 | Loss: 19.6055\n",
            "Epoch 15 | Batch: 14 | Loss: 14.9714\n",
            "Epoch 15 | Batch: 15 | Loss: 20.9318\n",
            "Epoch 15 | Batch: 16 | Loss: 19.7982\n",
            "Epoch 15 | Batch: 17 | Loss: 23.1097\n",
            "Epoch 15 | Batch: 18 | Loss: 20.4846\n",
            "Epoch 15 | Batch: 19 | Loss: 14.3729\n",
            "Epoch 15 | Batch: 20 | Loss: 23.9746\n",
            "Epoch 15 | Batch: 21 | Loss: 22.3633\n",
            "Epoch 15 | Batch: 22 | Loss: 18.2189\n",
            "Epoch 15 | Batch: 23 | Loss: 21.5360\n",
            "Epoch 15 | Batch: 24 | Loss: 15.9130\n",
            "Epoch 16 | Batch: 1 | Loss: 17.1392\n",
            "Epoch 16 | Batch: 2 | Loss: 16.9337\n",
            "Epoch 16 | Batch: 3 | Loss: 14.6455\n",
            "Epoch 16 | Batch: 4 | Loss: 17.5530\n",
            "Epoch 16 | Batch: 5 | Loss: 14.6067\n",
            "Epoch 16 | Batch: 6 | Loss: 17.3832\n",
            "Epoch 16 | Batch: 7 | Loss: 18.1705\n",
            "Epoch 16 | Batch: 8 | Loss: 21.5815\n",
            "Epoch 16 | Batch: 9 | Loss: 16.5119\n",
            "Epoch 16 | Batch: 10 | Loss: 14.8005\n",
            "Epoch 16 | Batch: 11 | Loss: 14.6112\n",
            "Epoch 16 | Batch: 12 | Loss: 14.3251\n",
            "Epoch 16 | Batch: 13 | Loss: 24.2544\n",
            "Epoch 16 | Batch: 14 | Loss: 17.6612\n",
            "Epoch 16 | Batch: 15 | Loss: 16.9226\n",
            "Epoch 16 | Batch: 16 | Loss: 15.8461\n",
            "Epoch 16 | Batch: 17 | Loss: 15.8253\n",
            "Epoch 16 | Batch: 18 | Loss: 17.6350\n",
            "Epoch 16 | Batch: 19 | Loss: 17.3110\n",
            "Epoch 16 | Batch: 20 | Loss: 15.5300\n",
            "Epoch 16 | Batch: 21 | Loss: 18.6294\n",
            "Epoch 16 | Batch: 22 | Loss: 17.2304\n",
            "Epoch 16 | Batch: 23 | Loss: 16.4148\n",
            "Epoch 16 | Batch: 24 | Loss: 11.8780\n",
            "Epoch 17 | Batch: 1 | Loss: 20.7706\n",
            "Epoch 17 | Batch: 2 | Loss: 16.4150\n",
            "Epoch 17 | Batch: 3 | Loss: 25.8494\n",
            "Epoch 17 | Batch: 4 | Loss: 14.8253\n",
            "Epoch 17 | Batch: 5 | Loss: 13.2424\n",
            "Epoch 17 | Batch: 6 | Loss: 20.2902\n",
            "Epoch 17 | Batch: 7 | Loss: 16.4139\n",
            "Epoch 17 | Batch: 8 | Loss: 24.4341\n",
            "Epoch 17 | Batch: 9 | Loss: 22.4092\n",
            "Epoch 17 | Batch: 10 | Loss: 15.4954\n",
            "Epoch 17 | Batch: 11 | Loss: 14.4964\n",
            "Epoch 17 | Batch: 12 | Loss: 16.1622\n",
            "Epoch 17 | Batch: 13 | Loss: 16.8456\n",
            "Epoch 17 | Batch: 14 | Loss: 14.1825\n",
            "Epoch 17 | Batch: 15 | Loss: 16.7391\n",
            "Epoch 17 | Batch: 16 | Loss: 23.0654\n",
            "Epoch 17 | Batch: 17 | Loss: 12.8718\n",
            "Epoch 17 | Batch: 18 | Loss: 15.3593\n",
            "Epoch 17 | Batch: 19 | Loss: 11.6064\n",
            "Epoch 17 | Batch: 20 | Loss: 12.6008\n",
            "Epoch 17 | Batch: 21 | Loss: 13.0697\n",
            "Epoch 17 | Batch: 22 | Loss: 16.9135\n",
            "Epoch 17 | Batch: 23 | Loss: 20.1003\n",
            "Epoch 17 | Batch: 24 | Loss: 10.5396\n",
            "Epoch 18 | Batch: 1 | Loss: 16.3067\n",
            "Epoch 18 | Batch: 2 | Loss: 10.3260\n",
            "Epoch 18 | Batch: 3 | Loss: 9.7878\n",
            "Epoch 18 | Batch: 4 | Loss: 18.9421\n",
            "Epoch 18 | Batch: 5 | Loss: 19.6816\n",
            "Epoch 18 | Batch: 6 | Loss: 14.6616\n",
            "Epoch 18 | Batch: 7 | Loss: 18.2243\n",
            "Epoch 18 | Batch: 8 | Loss: 21.6548\n",
            "Epoch 18 | Batch: 9 | Loss: 18.9539\n",
            "Epoch 18 | Batch: 10 | Loss: 14.7451\n",
            "Epoch 18 | Batch: 11 | Loss: 16.3968\n",
            "Epoch 18 | Batch: 12 | Loss: 20.2541\n",
            "Epoch 18 | Batch: 13 | Loss: 14.4042\n",
            "Epoch 18 | Batch: 14 | Loss: 18.4484\n",
            "Epoch 18 | Batch: 15 | Loss: 10.4509\n",
            "Epoch 18 | Batch: 16 | Loss: 16.5772\n",
            "Epoch 18 | Batch: 17 | Loss: 19.9056\n",
            "Epoch 18 | Batch: 18 | Loss: 18.3390\n",
            "Epoch 18 | Batch: 19 | Loss: 13.9315\n",
            "Epoch 18 | Batch: 20 | Loss: 13.7792\n",
            "Epoch 18 | Batch: 21 | Loss: 14.4768\n",
            "Epoch 18 | Batch: 22 | Loss: 15.4021\n",
            "Epoch 18 | Batch: 23 | Loss: 15.2792\n",
            "Epoch 18 | Batch: 24 | Loss: 13.5263\n",
            "Epoch 19 | Batch: 1 | Loss: 18.3283\n",
            "Epoch 19 | Batch: 2 | Loss: 20.9329\n",
            "Epoch 19 | Batch: 3 | Loss: 12.4632\n",
            "Epoch 19 | Batch: 4 | Loss: 13.6397\n",
            "Epoch 19 | Batch: 5 | Loss: 19.1387\n",
            "Epoch 19 | Batch: 6 | Loss: 12.7971\n",
            "Epoch 19 | Batch: 7 | Loss: 12.4035\n",
            "Epoch 19 | Batch: 8 | Loss: 19.7831\n",
            "Epoch 19 | Batch: 9 | Loss: 18.3171\n",
            "Epoch 19 | Batch: 10 | Loss: 21.5214\n",
            "Epoch 19 | Batch: 11 | Loss: 16.3222\n",
            "Epoch 19 | Batch: 12 | Loss: 10.2127\n",
            "Epoch 19 | Batch: 13 | Loss: 14.7899\n",
            "Epoch 19 | Batch: 14 | Loss: 9.6177\n",
            "Epoch 19 | Batch: 15 | Loss: 15.0879\n",
            "Epoch 19 | Batch: 16 | Loss: 13.3774\n",
            "Epoch 19 | Batch: 17 | Loss: 15.3779\n",
            "Epoch 19 | Batch: 18 | Loss: 19.5471\n",
            "Epoch 19 | Batch: 19 | Loss: 17.6390\n",
            "Epoch 19 | Batch: 20 | Loss: 17.8585\n",
            "Epoch 19 | Batch: 21 | Loss: 22.2351\n",
            "Epoch 19 | Batch: 22 | Loss: 19.4489\n",
            "Epoch 19 | Batch: 23 | Loss: 17.6380\n",
            "Epoch 19 | Batch: 24 | Loss: 13.9681\n",
            "Epoch 20 | Batch: 1 | Loss: 15.2938\n",
            "Epoch 20 | Batch: 2 | Loss: 15.6978\n",
            "Epoch 20 | Batch: 3 | Loss: 19.7015\n",
            "Epoch 20 | Batch: 4 | Loss: 15.5790\n",
            "Epoch 20 | Batch: 5 | Loss: 12.6210\n",
            "Epoch 20 | Batch: 6 | Loss: 18.9462\n",
            "Epoch 20 | Batch: 7 | Loss: 18.1279\n",
            "Epoch 20 | Batch: 8 | Loss: 21.2829\n",
            "Epoch 20 | Batch: 9 | Loss: 21.8812\n",
            "Epoch 20 | Batch: 10 | Loss: 12.2214\n",
            "Epoch 20 | Batch: 11 | Loss: 10.3479\n",
            "Epoch 20 | Batch: 12 | Loss: 20.5051\n",
            "Epoch 20 | Batch: 13 | Loss: 17.0434\n",
            "Epoch 20 | Batch: 14 | Loss: 15.8193\n",
            "Epoch 20 | Batch: 15 | Loss: 15.0557\n",
            "Epoch 20 | Batch: 16 | Loss: 14.0538\n",
            "Epoch 20 | Batch: 17 | Loss: 15.3285\n",
            "Epoch 20 | Batch: 18 | Loss: 14.4006\n",
            "Epoch 20 | Batch: 19 | Loss: 16.1037\n",
            "Epoch 20 | Batch: 20 | Loss: 14.4230\n",
            "Epoch 20 | Batch: 21 | Loss: 18.2293\n",
            "Epoch 20 | Batch: 22 | Loss: 17.1131\n",
            "Epoch 20 | Batch: 23 | Loss: 17.0385\n",
            "Epoch 20 | Batch: 24 | Loss: 9.9100\n",
            "Epoch 21 | Batch: 1 | Loss: 16.5263\n",
            "Epoch 21 | Batch: 2 | Loss: 15.5362\n",
            "Epoch 21 | Batch: 3 | Loss: 14.4072\n",
            "Epoch 21 | Batch: 4 | Loss: 14.4939\n",
            "Epoch 21 | Batch: 5 | Loss: 18.1185\n",
            "Epoch 21 | Batch: 6 | Loss: 17.6959\n",
            "Epoch 21 | Batch: 7 | Loss: 18.7684\n",
            "Epoch 21 | Batch: 8 | Loss: 14.7953\n",
            "Epoch 21 | Batch: 9 | Loss: 16.6847\n",
            "Epoch 21 | Batch: 10 | Loss: 18.3577\n",
            "Epoch 21 | Batch: 11 | Loss: 15.2383\n",
            "Epoch 21 | Batch: 12 | Loss: 19.6065\n",
            "Epoch 21 | Batch: 13 | Loss: 15.2242\n",
            "Epoch 21 | Batch: 14 | Loss: 15.7578\n",
            "Epoch 21 | Batch: 15 | Loss: 14.4573\n",
            "Epoch 21 | Batch: 16 | Loss: 15.6264\n",
            "Epoch 21 | Batch: 17 | Loss: 10.5693\n",
            "Epoch 21 | Batch: 18 | Loss: 13.0634\n",
            "Epoch 21 | Batch: 19 | Loss: 19.7708\n",
            "Epoch 21 | Batch: 20 | Loss: 15.4616\n",
            "Epoch 21 | Batch: 21 | Loss: 17.8265\n",
            "Epoch 21 | Batch: 22 | Loss: 13.2409\n",
            "Epoch 21 | Batch: 23 | Loss: 16.5662\n",
            "Epoch 21 | Batch: 24 | Loss: 14.7494\n",
            "Epoch 22 | Batch: 1 | Loss: 13.0061\n",
            "Epoch 22 | Batch: 2 | Loss: 18.2846\n",
            "Epoch 22 | Batch: 3 | Loss: 15.9697\n",
            "Epoch 22 | Batch: 4 | Loss: 15.6725\n",
            "Epoch 22 | Batch: 5 | Loss: 14.0117\n",
            "Epoch 22 | Batch: 6 | Loss: 10.7222\n",
            "Epoch 22 | Batch: 7 | Loss: 14.3759\n",
            "Epoch 22 | Batch: 8 | Loss: 11.5067\n",
            "Epoch 22 | Batch: 9 | Loss: 16.5799\n",
            "Epoch 22 | Batch: 10 | Loss: 19.9827\n",
            "Epoch 22 | Batch: 11 | Loss: 23.5202\n",
            "Epoch 22 | Batch: 12 | Loss: 16.1336\n",
            "Epoch 22 | Batch: 13 | Loss: 16.2715\n",
            "Epoch 22 | Batch: 14 | Loss: 19.6407\n",
            "Epoch 22 | Batch: 15 | Loss: 22.7265\n",
            "Epoch 22 | Batch: 16 | Loss: 18.9495\n",
            "Epoch 22 | Batch: 17 | Loss: 19.4894\n",
            "Epoch 22 | Batch: 18 | Loss: 20.8320\n",
            "Epoch 22 | Batch: 19 | Loss: 15.8883\n",
            "Epoch 22 | Batch: 20 | Loss: 12.9263\n",
            "Epoch 22 | Batch: 21 | Loss: 13.9224\n",
            "Epoch 22 | Batch: 22 | Loss: 12.0778\n",
            "Epoch 22 | Batch: 23 | Loss: 12.3943\n",
            "Epoch 22 | Batch: 24 | Loss: 14.1484\n",
            "Epoch 23 | Batch: 1 | Loss: 20.7607\n",
            "Epoch 23 | Batch: 2 | Loss: 21.0247\n",
            "Epoch 23 | Batch: 3 | Loss: 17.8217\n",
            "Epoch 23 | Batch: 4 | Loss: 17.3819\n",
            "Epoch 23 | Batch: 5 | Loss: 13.8856\n",
            "Epoch 23 | Batch: 6 | Loss: 16.3975\n",
            "Epoch 23 | Batch: 7 | Loss: 12.8872\n",
            "Epoch 23 | Batch: 8 | Loss: 19.5153\n",
            "Epoch 23 | Batch: 9 | Loss: 12.9510\n",
            "Epoch 23 | Batch: 10 | Loss: 11.6203\n",
            "Epoch 23 | Batch: 11 | Loss: 11.9951\n",
            "Epoch 23 | Batch: 12 | Loss: 14.7916\n",
            "Epoch 23 | Batch: 13 | Loss: 21.0069\n",
            "Epoch 23 | Batch: 14 | Loss: 14.6447\n",
            "Epoch 23 | Batch: 15 | Loss: 14.0919\n",
            "Epoch 23 | Batch: 16 | Loss: 19.0577\n",
            "Epoch 23 | Batch: 17 | Loss: 12.7275\n",
            "Epoch 23 | Batch: 18 | Loss: 12.3305\n",
            "Epoch 23 | Batch: 19 | Loss: 20.6741\n",
            "Epoch 23 | Batch: 20 | Loss: 14.1734\n",
            "Epoch 23 | Batch: 21 | Loss: 14.9523\n",
            "Epoch 23 | Batch: 22 | Loss: 16.9811\n",
            "Epoch 23 | Batch: 23 | Loss: 21.4901\n",
            "Epoch 23 | Batch: 24 | Loss: 9.7357\n",
            "Epoch 24 | Batch: 1 | Loss: 20.0959\n",
            "Epoch 24 | Batch: 2 | Loss: 15.4879\n",
            "Epoch 24 | Batch: 3 | Loss: 15.5996\n",
            "Epoch 24 | Batch: 4 | Loss: 20.9436\n",
            "Epoch 24 | Batch: 5 | Loss: 13.0983\n",
            "Epoch 24 | Batch: 6 | Loss: 13.4663\n",
            "Epoch 24 | Batch: 7 | Loss: 20.0080\n",
            "Epoch 24 | Batch: 8 | Loss: 15.0550\n",
            "Epoch 24 | Batch: 9 | Loss: 13.0954\n",
            "Epoch 24 | Batch: 10 | Loss: 19.7267\n",
            "Epoch 24 | Batch: 11 | Loss: 19.8588\n",
            "Epoch 24 | Batch: 12 | Loss: 19.9401\n",
            "Epoch 24 | Batch: 13 | Loss: 11.0519\n",
            "Epoch 24 | Batch: 14 | Loss: 9.4197\n",
            "Epoch 24 | Batch: 15 | Loss: 13.2423\n",
            "Epoch 24 | Batch: 16 | Loss: 19.2495\n",
            "Epoch 24 | Batch: 17 | Loss: 18.4802\n",
            "Epoch 24 | Batch: 18 | Loss: 21.0285\n",
            "Epoch 24 | Batch: 19 | Loss: 12.4826\n",
            "Epoch 24 | Batch: 20 | Loss: 13.0395\n",
            "Epoch 24 | Batch: 21 | Loss: 22.8196\n",
            "Epoch 24 | Batch: 22 | Loss: 21.8483\n",
            "Epoch 24 | Batch: 23 | Loss: 15.8698\n",
            "Epoch 24 | Batch: 24 | Loss: 6.4437\n",
            "Epoch 25 | Batch: 1 | Loss: 12.7299\n",
            "Epoch 25 | Batch: 2 | Loss: 22.8856\n",
            "Epoch 25 | Batch: 3 | Loss: 16.2739\n",
            "Epoch 25 | Batch: 4 | Loss: 10.9338\n",
            "Epoch 25 | Batch: 5 | Loss: 16.1003\n",
            "Epoch 25 | Batch: 6 | Loss: 13.2328\n",
            "Epoch 25 | Batch: 7 | Loss: 18.8929\n",
            "Epoch 25 | Batch: 8 | Loss: 15.8061\n",
            "Epoch 25 | Batch: 9 | Loss: 15.2705\n",
            "Epoch 25 | Batch: 10 | Loss: 16.2247\n",
            "Epoch 25 | Batch: 11 | Loss: 17.1505\n",
            "Epoch 25 | Batch: 12 | Loss: 17.8769\n",
            "Epoch 25 | Batch: 13 | Loss: 13.8119\n",
            "Epoch 25 | Batch: 14 | Loss: 18.1848\n",
            "Epoch 25 | Batch: 15 | Loss: 15.1731\n",
            "Epoch 25 | Batch: 16 | Loss: 13.6109\n",
            "Epoch 25 | Batch: 17 | Loss: 15.8520\n",
            "Epoch 25 | Batch: 18 | Loss: 9.4266\n",
            "Epoch 25 | Batch: 19 | Loss: 14.8487\n",
            "Epoch 25 | Batch: 20 | Loss: 13.3697\n",
            "Epoch 25 | Batch: 21 | Loss: 18.1795\n",
            "Epoch 25 | Batch: 22 | Loss: 19.8787\n",
            "Epoch 25 | Batch: 23 | Loss: 13.6027\n",
            "Epoch 25 | Batch: 24 | Loss: 12.9349\n",
            "Epoch 26 | Batch: 1 | Loss: 11.6718\n",
            "Epoch 26 | Batch: 2 | Loss: 16.3571\n",
            "Epoch 26 | Batch: 3 | Loss: 13.8652\n",
            "Epoch 26 | Batch: 4 | Loss: 19.4757\n",
            "Epoch 26 | Batch: 5 | Loss: 14.4661\n",
            "Epoch 26 | Batch: 6 | Loss: 13.7649\n",
            "Epoch 26 | Batch: 7 | Loss: 13.1006\n",
            "Epoch 26 | Batch: 8 | Loss: 15.3610\n",
            "Epoch 26 | Batch: 9 | Loss: 18.9379\n",
            "Epoch 26 | Batch: 10 | Loss: 14.6073\n",
            "Epoch 26 | Batch: 11 | Loss: 15.8681\n",
            "Epoch 26 | Batch: 12 | Loss: 15.0844\n",
            "Epoch 26 | Batch: 13 | Loss: 20.5670\n",
            "Epoch 26 | Batch: 14 | Loss: 24.5213\n",
            "Epoch 26 | Batch: 15 | Loss: 17.0061\n",
            "Epoch 26 | Batch: 16 | Loss: 16.4751\n",
            "Epoch 26 | Batch: 17 | Loss: 19.2718\n",
            "Epoch 26 | Batch: 18 | Loss: 12.8760\n",
            "Epoch 26 | Batch: 19 | Loss: 12.5093\n",
            "Epoch 26 | Batch: 20 | Loss: 18.4625\n",
            "Epoch 26 | Batch: 21 | Loss: 14.5450\n",
            "Epoch 26 | Batch: 22 | Loss: 14.9913\n",
            "Epoch 26 | Batch: 23 | Loss: 15.0786\n",
            "Epoch 26 | Batch: 24 | Loss: 9.3416\n",
            "Epoch 27 | Batch: 1 | Loss: 18.1812\n",
            "Epoch 27 | Batch: 2 | Loss: 16.1928\n",
            "Epoch 27 | Batch: 3 | Loss: 14.8288\n",
            "Epoch 27 | Batch: 4 | Loss: 18.7851\n",
            "Epoch 27 | Batch: 5 | Loss: 17.3460\n",
            "Epoch 27 | Batch: 6 | Loss: 15.2821\n",
            "Epoch 27 | Batch: 7 | Loss: 18.7014\n",
            "Epoch 27 | Batch: 8 | Loss: 11.0852\n",
            "Epoch 27 | Batch: 9 | Loss: 15.2834\n",
            "Epoch 27 | Batch: 10 | Loss: 18.2689\n",
            "Epoch 27 | Batch: 11 | Loss: 13.8576\n",
            "Epoch 27 | Batch: 12 | Loss: 13.8628\n",
            "Epoch 27 | Batch: 13 | Loss: 19.9790\n",
            "Epoch 27 | Batch: 14 | Loss: 14.8303\n",
            "Epoch 27 | Batch: 15 | Loss: 14.3134\n",
            "Epoch 27 | Batch: 16 | Loss: 10.7660\n",
            "Epoch 27 | Batch: 17 | Loss: 12.6133\n",
            "Epoch 27 | Batch: 18 | Loss: 15.9367\n",
            "Epoch 27 | Batch: 19 | Loss: 10.9583\n",
            "Epoch 27 | Batch: 20 | Loss: 14.2176\n",
            "Epoch 27 | Batch: 21 | Loss: 14.8670\n",
            "Epoch 27 | Batch: 22 | Loss: 20.7881\n",
            "Epoch 27 | Batch: 23 | Loss: 13.9701\n",
            "Epoch 27 | Batch: 24 | Loss: 10.8690\n",
            "Epoch 28 | Batch: 1 | Loss: 16.8787\n",
            "Epoch 28 | Batch: 2 | Loss: 12.7573\n",
            "Epoch 28 | Batch: 3 | Loss: 14.4728\n",
            "Epoch 28 | Batch: 4 | Loss: 15.4194\n",
            "Epoch 28 | Batch: 5 | Loss: 18.4754\n",
            "Epoch 28 | Batch: 6 | Loss: 13.2314\n",
            "Epoch 28 | Batch: 7 | Loss: 12.6008\n",
            "Epoch 28 | Batch: 8 | Loss: 17.5269\n",
            "Epoch 28 | Batch: 9 | Loss: 14.3489\n",
            "Epoch 28 | Batch: 10 | Loss: 15.8804\n",
            "Epoch 28 | Batch: 11 | Loss: 23.5327\n",
            "Epoch 28 | Batch: 12 | Loss: 20.3087\n",
            "Epoch 28 | Batch: 13 | Loss: 13.4730\n",
            "Epoch 28 | Batch: 14 | Loss: 22.1397\n",
            "Epoch 28 | Batch: 15 | Loss: 21.6628\n",
            "Epoch 28 | Batch: 16 | Loss: 14.0768\n",
            "Epoch 28 | Batch: 17 | Loss: 11.0329\n",
            "Epoch 28 | Batch: 18 | Loss: 13.6819\n",
            "Epoch 28 | Batch: 19 | Loss: 18.2137\n",
            "Epoch 28 | Batch: 20 | Loss: 14.3315\n",
            "Epoch 28 | Batch: 21 | Loss: 18.0282\n",
            "Epoch 28 | Batch: 22 | Loss: 16.6200\n",
            "Epoch 28 | Batch: 23 | Loss: 15.5562\n",
            "Epoch 28 | Batch: 24 | Loss: 10.8581\n",
            "Epoch 29 | Batch: 1 | Loss: 20.0283\n",
            "Epoch 29 | Batch: 2 | Loss: 17.3400\n",
            "Epoch 29 | Batch: 3 | Loss: 16.8594\n",
            "Epoch 29 | Batch: 4 | Loss: 16.0165\n",
            "Epoch 29 | Batch: 5 | Loss: 11.5258\n",
            "Epoch 29 | Batch: 6 | Loss: 15.1645\n",
            "Epoch 29 | Batch: 7 | Loss: 16.4663\n",
            "Epoch 29 | Batch: 8 | Loss: 13.7568\n",
            "Epoch 29 | Batch: 9 | Loss: 12.7085\n",
            "Epoch 29 | Batch: 10 | Loss: 14.9620\n",
            "Epoch 29 | Batch: 11 | Loss: 15.8256\n",
            "Epoch 29 | Batch: 12 | Loss: 14.5944\n",
            "Epoch 29 | Batch: 13 | Loss: 21.3712\n",
            "Epoch 29 | Batch: 14 | Loss: 15.9962\n",
            "Epoch 29 | Batch: 15 | Loss: 16.1042\n",
            "Epoch 29 | Batch: 16 | Loss: 15.7836\n",
            "Epoch 29 | Batch: 17 | Loss: 11.9176\n",
            "Epoch 29 | Batch: 18 | Loss: 11.4810\n",
            "Epoch 29 | Batch: 19 | Loss: 18.8574\n",
            "Epoch 29 | Batch: 20 | Loss: 16.1377\n",
            "Epoch 29 | Batch: 21 | Loss: 21.0617\n",
            "Epoch 29 | Batch: 22 | Loss: 13.3234\n",
            "Epoch 29 | Batch: 23 | Loss: 18.8202\n",
            "Epoch 29 | Batch: 24 | Loss: 10.7683\n",
            "Epoch 30 | Batch: 1 | Loss: 18.6871\n",
            "Epoch 30 | Batch: 2 | Loss: 10.7081\n",
            "Epoch 30 | Batch: 3 | Loss: 15.7023\n",
            "Epoch 30 | Batch: 4 | Loss: 15.5217\n",
            "Epoch 30 | Batch: 5 | Loss: 13.2557\n",
            "Epoch 30 | Batch: 6 | Loss: 15.9937\n",
            "Epoch 30 | Batch: 7 | Loss: 13.3699\n",
            "Epoch 30 | Batch: 8 | Loss: 11.9564\n",
            "Epoch 30 | Batch: 9 | Loss: 11.9112\n",
            "Epoch 30 | Batch: 10 | Loss: 17.8851\n",
            "Epoch 30 | Batch: 11 | Loss: 11.8122\n",
            "Epoch 30 | Batch: 12 | Loss: 15.9344\n",
            "Epoch 30 | Batch: 13 | Loss: 14.1907\n",
            "Epoch 30 | Batch: 14 | Loss: 15.6539\n",
            "Epoch 30 | Batch: 15 | Loss: 15.1467\n",
            "Epoch 30 | Batch: 16 | Loss: 17.4700\n",
            "Epoch 30 | Batch: 17 | Loss: 10.7426\n",
            "Epoch 30 | Batch: 18 | Loss: 16.8981\n",
            "Epoch 30 | Batch: 19 | Loss: 17.6625\n",
            "Epoch 30 | Batch: 20 | Loss: 17.5112\n",
            "Epoch 30 | Batch: 21 | Loss: 14.7606\n",
            "Epoch 30 | Batch: 22 | Loss: 14.6612\n",
            "Epoch 30 | Batch: 23 | Loss: 16.4346\n",
            "Epoch 30 | Batch: 24 | Loss: 10.9481\n",
            "Epoch 31 | Batch: 1 | Loss: 12.3993\n",
            "Epoch 31 | Batch: 2 | Loss: 14.9925\n",
            "Epoch 31 | Batch: 3 | Loss: 12.5410\n",
            "Epoch 31 | Batch: 4 | Loss: 17.1657\n",
            "Epoch 31 | Batch: 5 | Loss: 17.5078\n",
            "Epoch 31 | Batch: 6 | Loss: 15.0120\n",
            "Epoch 31 | Batch: 7 | Loss: 17.5069\n",
            "Epoch 31 | Batch: 8 | Loss: 16.5113\n",
            "Epoch 31 | Batch: 9 | Loss: 21.0660\n",
            "Epoch 31 | Batch: 10 | Loss: 15.1862\n",
            "Epoch 31 | Batch: 11 | Loss: 11.9195\n",
            "Epoch 31 | Batch: 12 | Loss: 20.3833\n",
            "Epoch 31 | Batch: 13 | Loss: 17.0920\n",
            "Epoch 31 | Batch: 14 | Loss: 12.3873\n",
            "Epoch 31 | Batch: 15 | Loss: 11.0472\n",
            "Epoch 31 | Batch: 16 | Loss: 16.9475\n",
            "Epoch 31 | Batch: 17 | Loss: 18.2544\n",
            "Epoch 31 | Batch: 18 | Loss: 17.6448\n",
            "Epoch 31 | Batch: 19 | Loss: 15.9222\n",
            "Epoch 31 | Batch: 20 | Loss: 16.3821\n",
            "Epoch 31 | Batch: 21 | Loss: 13.8562\n",
            "Epoch 31 | Batch: 22 | Loss: 13.6378\n",
            "Epoch 31 | Batch: 23 | Loss: 16.0001\n",
            "Epoch 31 | Batch: 24 | Loss: 10.8931\n",
            "Epoch 32 | Batch: 1 | Loss: 13.0051\n",
            "Epoch 32 | Batch: 2 | Loss: 14.5643\n",
            "Epoch 32 | Batch: 3 | Loss: 13.8561\n",
            "Epoch 32 | Batch: 4 | Loss: 15.7978\n",
            "Epoch 32 | Batch: 5 | Loss: 17.7201\n",
            "Epoch 32 | Batch: 6 | Loss: 13.4919\n",
            "Epoch 32 | Batch: 7 | Loss: 15.0566\n",
            "Epoch 32 | Batch: 8 | Loss: 15.3967\n",
            "Epoch 32 | Batch: 9 | Loss: 16.2224\n",
            "Epoch 32 | Batch: 10 | Loss: 12.6859\n",
            "Epoch 32 | Batch: 11 | Loss: 8.7121\n",
            "Epoch 32 | Batch: 12 | Loss: 19.0422\n",
            "Epoch 32 | Batch: 13 | Loss: 20.4706\n",
            "Epoch 32 | Batch: 14 | Loss: 14.3339\n",
            "Epoch 32 | Batch: 15 | Loss: 12.6047\n",
            "Epoch 32 | Batch: 16 | Loss: 14.8558\n",
            "Epoch 32 | Batch: 17 | Loss: 17.5698\n",
            "Epoch 32 | Batch: 18 | Loss: 16.2864\n",
            "Epoch 32 | Batch: 19 | Loss: 16.0907\n",
            "Epoch 32 | Batch: 20 | Loss: 17.7463\n",
            "Epoch 32 | Batch: 21 | Loss: 15.5184\n",
            "Epoch 32 | Batch: 22 | Loss: 21.0005\n",
            "Epoch 32 | Batch: 23 | Loss: 18.0357\n",
            "Epoch 32 | Batch: 24 | Loss: 6.8673\n",
            "Epoch 33 | Batch: 1 | Loss: 13.1879\n",
            "Epoch 33 | Batch: 2 | Loss: 18.4736\n",
            "Epoch 33 | Batch: 3 | Loss: 17.6273\n",
            "Epoch 33 | Batch: 4 | Loss: 11.5494\n",
            "Epoch 33 | Batch: 5 | Loss: 13.2714\n",
            "Epoch 33 | Batch: 6 | Loss: 14.9466\n",
            "Epoch 33 | Batch: 7 | Loss: 17.0098\n",
            "Epoch 33 | Batch: 8 | Loss: 17.4935\n",
            "Epoch 33 | Batch: 9 | Loss: 15.6148\n",
            "Epoch 33 | Batch: 10 | Loss: 17.5735\n",
            "Epoch 33 | Batch: 11 | Loss: 13.2822\n",
            "Epoch 33 | Batch: 12 | Loss: 17.3377\n",
            "Epoch 33 | Batch: 13 | Loss: 19.1113\n",
            "Epoch 33 | Batch: 14 | Loss: 15.1574\n",
            "Epoch 33 | Batch: 15 | Loss: 14.5005\n",
            "Epoch 33 | Batch: 16 | Loss: 19.8111\n",
            "Epoch 33 | Batch: 17 | Loss: 14.8612\n",
            "Epoch 33 | Batch: 18 | Loss: 12.5583\n",
            "Epoch 33 | Batch: 19 | Loss: 15.9429\n",
            "Epoch 33 | Batch: 20 | Loss: 11.9997\n",
            "Epoch 33 | Batch: 21 | Loss: 20.2161\n",
            "Epoch 33 | Batch: 22 | Loss: 11.1011\n",
            "Epoch 33 | Batch: 23 | Loss: 14.6012\n",
            "Epoch 33 | Batch: 24 | Loss: 11.5568\n",
            "Epoch 34 | Batch: 1 | Loss: 11.2934\n",
            "Epoch 34 | Batch: 2 | Loss: 22.9444\n",
            "Epoch 34 | Batch: 3 | Loss: 13.3783\n",
            "Epoch 34 | Batch: 4 | Loss: 18.7261\n",
            "Epoch 34 | Batch: 5 | Loss: 13.5027\n",
            "Epoch 34 | Batch: 6 | Loss: 16.2374\n",
            "Epoch 34 | Batch: 7 | Loss: 15.0668\n",
            "Epoch 34 | Batch: 8 | Loss: 12.9984\n",
            "Epoch 34 | Batch: 9 | Loss: 14.4027\n",
            "Epoch 34 | Batch: 10 | Loss: 15.8823\n",
            "Epoch 34 | Batch: 11 | Loss: 14.7641\n",
            "Epoch 34 | Batch: 12 | Loss: 13.9247\n",
            "Epoch 34 | Batch: 13 | Loss: 19.2364\n",
            "Epoch 34 | Batch: 14 | Loss: 14.8319\n",
            "Epoch 34 | Batch: 15 | Loss: 17.8716\n",
            "Epoch 34 | Batch: 16 | Loss: 14.8481\n",
            "Epoch 34 | Batch: 17 | Loss: 15.4511\n",
            "Epoch 34 | Batch: 18 | Loss: 14.2260\n",
            "Epoch 34 | Batch: 19 | Loss: 16.3088\n",
            "Epoch 34 | Batch: 20 | Loss: 8.6167\n",
            "Epoch 34 | Batch: 21 | Loss: 15.8888\n",
            "Epoch 34 | Batch: 22 | Loss: 16.5699\n",
            "Epoch 34 | Batch: 23 | Loss: 19.3189\n",
            "Epoch 34 | Batch: 24 | Loss: 12.1473\n",
            "Epoch 35 | Batch: 1 | Loss: 18.2125\n",
            "Epoch 35 | Batch: 2 | Loss: 13.8356\n",
            "Epoch 35 | Batch: 3 | Loss: 5.6006\n",
            "Epoch 35 | Batch: 4 | Loss: 11.1583\n",
            "Epoch 35 | Batch: 5 | Loss: 12.3489\n",
            "Epoch 35 | Batch: 6 | Loss: 7.0832\n",
            "Epoch 35 | Batch: 7 | Loss: 17.3333\n",
            "Epoch 35 | Batch: 8 | Loss: 11.9533\n",
            "Epoch 35 | Batch: 9 | Loss: 13.1327\n",
            "Epoch 35 | Batch: 10 | Loss: 17.7997\n",
            "Epoch 35 | Batch: 11 | Loss: 17.0705\n",
            "Epoch 35 | Batch: 12 | Loss: 16.1583\n",
            "Epoch 35 | Batch: 13 | Loss: 19.0967\n",
            "Epoch 35 | Batch: 14 | Loss: 16.0348\n",
            "Epoch 35 | Batch: 15 | Loss: 20.7396\n",
            "Epoch 35 | Batch: 16 | Loss: 20.0650\n",
            "Epoch 35 | Batch: 17 | Loss: 18.6990\n",
            "Epoch 35 | Batch: 18 | Loss: 14.5717\n",
            "Epoch 35 | Batch: 19 | Loss: 16.8348\n",
            "Epoch 35 | Batch: 20 | Loss: 20.9993\n",
            "Epoch 35 | Batch: 21 | Loss: 15.2781\n",
            "Epoch 35 | Batch: 22 | Loss: 14.6607\n",
            "Epoch 35 | Batch: 23 | Loss: 20.7122\n",
            "Epoch 35 | Batch: 24 | Loss: 7.2005\n",
            "Epoch 36 | Batch: 1 | Loss: 20.6044\n",
            "Epoch 36 | Batch: 2 | Loss: 15.6831\n",
            "Epoch 36 | Batch: 3 | Loss: 12.0546\n",
            "Epoch 36 | Batch: 4 | Loss: 18.3667\n",
            "Epoch 36 | Batch: 5 | Loss: 18.7956\n",
            "Epoch 36 | Batch: 6 | Loss: 14.0903\n",
            "Epoch 36 | Batch: 7 | Loss: 9.8341\n",
            "Epoch 36 | Batch: 8 | Loss: 12.4014\n",
            "Epoch 36 | Batch: 9 | Loss: 16.8023\n",
            "Epoch 36 | Batch: 10 | Loss: 15.9641\n",
            "Epoch 36 | Batch: 11 | Loss: 18.7298\n",
            "Epoch 36 | Batch: 12 | Loss: 16.0479\n",
            "Epoch 36 | Batch: 13 | Loss: 14.5178\n",
            "Epoch 36 | Batch: 14 | Loss: 18.9667\n",
            "Epoch 36 | Batch: 15 | Loss: 14.5545\n",
            "Epoch 36 | Batch: 16 | Loss: 16.8610\n",
            "Epoch 36 | Batch: 17 | Loss: 16.7445\n",
            "Epoch 36 | Batch: 18 | Loss: 21.2784\n",
            "Epoch 36 | Batch: 19 | Loss: 16.8363\n",
            "Epoch 36 | Batch: 20 | Loss: 10.5678\n",
            "Epoch 36 | Batch: 21 | Loss: 13.5289\n",
            "Epoch 36 | Batch: 22 | Loss: 16.6425\n",
            "Epoch 36 | Batch: 23 | Loss: 12.5171\n",
            "Epoch 36 | Batch: 24 | Loss: 7.5356\n",
            "Epoch 37 | Batch: 1 | Loss: 11.0333\n",
            "Epoch 37 | Batch: 2 | Loss: 20.8517\n",
            "Epoch 37 | Batch: 3 | Loss: 14.0281\n",
            "Epoch 37 | Batch: 4 | Loss: 10.3883\n",
            "Epoch 37 | Batch: 5 | Loss: 17.9897\n",
            "Epoch 37 | Batch: 6 | Loss: 15.4043\n",
            "Epoch 37 | Batch: 7 | Loss: 9.6578\n",
            "Epoch 37 | Batch: 8 | Loss: 16.8100\n",
            "Epoch 37 | Batch: 9 | Loss: 17.6947\n",
            "Epoch 37 | Batch: 10 | Loss: 23.1853\n",
            "Epoch 37 | Batch: 11 | Loss: 18.4525\n",
            "Epoch 37 | Batch: 12 | Loss: 17.2973\n",
            "Epoch 37 | Batch: 13 | Loss: 12.5310\n",
            "Epoch 37 | Batch: 14 | Loss: 9.8800\n",
            "Epoch 37 | Batch: 15 | Loss: 17.9479\n",
            "Epoch 37 | Batch: 16 | Loss: 13.6118\n",
            "Epoch 37 | Batch: 17 | Loss: 14.1454\n",
            "Epoch 37 | Batch: 18 | Loss: 12.0522\n",
            "Epoch 37 | Batch: 19 | Loss: 12.8328\n",
            "Epoch 37 | Batch: 20 | Loss: 19.4128\n",
            "Epoch 37 | Batch: 21 | Loss: 19.9252\n",
            "Epoch 37 | Batch: 22 | Loss: 17.1251\n",
            "Epoch 37 | Batch: 23 | Loss: 11.0318\n",
            "Epoch 37 | Batch: 24 | Loss: 25.1011\n",
            "Epoch 38 | Batch: 1 | Loss: 16.8880\n",
            "Epoch 38 | Batch: 2 | Loss: 13.2428\n",
            "Epoch 38 | Batch: 3 | Loss: 12.4080\n",
            "Epoch 38 | Batch: 4 | Loss: 10.0859\n",
            "Epoch 38 | Batch: 5 | Loss: 17.0293\n",
            "Epoch 38 | Batch: 6 | Loss: 15.4588\n",
            "Epoch 38 | Batch: 7 | Loss: 16.1174\n",
            "Epoch 38 | Batch: 8 | Loss: 15.2312\n",
            "Epoch 38 | Batch: 9 | Loss: 16.3995\n",
            "Epoch 38 | Batch: 10 | Loss: 16.7990\n",
            "Epoch 38 | Batch: 11 | Loss: 12.4665\n",
            "Epoch 38 | Batch: 12 | Loss: 15.4014\n",
            "Epoch 38 | Batch: 13 | Loss: 11.6567\n",
            "Epoch 38 | Batch: 14 | Loss: 19.1338\n",
            "Epoch 38 | Batch: 15 | Loss: 17.2150\n",
            "Epoch 38 | Batch: 16 | Loss: 14.8507\n",
            "Epoch 38 | Batch: 17 | Loss: 14.3244\n",
            "Epoch 38 | Batch: 18 | Loss: 21.1955\n",
            "Epoch 38 | Batch: 19 | Loss: 20.7773\n",
            "Epoch 38 | Batch: 20 | Loss: 14.9871\n",
            "Epoch 38 | Batch: 21 | Loss: 11.4794\n",
            "Epoch 38 | Batch: 22 | Loss: 20.0765\n",
            "Epoch 38 | Batch: 23 | Loss: 18.0330\n",
            "Epoch 38 | Batch: 24 | Loss: 11.2836\n",
            "Epoch 39 | Batch: 1 | Loss: 14.9212\n",
            "Epoch 39 | Batch: 2 | Loss: 17.5115\n",
            "Epoch 39 | Batch: 3 | Loss: 10.6028\n",
            "Epoch 39 | Batch: 4 | Loss: 13.4197\n",
            "Epoch 39 | Batch: 5 | Loss: 15.8918\n",
            "Epoch 39 | Batch: 6 | Loss: 14.1328\n",
            "Epoch 39 | Batch: 7 | Loss: 14.8685\n",
            "Epoch 39 | Batch: 8 | Loss: 15.5319\n",
            "Epoch 39 | Batch: 9 | Loss: 13.2672\n",
            "Epoch 39 | Batch: 10 | Loss: 26.7974\n",
            "Epoch 39 | Batch: 11 | Loss: 20.3015\n",
            "Epoch 39 | Batch: 12 | Loss: 17.5788\n",
            "Epoch 39 | Batch: 13 | Loss: 12.8408\n",
            "Epoch 39 | Batch: 14 | Loss: 11.2286\n",
            "Epoch 39 | Batch: 15 | Loss: 13.5639\n",
            "Epoch 39 | Batch: 16 | Loss: 13.0248\n",
            "Epoch 39 | Batch: 17 | Loss: 17.8435\n",
            "Epoch 39 | Batch: 18 | Loss: 16.6184\n",
            "Epoch 39 | Batch: 19 | Loss: 16.5923\n",
            "Epoch 39 | Batch: 20 | Loss: 15.1977\n",
            "Epoch 39 | Batch: 21 | Loss: 13.3379\n",
            "Epoch 39 | Batch: 22 | Loss: 15.5132\n",
            "Epoch 39 | Batch: 23 | Loss: 16.1686\n",
            "Epoch 39 | Batch: 24 | Loss: 10.4097\n",
            "Epoch 40 | Batch: 1 | Loss: 13.8833\n",
            "Epoch 40 | Batch: 2 | Loss: 16.0126\n",
            "Epoch 40 | Batch: 3 | Loss: 19.4391\n",
            "Epoch 40 | Batch: 4 | Loss: 16.4619\n",
            "Epoch 40 | Batch: 5 | Loss: 18.7427\n",
            "Epoch 40 | Batch: 6 | Loss: 18.6100\n",
            "Epoch 40 | Batch: 7 | Loss: 17.5387\n",
            "Epoch 40 | Batch: 8 | Loss: 15.2303\n",
            "Epoch 40 | Batch: 9 | Loss: 16.1885\n",
            "Epoch 40 | Batch: 10 | Loss: 13.4923\n",
            "Epoch 40 | Batch: 11 | Loss: 12.2954\n",
            "Epoch 40 | Batch: 12 | Loss: 12.0716\n",
            "Epoch 40 | Batch: 13 | Loss: 12.9241\n",
            "Epoch 40 | Batch: 14 | Loss: 21.1819\n",
            "Epoch 40 | Batch: 15 | Loss: 13.6158\n",
            "Epoch 40 | Batch: 16 | Loss: 9.5360\n",
            "Epoch 40 | Batch: 17 | Loss: 20.3687\n",
            "Epoch 40 | Batch: 18 | Loss: 17.3087\n",
            "Epoch 40 | Batch: 19 | Loss: 21.6545\n",
            "Epoch 40 | Batch: 20 | Loss: 20.8607\n",
            "Epoch 40 | Batch: 21 | Loss: 13.7780\n",
            "Epoch 40 | Batch: 22 | Loss: 11.3006\n",
            "Epoch 40 | Batch: 23 | Loss: 14.0825\n",
            "Epoch 40 | Batch: 24 | Loss: 12.2848\n",
            "Epoch 41 | Batch: 1 | Loss: 17.1331\n",
            "Epoch 41 | Batch: 2 | Loss: 15.4170\n",
            "Epoch 41 | Batch: 3 | Loss: 11.1853\n",
            "Epoch 41 | Batch: 4 | Loss: 13.2947\n",
            "Epoch 41 | Batch: 5 | Loss: 17.8870\n",
            "Epoch 41 | Batch: 6 | Loss: 18.3997\n",
            "Epoch 41 | Batch: 7 | Loss: 12.7136\n",
            "Epoch 41 | Batch: 8 | Loss: 9.0628\n",
            "Epoch 41 | Batch: 9 | Loss: 17.4992\n",
            "Epoch 41 | Batch: 10 | Loss: 14.9389\n",
            "Epoch 41 | Batch: 11 | Loss: 14.0164\n",
            "Epoch 41 | Batch: 12 | Loss: 15.3789\n",
            "Epoch 41 | Batch: 13 | Loss: 13.4765\n",
            "Epoch 41 | Batch: 14 | Loss: 18.2669\n",
            "Epoch 41 | Batch: 15 | Loss: 14.6936\n",
            "Epoch 41 | Batch: 16 | Loss: 17.8352\n",
            "Epoch 41 | Batch: 17 | Loss: 16.9847\n",
            "Epoch 41 | Batch: 18 | Loss: 12.8944\n",
            "Epoch 41 | Batch: 19 | Loss: 16.5436\n",
            "Epoch 41 | Batch: 20 | Loss: 11.4226\n",
            "Epoch 41 | Batch: 21 | Loss: 17.0977\n",
            "Epoch 41 | Batch: 22 | Loss: 19.3651\n",
            "Epoch 41 | Batch: 23 | Loss: 17.6379\n",
            "Epoch 41 | Batch: 24 | Loss: 11.0563\n",
            "Epoch 42 | Batch: 1 | Loss: 13.8146\n",
            "Epoch 42 | Batch: 2 | Loss: 20.6812\n",
            "Epoch 42 | Batch: 3 | Loss: 20.8510\n",
            "Epoch 42 | Batch: 4 | Loss: 14.1449\n",
            "Epoch 42 | Batch: 5 | Loss: 14.5225\n",
            "Epoch 42 | Batch: 6 | Loss: 16.3902\n",
            "Epoch 42 | Batch: 7 | Loss: 14.6292\n",
            "Epoch 42 | Batch: 8 | Loss: 20.8637\n",
            "Epoch 42 | Batch: 9 | Loss: 16.4788\n",
            "Epoch 42 | Batch: 10 | Loss: 8.8532\n",
            "Epoch 42 | Batch: 11 | Loss: 17.5066\n",
            "Epoch 42 | Batch: 12 | Loss: 12.4522\n",
            "Epoch 42 | Batch: 13 | Loss: 18.4631\n",
            "Epoch 42 | Batch: 14 | Loss: 12.8310\n",
            "Epoch 42 | Batch: 15 | Loss: 13.8310\n",
            "Epoch 42 | Batch: 16 | Loss: 16.0245\n",
            "Epoch 42 | Batch: 17 | Loss: 14.7854\n",
            "Epoch 42 | Batch: 18 | Loss: 11.9108\n",
            "Epoch 42 | Batch: 19 | Loss: 13.8239\n",
            "Epoch 42 | Batch: 20 | Loss: 16.6859\n",
            "Epoch 42 | Batch: 21 | Loss: 16.6814\n",
            "Epoch 42 | Batch: 22 | Loss: 17.1480\n",
            "Epoch 42 | Batch: 23 | Loss: 16.6923\n",
            "Epoch 42 | Batch: 24 | Loss: 8.5868\n",
            "Epoch 43 | Batch: 1 | Loss: 17.4362\n",
            "Epoch 43 | Batch: 2 | Loss: 18.7415\n",
            "Epoch 43 | Batch: 3 | Loss: 12.9417\n",
            "Epoch 43 | Batch: 4 | Loss: 17.1278\n",
            "Epoch 43 | Batch: 5 | Loss: 12.4703\n",
            "Epoch 43 | Batch: 6 | Loss: 20.3068\n",
            "Epoch 43 | Batch: 7 | Loss: 15.5247\n",
            "Epoch 43 | Batch: 8 | Loss: 11.2999\n",
            "Epoch 43 | Batch: 9 | Loss: 10.9586\n",
            "Epoch 43 | Batch: 10 | Loss: 21.2114\n",
            "Epoch 43 | Batch: 11 | Loss: 18.9668\n",
            "Epoch 43 | Batch: 12 | Loss: 13.7568\n",
            "Epoch 43 | Batch: 13 | Loss: 15.7274\n",
            "Epoch 43 | Batch: 14 | Loss: 15.2225\n",
            "Epoch 43 | Batch: 15 | Loss: 12.9596\n",
            "Epoch 43 | Batch: 16 | Loss: 15.7849\n",
            "Epoch 43 | Batch: 17 | Loss: 17.2901\n",
            "Epoch 43 | Batch: 18 | Loss: 11.7524\n",
            "Epoch 43 | Batch: 19 | Loss: 13.2216\n",
            "Epoch 43 | Batch: 20 | Loss: 11.3770\n",
            "Epoch 43 | Batch: 21 | Loss: 15.7296\n",
            "Epoch 43 | Batch: 22 | Loss: 17.7995\n",
            "Epoch 43 | Batch: 23 | Loss: 18.4885\n",
            "Epoch 43 | Batch: 24 | Loss: 15.2224\n",
            "Epoch 44 | Batch: 1 | Loss: 14.3629\n",
            "Epoch 44 | Batch: 2 | Loss: 19.5059\n",
            "Epoch 44 | Batch: 3 | Loss: 17.4397\n",
            "Epoch 44 | Batch: 4 | Loss: 14.2802\n",
            "Epoch 44 | Batch: 5 | Loss: 11.4952\n",
            "Epoch 44 | Batch: 6 | Loss: 13.5121\n",
            "Epoch 44 | Batch: 7 | Loss: 20.8251\n",
            "Epoch 44 | Batch: 8 | Loss: 15.3074\n",
            "Epoch 44 | Batch: 9 | Loss: 18.3507\n",
            "Epoch 44 | Batch: 10 | Loss: 12.9562\n",
            "Epoch 44 | Batch: 11 | Loss: 11.4808\n",
            "Epoch 44 | Batch: 12 | Loss: 8.5601\n",
            "Epoch 44 | Batch: 13 | Loss: 20.4791\n",
            "Epoch 44 | Batch: 14 | Loss: 16.7934\n",
            "Epoch 44 | Batch: 15 | Loss: 13.7473\n",
            "Epoch 44 | Batch: 16 | Loss: 13.8473\n",
            "Epoch 44 | Batch: 17 | Loss: 17.6481\n",
            "Epoch 44 | Batch: 18 | Loss: 19.5522\n",
            "Epoch 44 | Batch: 19 | Loss: 16.8618\n",
            "Epoch 44 | Batch: 20 | Loss: 8.1329\n",
            "Epoch 44 | Batch: 21 | Loss: 12.1520\n",
            "Epoch 44 | Batch: 22 | Loss: 11.9557\n",
            "Epoch 44 | Batch: 23 | Loss: 15.9249\n",
            "Epoch 44 | Batch: 24 | Loss: 11.1780\n",
            "Epoch 45 | Batch: 1 | Loss: 19.6303\n",
            "Epoch 45 | Batch: 2 | Loss: 14.3992\n",
            "Epoch 45 | Batch: 3 | Loss: 18.1467\n",
            "Epoch 45 | Batch: 4 | Loss: 19.9899\n",
            "Epoch 45 | Batch: 5 | Loss: 17.9612\n",
            "Epoch 45 | Batch: 6 | Loss: 15.1704\n",
            "Epoch 45 | Batch: 7 | Loss: 13.7612\n",
            "Epoch 45 | Batch: 8 | Loss: 17.5953\n",
            "Epoch 45 | Batch: 9 | Loss: 15.0140\n",
            "Epoch 45 | Batch: 10 | Loss: 14.5098\n",
            "Epoch 45 | Batch: 11 | Loss: 14.6889\n",
            "Epoch 45 | Batch: 12 | Loss: 12.1389\n",
            "Epoch 45 | Batch: 13 | Loss: 13.3795\n",
            "Epoch 45 | Batch: 14 | Loss: 15.2887\n",
            "Epoch 45 | Batch: 15 | Loss: 11.9852\n",
            "Epoch 45 | Batch: 16 | Loss: 16.5498\n",
            "Epoch 45 | Batch: 17 | Loss: 12.6009\n",
            "Epoch 45 | Batch: 18 | Loss: 10.7820\n",
            "Epoch 45 | Batch: 19 | Loss: 17.7090\n",
            "Epoch 45 | Batch: 20 | Loss: 13.4064\n",
            "Epoch 45 | Batch: 21 | Loss: 16.5314\n",
            "Epoch 45 | Batch: 22 | Loss: 18.3355\n",
            "Epoch 45 | Batch: 23 | Loss: 12.8817\n",
            "Epoch 45 | Batch: 24 | Loss: 10.5349\n",
            "Epoch 46 | Batch: 1 | Loss: 16.3410\n",
            "Epoch 46 | Batch: 2 | Loss: 19.4602\n",
            "Epoch 46 | Batch: 3 | Loss: 10.2878\n",
            "Epoch 46 | Batch: 4 | Loss: 17.4864\n",
            "Epoch 46 | Batch: 5 | Loss: 12.9760\n",
            "Epoch 46 | Batch: 6 | Loss: 15.2090\n",
            "Epoch 46 | Batch: 7 | Loss: 19.9169\n",
            "Epoch 46 | Batch: 8 | Loss: 15.6741\n",
            "Epoch 46 | Batch: 9 | Loss: 16.0111\n",
            "Epoch 46 | Batch: 10 | Loss: 14.9651\n",
            "Epoch 46 | Batch: 11 | Loss: 19.1101\n",
            "Epoch 46 | Batch: 12 | Loss: 16.8102\n",
            "Epoch 46 | Batch: 13 | Loss: 14.2117\n",
            "Epoch 46 | Batch: 14 | Loss: 16.6590\n",
            "Epoch 46 | Batch: 15 | Loss: 11.7072\n",
            "Epoch 46 | Batch: 16 | Loss: 16.2746\n",
            "Epoch 46 | Batch: 17 | Loss: 14.0878\n",
            "Epoch 46 | Batch: 18 | Loss: 17.4358\n",
            "Epoch 46 | Batch: 19 | Loss: 11.0399\n",
            "Epoch 46 | Batch: 20 | Loss: 17.6967\n",
            "Epoch 46 | Batch: 21 | Loss: 10.7714\n",
            "Epoch 46 | Batch: 22 | Loss: 14.0601\n",
            "Epoch 46 | Batch: 23 | Loss: 16.9482\n",
            "Epoch 46 | Batch: 24 | Loss: 7.7531\n",
            "Epoch 47 | Batch: 1 | Loss: 18.4869\n",
            "Epoch 47 | Batch: 2 | Loss: 12.8645\n",
            "Epoch 47 | Batch: 3 | Loss: 11.2369\n",
            "Epoch 47 | Batch: 4 | Loss: 22.7843\n",
            "Epoch 47 | Batch: 5 | Loss: 16.5863\n",
            "Epoch 47 | Batch: 6 | Loss: 17.4619\n",
            "Epoch 47 | Batch: 7 | Loss: 13.1166\n",
            "Epoch 47 | Batch: 8 | Loss: 15.9524\n",
            "Epoch 47 | Batch: 9 | Loss: 19.1623\n",
            "Epoch 47 | Batch: 10 | Loss: 14.4013\n",
            "Epoch 47 | Batch: 11 | Loss: 16.9876\n",
            "Epoch 47 | Batch: 12 | Loss: 16.3400\n",
            "Epoch 47 | Batch: 13 | Loss: 16.4557\n",
            "Epoch 47 | Batch: 14 | Loss: 19.4491\n",
            "Epoch 47 | Batch: 15 | Loss: 18.9931\n",
            "Epoch 47 | Batch: 16 | Loss: 14.6032\n",
            "Epoch 47 | Batch: 17 | Loss: 12.9950\n",
            "Epoch 47 | Batch: 18 | Loss: 15.5088\n",
            "Epoch 47 | Batch: 19 | Loss: 15.2605\n",
            "Epoch 47 | Batch: 20 | Loss: 15.2937\n",
            "Epoch 47 | Batch: 21 | Loss: 12.0932\n",
            "Epoch 47 | Batch: 22 | Loss: 18.8062\n",
            "Epoch 47 | Batch: 23 | Loss: 13.4303\n",
            "Epoch 47 | Batch: 24 | Loss: 6.8422\n",
            "Epoch 48 | Batch: 1 | Loss: 13.1744\n",
            "Epoch 48 | Batch: 2 | Loss: 15.5592\n",
            "Epoch 48 | Batch: 3 | Loss: 13.8333\n",
            "Epoch 48 | Batch: 4 | Loss: 13.8419\n",
            "Epoch 48 | Batch: 5 | Loss: 22.4372\n",
            "Epoch 48 | Batch: 6 | Loss: 17.7498\n",
            "Epoch 48 | Batch: 7 | Loss: 16.4775\n",
            "Epoch 48 | Batch: 8 | Loss: 21.3739\n",
            "Epoch 48 | Batch: 9 | Loss: 27.3712\n",
            "Epoch 48 | Batch: 10 | Loss: 12.0211\n",
            "Epoch 48 | Batch: 11 | Loss: 14.2679\n",
            "Epoch 48 | Batch: 12 | Loss: 11.4794\n",
            "Epoch 48 | Batch: 13 | Loss: 14.6204\n",
            "Epoch 48 | Batch: 14 | Loss: 21.0732\n",
            "Epoch 48 | Batch: 15 | Loss: 12.2239\n",
            "Epoch 48 | Batch: 16 | Loss: 13.9055\n",
            "Epoch 48 | Batch: 17 | Loss: 13.4712\n",
            "Epoch 48 | Batch: 18 | Loss: 15.5393\n",
            "Epoch 48 | Batch: 19 | Loss: 11.9390\n",
            "Epoch 48 | Batch: 20 | Loss: 18.9008\n",
            "Epoch 48 | Batch: 21 | Loss: 9.9575\n",
            "Epoch 48 | Batch: 22 | Loss: 21.5695\n",
            "Epoch 48 | Batch: 23 | Loss: 14.4802\n",
            "Epoch 48 | Batch: 24 | Loss: 7.3985\n",
            "Epoch 49 | Batch: 1 | Loss: 30.1254\n",
            "Epoch 49 | Batch: 2 | Loss: 16.1234\n",
            "Epoch 49 | Batch: 3 | Loss: 13.7386\n",
            "Epoch 49 | Batch: 4 | Loss: 17.9471\n",
            "Epoch 49 | Batch: 5 | Loss: 10.8344\n",
            "Epoch 49 | Batch: 6 | Loss: 14.0590\n",
            "Epoch 49 | Batch: 7 | Loss: 15.0814\n",
            "Epoch 49 | Batch: 8 | Loss: 15.0762\n",
            "Epoch 49 | Batch: 9 | Loss: 17.1894\n",
            "Epoch 49 | Batch: 10 | Loss: 19.0940\n",
            "Epoch 49 | Batch: 11 | Loss: 16.4031\n",
            "Epoch 49 | Batch: 12 | Loss: 13.7942\n",
            "Epoch 49 | Batch: 13 | Loss: 15.8592\n",
            "Epoch 49 | Batch: 14 | Loss: 14.3763\n",
            "Epoch 49 | Batch: 15 | Loss: 10.0642\n",
            "Epoch 49 | Batch: 16 | Loss: 14.9136\n",
            "Epoch 49 | Batch: 17 | Loss: 14.7626\n",
            "Epoch 49 | Batch: 18 | Loss: 12.7484\n",
            "Epoch 49 | Batch: 19 | Loss: 12.9842\n",
            "Epoch 49 | Batch: 20 | Loss: 11.5373\n",
            "Epoch 49 | Batch: 21 | Loss: 16.7520\n",
            "Epoch 49 | Batch: 22 | Loss: 18.7429\n",
            "Epoch 49 | Batch: 23 | Loss: 18.5468\n",
            "Epoch 49 | Batch: 24 | Loss: 6.7070\n",
            "Epoch 50 | Batch: 1 | Loss: 12.7327\n",
            "Epoch 50 | Batch: 2 | Loss: 18.4602\n",
            "Epoch 50 | Batch: 3 | Loss: 9.0660\n",
            "Epoch 50 | Batch: 4 | Loss: 29.8203\n",
            "Epoch 50 | Batch: 5 | Loss: 19.5865\n",
            "Epoch 50 | Batch: 6 | Loss: 18.1140\n",
            "Epoch 50 | Batch: 7 | Loss: 14.9220\n",
            "Epoch 50 | Batch: 8 | Loss: 15.1673\n",
            "Epoch 50 | Batch: 9 | Loss: 16.0642\n",
            "Epoch 50 | Batch: 10 | Loss: 16.4827\n",
            "Epoch 50 | Batch: 11 | Loss: 17.2427\n",
            "Epoch 50 | Batch: 12 | Loss: 17.6158\n",
            "Epoch 50 | Batch: 13 | Loss: 13.7049\n",
            "Epoch 50 | Batch: 14 | Loss: 11.7088\n",
            "Epoch 50 | Batch: 15 | Loss: 10.2171\n",
            "Epoch 50 | Batch: 16 | Loss: 16.2418\n",
            "Epoch 50 | Batch: 17 | Loss: 13.1756\n",
            "Epoch 50 | Batch: 18 | Loss: 10.9939\n",
            "Epoch 50 | Batch: 19 | Loss: 13.7186\n",
            "Epoch 50 | Batch: 20 | Loss: 19.9127\n",
            "Epoch 50 | Batch: 21 | Loss: 16.0192\n",
            "Epoch 50 | Batch: 22 | Loss: 17.4988\n",
            "Epoch 50 | Batch: 23 | Loss: 18.2176\n",
            "Epoch 50 | Batch: 24 | Loss: 9.3341\n",
            "Epoch 51 | Batch: 1 | Loss: 12.6262\n",
            "Epoch 51 | Batch: 2 | Loss: 15.7396\n",
            "Epoch 51 | Batch: 3 | Loss: 23.9194\n",
            "Epoch 51 | Batch: 4 | Loss: 16.2549\n",
            "Epoch 51 | Batch: 5 | Loss: 18.3331\n",
            "Epoch 51 | Batch: 6 | Loss: 13.1361\n",
            "Epoch 51 | Batch: 7 | Loss: 13.9532\n",
            "Epoch 51 | Batch: 8 | Loss: 12.5822\n",
            "Epoch 51 | Batch: 9 | Loss: 21.8128\n",
            "Epoch 51 | Batch: 10 | Loss: 16.5833\n",
            "Epoch 51 | Batch: 11 | Loss: 13.7419\n",
            "Epoch 51 | Batch: 12 | Loss: 17.5229\n",
            "Epoch 51 | Batch: 13 | Loss: 12.2772\n",
            "Epoch 51 | Batch: 14 | Loss: 12.9891\n",
            "Epoch 51 | Batch: 15 | Loss: 17.6200\n",
            "Epoch 51 | Batch: 16 | Loss: 14.2835\n",
            "Epoch 51 | Batch: 17 | Loss: 13.3629\n",
            "Epoch 51 | Batch: 18 | Loss: 22.6068\n",
            "Epoch 51 | Batch: 19 | Loss: 16.5076\n",
            "Epoch 51 | Batch: 20 | Loss: 15.0703\n",
            "Epoch 51 | Batch: 21 | Loss: 15.9598\n",
            "Epoch 51 | Batch: 22 | Loss: 15.0600\n",
            "Epoch 51 | Batch: 23 | Loss: 15.2731\n",
            "Epoch 51 | Batch: 24 | Loss: 9.1730\n",
            "Epoch 52 | Batch: 1 | Loss: 15.7611\n",
            "Epoch 52 | Batch: 2 | Loss: 14.9327\n",
            "Epoch 52 | Batch: 3 | Loss: 11.9687\n",
            "Epoch 52 | Batch: 4 | Loss: 18.6375\n",
            "Epoch 52 | Batch: 5 | Loss: 17.1049\n",
            "Epoch 52 | Batch: 6 | Loss: 12.3244\n",
            "Epoch 52 | Batch: 7 | Loss: 14.7546\n",
            "Epoch 52 | Batch: 8 | Loss: 9.8761\n",
            "Epoch 52 | Batch: 9 | Loss: 19.4094\n",
            "Epoch 52 | Batch: 10 | Loss: 12.5040\n",
            "Epoch 52 | Batch: 11 | Loss: 13.1051\n",
            "Epoch 52 | Batch: 12 | Loss: 25.3473\n",
            "Epoch 52 | Batch: 13 | Loss: 22.1493\n",
            "Epoch 52 | Batch: 14 | Loss: 10.1351\n",
            "Epoch 52 | Batch: 15 | Loss: 12.1701\n",
            "Epoch 52 | Batch: 16 | Loss: 12.9850\n",
            "Epoch 52 | Batch: 17 | Loss: 13.2650\n",
            "Epoch 52 | Batch: 18 | Loss: 24.3771\n",
            "Epoch 52 | Batch: 19 | Loss: 16.4572\n",
            "Epoch 52 | Batch: 20 | Loss: 15.7253\n",
            "Epoch 52 | Batch: 21 | Loss: 17.2865\n",
            "Epoch 52 | Batch: 22 | Loss: 13.5226\n",
            "Epoch 52 | Batch: 23 | Loss: 14.0161\n",
            "Epoch 52 | Batch: 24 | Loss: 11.4015\n",
            "Epoch 53 | Batch: 1 | Loss: 14.2992\n",
            "Epoch 53 | Batch: 2 | Loss: 18.7635\n",
            "Epoch 53 | Batch: 3 | Loss: 12.5307\n",
            "Epoch 53 | Batch: 4 | Loss: 10.4590\n",
            "Epoch 53 | Batch: 5 | Loss: 18.4795\n",
            "Epoch 53 | Batch: 6 | Loss: 20.3382\n",
            "Epoch 53 | Batch: 7 | Loss: 16.5718\n",
            "Epoch 53 | Batch: 8 | Loss: 14.9911\n",
            "Epoch 53 | Batch: 9 | Loss: 18.1359\n",
            "Epoch 53 | Batch: 10 | Loss: 16.9538\n",
            "Epoch 53 | Batch: 11 | Loss: 14.5006\n",
            "Epoch 53 | Batch: 12 | Loss: 17.6224\n",
            "Epoch 53 | Batch: 13 | Loss: 13.6870\n",
            "Epoch 53 | Batch: 14 | Loss: 16.9177\n",
            "Epoch 53 | Batch: 15 | Loss: 17.3675\n",
            "Epoch 53 | Batch: 16 | Loss: 14.7901\n",
            "Epoch 53 | Batch: 17 | Loss: 18.1299\n",
            "Epoch 53 | Batch: 18 | Loss: 15.8491\n",
            "Epoch 53 | Batch: 19 | Loss: 14.4899\n",
            "Epoch 53 | Batch: 20 | Loss: 12.1014\n",
            "Epoch 53 | Batch: 21 | Loss: 12.1575\n",
            "Epoch 53 | Batch: 22 | Loss: 7.2982\n",
            "Epoch 53 | Batch: 23 | Loss: 22.5982\n",
            "Epoch 53 | Batch: 24 | Loss: 9.2662\n",
            "Epoch 54 | Batch: 1 | Loss: 13.8177\n",
            "Epoch 54 | Batch: 2 | Loss: 9.8894\n",
            "Epoch 54 | Batch: 3 | Loss: 17.5820\n",
            "Epoch 54 | Batch: 4 | Loss: 15.4995\n",
            "Epoch 54 | Batch: 5 | Loss: 12.5871\n",
            "Epoch 54 | Batch: 6 | Loss: 21.3736\n",
            "Epoch 54 | Batch: 7 | Loss: 8.8322\n",
            "Epoch 54 | Batch: 8 | Loss: 18.0797\n",
            "Epoch 54 | Batch: 9 | Loss: 15.5639\n",
            "Epoch 54 | Batch: 10 | Loss: 16.0206\n",
            "Epoch 54 | Batch: 11 | Loss: 12.8396\n",
            "Epoch 54 | Batch: 12 | Loss: 19.4176\n",
            "Epoch 54 | Batch: 13 | Loss: 18.0380\n",
            "Epoch 54 | Batch: 14 | Loss: 24.1591\n",
            "Epoch 54 | Batch: 15 | Loss: 22.0456\n",
            "Epoch 54 | Batch: 16 | Loss: 17.1395\n",
            "Epoch 54 | Batch: 17 | Loss: 13.9460\n",
            "Epoch 54 | Batch: 18 | Loss: 15.6379\n",
            "Epoch 54 | Batch: 19 | Loss: 11.5706\n",
            "Epoch 54 | Batch: 20 | Loss: 12.8555\n",
            "Epoch 54 | Batch: 21 | Loss: 13.1832\n",
            "Epoch 54 | Batch: 22 | Loss: 16.2881\n",
            "Epoch 54 | Batch: 23 | Loss: 16.2619\n",
            "Epoch 54 | Batch: 24 | Loss: 9.1006\n",
            "Epoch 55 | Batch: 1 | Loss: 11.4836\n",
            "Epoch 55 | Batch: 2 | Loss: 10.4446\n",
            "Epoch 55 | Batch: 3 | Loss: 11.6673\n",
            "Epoch 55 | Batch: 4 | Loss: 18.3577\n",
            "Epoch 55 | Batch: 5 | Loss: 14.5262\n",
            "Epoch 55 | Batch: 6 | Loss: 25.3337\n",
            "Epoch 55 | Batch: 7 | Loss: 25.4425\n",
            "Epoch 55 | Batch: 8 | Loss: 15.3252\n",
            "Epoch 55 | Batch: 9 | Loss: 14.4113\n",
            "Epoch 55 | Batch: 10 | Loss: 14.6481\n",
            "Epoch 55 | Batch: 11 | Loss: 18.2326\n",
            "Epoch 55 | Batch: 12 | Loss: 16.5830\n",
            "Epoch 55 | Batch: 13 | Loss: 14.5417\n",
            "Epoch 55 | Batch: 14 | Loss: 15.9647\n",
            "Epoch 55 | Batch: 15 | Loss: 14.4289\n",
            "Epoch 55 | Batch: 16 | Loss: 16.1895\n",
            "Epoch 55 | Batch: 17 | Loss: 15.8243\n",
            "Epoch 55 | Batch: 18 | Loss: 13.9303\n",
            "Epoch 55 | Batch: 19 | Loss: 12.8381\n",
            "Epoch 55 | Batch: 20 | Loss: 15.5991\n",
            "Epoch 55 | Batch: 21 | Loss: 14.4815\n",
            "Epoch 55 | Batch: 22 | Loss: 14.1619\n",
            "Epoch 55 | Batch: 23 | Loss: 13.1503\n",
            "Epoch 55 | Batch: 24 | Loss: 10.2378\n",
            "Epoch 56 | Batch: 1 | Loss: 16.1467\n",
            "Epoch 56 | Batch: 2 | Loss: 15.2873\n",
            "Epoch 56 | Batch: 3 | Loss: 14.3639\n",
            "Epoch 56 | Batch: 4 | Loss: 15.8943\n",
            "Epoch 56 | Batch: 5 | Loss: 10.8573\n",
            "Epoch 56 | Batch: 6 | Loss: 11.4495\n",
            "Epoch 56 | Batch: 7 | Loss: 11.6918\n",
            "Epoch 56 | Batch: 8 | Loss: 10.4037\n",
            "Epoch 56 | Batch: 9 | Loss: 14.7969\n",
            "Epoch 56 | Batch: 10 | Loss: 13.5966\n",
            "Epoch 56 | Batch: 11 | Loss: 18.4901\n",
            "Epoch 56 | Batch: 12 | Loss: 14.0018\n",
            "Epoch 56 | Batch: 13 | Loss: 18.4631\n",
            "Epoch 56 | Batch: 14 | Loss: 17.7941\n",
            "Epoch 56 | Batch: 15 | Loss: 16.3028\n",
            "Epoch 56 | Batch: 16 | Loss: 16.2014\n",
            "Epoch 56 | Batch: 17 | Loss: 11.8515\n",
            "Epoch 56 | Batch: 18 | Loss: 10.1677\n",
            "Epoch 56 | Batch: 19 | Loss: 16.3745\n",
            "Epoch 56 | Batch: 20 | Loss: 17.2333\n",
            "Epoch 56 | Batch: 21 | Loss: 12.5808\n",
            "Epoch 56 | Batch: 22 | Loss: 18.8278\n",
            "Epoch 56 | Batch: 23 | Loss: 17.5670\n",
            "Epoch 56 | Batch: 24 | Loss: 13.0968\n",
            "Epoch 57 | Batch: 1 | Loss: 16.0773\n",
            "Epoch 57 | Batch: 2 | Loss: 14.2924\n",
            "Epoch 57 | Batch: 3 | Loss: 14.5507\n",
            "Epoch 57 | Batch: 4 | Loss: 13.8277\n",
            "Epoch 57 | Batch: 5 | Loss: 11.7240\n",
            "Epoch 57 | Batch: 6 | Loss: 14.8026\n",
            "Epoch 57 | Batch: 7 | Loss: 15.3790\n",
            "Epoch 57 | Batch: 8 | Loss: 14.9163\n",
            "Epoch 57 | Batch: 9 | Loss: 16.6327\n",
            "Epoch 57 | Batch: 10 | Loss: 14.8275\n",
            "Epoch 57 | Batch: 11 | Loss: 14.1798\n",
            "Epoch 57 | Batch: 12 | Loss: 17.0410\n",
            "Epoch 57 | Batch: 13 | Loss: 15.7998\n",
            "Epoch 57 | Batch: 14 | Loss: 18.5212\n",
            "Epoch 57 | Batch: 15 | Loss: 20.9101\n",
            "Epoch 57 | Batch: 16 | Loss: 12.8866\n",
            "Epoch 57 | Batch: 17 | Loss: 12.2792\n",
            "Epoch 57 | Batch: 18 | Loss: 12.1598\n",
            "Epoch 57 | Batch: 19 | Loss: 15.6186\n",
            "Epoch 57 | Batch: 20 | Loss: 12.8110\n",
            "Epoch 57 | Batch: 21 | Loss: 17.1724\n",
            "Epoch 57 | Batch: 22 | Loss: 17.0549\n",
            "Epoch 57 | Batch: 23 | Loss: 15.5285\n",
            "Epoch 57 | Batch: 24 | Loss: 10.6402\n",
            "Epoch 58 | Batch: 1 | Loss: 15.4871\n",
            "Epoch 58 | Batch: 2 | Loss: 14.1766\n",
            "Epoch 58 | Batch: 3 | Loss: 13.2584\n",
            "Epoch 58 | Batch: 4 | Loss: 16.7222\n",
            "Epoch 58 | Batch: 5 | Loss: 12.3737\n",
            "Epoch 58 | Batch: 6 | Loss: 14.7786\n",
            "Epoch 58 | Batch: 7 | Loss: 14.0370\n",
            "Epoch 58 | Batch: 8 | Loss: 13.4154\n",
            "Epoch 58 | Batch: 9 | Loss: 12.7287\n",
            "Epoch 58 | Batch: 10 | Loss: 19.9734\n",
            "Epoch 58 | Batch: 11 | Loss: 14.9146\n",
            "Epoch 58 | Batch: 12 | Loss: 19.4502\n",
            "Epoch 58 | Batch: 13 | Loss: 14.9949\n",
            "Epoch 58 | Batch: 14 | Loss: 17.9086\n",
            "Epoch 58 | Batch: 15 | Loss: 15.5190\n",
            "Epoch 58 | Batch: 16 | Loss: 11.9562\n",
            "Epoch 58 | Batch: 17 | Loss: 11.7896\n",
            "Epoch 58 | Batch: 18 | Loss: 11.9298\n",
            "Epoch 58 | Batch: 19 | Loss: 13.1014\n",
            "Epoch 58 | Batch: 20 | Loss: 20.9640\n",
            "Epoch 58 | Batch: 21 | Loss: 22.7008\n",
            "Epoch 58 | Batch: 22 | Loss: 15.6015\n",
            "Epoch 58 | Batch: 23 | Loss: 13.2646\n",
            "Epoch 58 | Batch: 24 | Loss: 9.3685\n",
            "Epoch 59 | Batch: 1 | Loss: 17.1575\n",
            "Epoch 59 | Batch: 2 | Loss: 14.9294\n",
            "Epoch 59 | Batch: 3 | Loss: 12.6592\n",
            "Epoch 59 | Batch: 4 | Loss: 20.2863\n",
            "Epoch 59 | Batch: 5 | Loss: 13.8600\n",
            "Epoch 59 | Batch: 6 | Loss: 13.0046\n",
            "Epoch 59 | Batch: 7 | Loss: 13.3838\n",
            "Epoch 59 | Batch: 8 | Loss: 20.0178\n",
            "Epoch 59 | Batch: 9 | Loss: 12.1220\n",
            "Epoch 59 | Batch: 10 | Loss: 13.7082\n",
            "Epoch 59 | Batch: 11 | Loss: 11.9328\n",
            "Epoch 59 | Batch: 12 | Loss: 12.8215\n",
            "Epoch 59 | Batch: 13 | Loss: 15.5298\n",
            "Epoch 59 | Batch: 14 | Loss: 17.0026\n",
            "Epoch 59 | Batch: 15 | Loss: 12.2809\n",
            "Epoch 59 | Batch: 16 | Loss: 12.1114\n",
            "Epoch 59 | Batch: 17 | Loss: 14.9590\n",
            "Epoch 59 | Batch: 18 | Loss: 18.6506\n",
            "Epoch 59 | Batch: 19 | Loss: 14.3114\n",
            "Epoch 59 | Batch: 20 | Loss: 14.6448\n",
            "Epoch 59 | Batch: 21 | Loss: 20.6193\n",
            "Epoch 59 | Batch: 22 | Loss: 15.6336\n",
            "Epoch 59 | Batch: 23 | Loss: 13.5880\n",
            "Epoch 59 | Batch: 24 | Loss: 9.6864\n",
            "Epoch 60 | Batch: 1 | Loss: 15.9203\n",
            "Epoch 60 | Batch: 2 | Loss: 16.1511\n",
            "Epoch 60 | Batch: 3 | Loss: 11.4536\n",
            "Epoch 60 | Batch: 4 | Loss: 13.7669\n",
            "Epoch 60 | Batch: 5 | Loss: 16.6241\n",
            "Epoch 60 | Batch: 6 | Loss: 13.9890\n",
            "Epoch 60 | Batch: 7 | Loss: 22.0747\n",
            "Epoch 60 | Batch: 8 | Loss: 14.9250\n",
            "Epoch 60 | Batch: 9 | Loss: 17.4504\n",
            "Epoch 60 | Batch: 10 | Loss: 13.7362\n",
            "Epoch 60 | Batch: 11 | Loss: 18.0372\n",
            "Epoch 60 | Batch: 12 | Loss: 13.4603\n",
            "Epoch 60 | Batch: 13 | Loss: 15.3951\n",
            "Epoch 60 | Batch: 14 | Loss: 10.4363\n",
            "Epoch 60 | Batch: 15 | Loss: 13.3515\n",
            "Epoch 60 | Batch: 16 | Loss: 21.3925\n",
            "Epoch 60 | Batch: 17 | Loss: 17.7134\n",
            "Epoch 60 | Batch: 18 | Loss: 11.1688\n",
            "Epoch 60 | Batch: 19 | Loss: 19.5903\n",
            "Epoch 60 | Batch: 20 | Loss: 16.0931\n",
            "Epoch 60 | Batch: 21 | Loss: 15.4168\n",
            "Epoch 60 | Batch: 22 | Loss: 15.3266\n",
            "Epoch 60 | Batch: 23 | Loss: 16.9115\n",
            "Epoch 60 | Batch: 24 | Loss: 13.1390\n",
            "Epoch 61 | Batch: 1 | Loss: 15.0004\n",
            "Epoch 61 | Batch: 2 | Loss: 13.4924\n",
            "Epoch 61 | Batch: 3 | Loss: 13.7953\n",
            "Epoch 61 | Batch: 4 | Loss: 13.4535\n",
            "Epoch 61 | Batch: 5 | Loss: 16.7280\n",
            "Epoch 61 | Batch: 6 | Loss: 12.9607\n",
            "Epoch 61 | Batch: 7 | Loss: 20.1097\n",
            "Epoch 61 | Batch: 8 | Loss: 11.6283\n",
            "Epoch 61 | Batch: 9 | Loss: 8.6668\n",
            "Epoch 61 | Batch: 10 | Loss: 17.6646\n",
            "Epoch 61 | Batch: 11 | Loss: 16.7543\n",
            "Epoch 61 | Batch: 12 | Loss: 13.6938\n",
            "Epoch 61 | Batch: 13 | Loss: 17.2225\n",
            "Epoch 61 | Batch: 14 | Loss: 13.9832\n",
            "Epoch 61 | Batch: 15 | Loss: 15.0261\n",
            "Epoch 61 | Batch: 16 | Loss: 18.1194\n",
            "Epoch 61 | Batch: 17 | Loss: 16.4664\n",
            "Epoch 61 | Batch: 18 | Loss: 14.6953\n",
            "Epoch 61 | Batch: 19 | Loss: 10.5231\n",
            "Epoch 61 | Batch: 20 | Loss: 19.7470\n",
            "Epoch 61 | Batch: 21 | Loss: 10.0355\n",
            "Epoch 61 | Batch: 22 | Loss: 20.6520\n",
            "Epoch 61 | Batch: 23 | Loss: 12.0490\n",
            "Epoch 61 | Batch: 24 | Loss: 10.6550\n",
            "Epoch 62 | Batch: 1 | Loss: 16.8321\n",
            "Epoch 62 | Batch: 2 | Loss: 10.6921\n",
            "Epoch 62 | Batch: 3 | Loss: 16.8087\n",
            "Epoch 62 | Batch: 4 | Loss: 11.7005\n",
            "Epoch 62 | Batch: 5 | Loss: 16.1459\n",
            "Epoch 62 | Batch: 6 | Loss: 17.7401\n",
            "Epoch 62 | Batch: 7 | Loss: 13.0137\n",
            "Epoch 62 | Batch: 8 | Loss: 14.8787\n",
            "Epoch 62 | Batch: 9 | Loss: 19.5052\n",
            "Epoch 62 | Batch: 10 | Loss: 14.7358\n",
            "Epoch 62 | Batch: 11 | Loss: 11.4804\n",
            "Epoch 62 | Batch: 12 | Loss: 12.4984\n",
            "Epoch 62 | Batch: 13 | Loss: 14.3327\n",
            "Epoch 62 | Batch: 14 | Loss: 14.0029\n",
            "Epoch 62 | Batch: 15 | Loss: 14.8600\n",
            "Epoch 62 | Batch: 16 | Loss: 12.5943\n",
            "Epoch 62 | Batch: 17 | Loss: 13.8343\n",
            "Epoch 62 | Batch: 18 | Loss: 14.5988\n",
            "Epoch 62 | Batch: 19 | Loss: 18.7316\n",
            "Epoch 62 | Batch: 20 | Loss: 19.3170\n",
            "Epoch 62 | Batch: 21 | Loss: 14.4604\n",
            "Epoch 62 | Batch: 22 | Loss: 15.9044\n",
            "Epoch 62 | Batch: 23 | Loss: 15.1962\n",
            "Epoch 62 | Batch: 24 | Loss: 10.3537\n",
            "Epoch 63 | Batch: 1 | Loss: 16.5651\n",
            "Epoch 63 | Batch: 2 | Loss: 18.4177\n",
            "Epoch 63 | Batch: 3 | Loss: 16.0963\n",
            "Epoch 63 | Batch: 4 | Loss: 16.2505\n",
            "Epoch 63 | Batch: 5 | Loss: 16.6471\n",
            "Epoch 63 | Batch: 6 | Loss: 15.5081\n",
            "Epoch 63 | Batch: 7 | Loss: 16.1875\n",
            "Epoch 63 | Batch: 8 | Loss: 23.7124\n",
            "Epoch 63 | Batch: 9 | Loss: 19.6044\n",
            "Epoch 63 | Batch: 10 | Loss: 18.8978\n",
            "Epoch 63 | Batch: 11 | Loss: 16.0864\n",
            "Epoch 63 | Batch: 12 | Loss: 12.4751\n",
            "Epoch 63 | Batch: 13 | Loss: 15.0411\n",
            "Epoch 63 | Batch: 14 | Loss: 12.0237\n",
            "Epoch 63 | Batch: 15 | Loss: 13.3701\n",
            "Epoch 63 | Batch: 16 | Loss: 22.5128\n",
            "Epoch 63 | Batch: 17 | Loss: 18.0954\n",
            "Epoch 63 | Batch: 18 | Loss: 14.2045\n",
            "Epoch 63 | Batch: 19 | Loss: 12.8678\n",
            "Epoch 63 | Batch: 20 | Loss: 14.6366\n",
            "Epoch 63 | Batch: 21 | Loss: 12.6992\n",
            "Epoch 63 | Batch: 22 | Loss: 13.1647\n",
            "Epoch 63 | Batch: 23 | Loss: 15.6819\n",
            "Epoch 63 | Batch: 24 | Loss: 3.4975\n",
            "Epoch 64 | Batch: 1 | Loss: 15.4689\n",
            "Epoch 64 | Batch: 2 | Loss: 17.0925\n",
            "Epoch 64 | Batch: 3 | Loss: 17.0314\n",
            "Epoch 64 | Batch: 4 | Loss: 12.6366\n",
            "Epoch 64 | Batch: 5 | Loss: 15.8743\n",
            "Epoch 64 | Batch: 6 | Loss: 14.7663\n",
            "Epoch 64 | Batch: 7 | Loss: 17.0812\n",
            "Epoch 64 | Batch: 8 | Loss: 12.7799\n",
            "Epoch 64 | Batch: 9 | Loss: 13.1894\n",
            "Epoch 64 | Batch: 10 | Loss: 11.1759\n",
            "Epoch 64 | Batch: 11 | Loss: 16.5514\n",
            "Epoch 64 | Batch: 12 | Loss: 12.2551\n",
            "Epoch 64 | Batch: 13 | Loss: 16.1129\n",
            "Epoch 64 | Batch: 14 | Loss: 12.9368\n",
            "Epoch 64 | Batch: 15 | Loss: 16.6073\n",
            "Epoch 64 | Batch: 16 | Loss: 14.0910\n",
            "Epoch 64 | Batch: 17 | Loss: 18.0429\n",
            "Epoch 64 | Batch: 18 | Loss: 15.3633\n",
            "Epoch 64 | Batch: 19 | Loss: 17.1614\n",
            "Epoch 64 | Batch: 20 | Loss: 16.1006\n",
            "Epoch 64 | Batch: 21 | Loss: 20.0156\n",
            "Epoch 64 | Batch: 22 | Loss: 10.0342\n",
            "Epoch 64 | Batch: 23 | Loss: 13.7254\n",
            "Epoch 64 | Batch: 24 | Loss: 7.6342\n",
            "Epoch 65 | Batch: 1 | Loss: 15.0314\n",
            "Epoch 65 | Batch: 2 | Loss: 11.4648\n",
            "Epoch 65 | Batch: 3 | Loss: 19.7265\n",
            "Epoch 65 | Batch: 4 | Loss: 20.6088\n",
            "Epoch 65 | Batch: 5 | Loss: 15.1077\n",
            "Epoch 65 | Batch: 6 | Loss: 16.7744\n",
            "Epoch 65 | Batch: 7 | Loss: 15.6994\n",
            "Epoch 65 | Batch: 8 | Loss: 15.3686\n",
            "Epoch 65 | Batch: 9 | Loss: 10.6215\n",
            "Epoch 65 | Batch: 10 | Loss: 20.9943\n",
            "Epoch 65 | Batch: 11 | Loss: 11.5293\n",
            "Epoch 65 | Batch: 12 | Loss: 14.9462\n",
            "Epoch 65 | Batch: 13 | Loss: 11.4215\n",
            "Epoch 65 | Batch: 14 | Loss: 14.4903\n",
            "Epoch 65 | Batch: 15 | Loss: 12.9301\n",
            "Epoch 65 | Batch: 16 | Loss: 19.8442\n",
            "Epoch 65 | Batch: 17 | Loss: 12.3646\n",
            "Epoch 65 | Batch: 18 | Loss: 15.8349\n",
            "Epoch 65 | Batch: 19 | Loss: 10.8489\n",
            "Epoch 65 | Batch: 20 | Loss: 17.9240\n",
            "Epoch 65 | Batch: 21 | Loss: 10.5605\n",
            "Epoch 65 | Batch: 22 | Loss: 16.0497\n",
            "Epoch 65 | Batch: 23 | Loss: 12.0711\n",
            "Epoch 65 | Batch: 24 | Loss: 11.9635\n",
            "Epoch 66 | Batch: 1 | Loss: 17.0827\n",
            "Epoch 66 | Batch: 2 | Loss: 11.1642\n",
            "Epoch 66 | Batch: 3 | Loss: 18.6906\n",
            "Epoch 66 | Batch: 4 | Loss: 13.7582\n",
            "Epoch 66 | Batch: 5 | Loss: 13.8189\n",
            "Epoch 66 | Batch: 6 | Loss: 10.8806\n",
            "Epoch 66 | Batch: 7 | Loss: 18.1829\n",
            "Epoch 66 | Batch: 8 | Loss: 13.4062\n",
            "Epoch 66 | Batch: 9 | Loss: 12.7751\n",
            "Epoch 66 | Batch: 10 | Loss: 12.7205\n",
            "Epoch 66 | Batch: 11 | Loss: 10.3809\n",
            "Epoch 66 | Batch: 12 | Loss: 13.7346\n",
            "Epoch 66 | Batch: 13 | Loss: 17.1997\n",
            "Epoch 66 | Batch: 14 | Loss: 23.3737\n",
            "Epoch 66 | Batch: 15 | Loss: 16.4829\n",
            "Epoch 66 | Batch: 16 | Loss: 14.3300\n",
            "Epoch 66 | Batch: 17 | Loss: 14.3278\n",
            "Epoch 66 | Batch: 18 | Loss: 16.8012\n",
            "Epoch 66 | Batch: 19 | Loss: 20.7724\n",
            "Epoch 66 | Batch: 20 | Loss: 12.5415\n",
            "Epoch 66 | Batch: 21 | Loss: 13.8006\n",
            "Epoch 66 | Batch: 22 | Loss: 12.3501\n",
            "Epoch 66 | Batch: 23 | Loss: 12.6549\n",
            "Epoch 66 | Batch: 24 | Loss: 17.7020\n",
            "Epoch 67 | Batch: 1 | Loss: 19.8888\n",
            "Epoch 67 | Batch: 2 | Loss: 12.8056\n",
            "Epoch 67 | Batch: 3 | Loss: 11.0496\n",
            "Epoch 67 | Batch: 4 | Loss: 16.7308\n",
            "Epoch 67 | Batch: 5 | Loss: 10.4096\n",
            "Epoch 67 | Batch: 6 | Loss: 14.2241\n",
            "Epoch 67 | Batch: 7 | Loss: 13.7839\n",
            "Epoch 67 | Batch: 8 | Loss: 13.4625\n",
            "Epoch 67 | Batch: 9 | Loss: 20.4089\n",
            "Epoch 67 | Batch: 10 | Loss: 21.3014\n",
            "Epoch 67 | Batch: 11 | Loss: 17.4667\n",
            "Epoch 67 | Batch: 12 | Loss: 19.8110\n",
            "Epoch 67 | Batch: 13 | Loss: 13.3156\n",
            "Epoch 67 | Batch: 14 | Loss: 12.0069\n",
            "Epoch 67 | Batch: 15 | Loss: 20.5579\n",
            "Epoch 67 | Batch: 16 | Loss: 12.5158\n",
            "Epoch 67 | Batch: 17 | Loss: 16.6738\n",
            "Epoch 67 | Batch: 18 | Loss: 11.9307\n",
            "Epoch 67 | Batch: 19 | Loss: 13.3217\n",
            "Epoch 67 | Batch: 20 | Loss: 17.3251\n",
            "Epoch 67 | Batch: 21 | Loss: 17.6848\n",
            "Epoch 67 | Batch: 22 | Loss: 11.6857\n",
            "Epoch 67 | Batch: 23 | Loss: 16.5442\n",
            "Epoch 67 | Batch: 24 | Loss: 11.8041\n",
            "Epoch 68 | Batch: 1 | Loss: 15.3795\n",
            "Epoch 68 | Batch: 2 | Loss: 18.4299\n",
            "Epoch 68 | Batch: 3 | Loss: 16.5846\n",
            "Epoch 68 | Batch: 4 | Loss: 16.7363\n",
            "Epoch 68 | Batch: 5 | Loss: 11.6349\n",
            "Epoch 68 | Batch: 6 | Loss: 11.5612\n",
            "Epoch 68 | Batch: 7 | Loss: 18.5256\n",
            "Epoch 68 | Batch: 8 | Loss: 16.9931\n",
            "Epoch 68 | Batch: 9 | Loss: 12.8102\n",
            "Epoch 68 | Batch: 10 | Loss: 12.7260\n",
            "Epoch 68 | Batch: 11 | Loss: 13.7419\n",
            "Epoch 68 | Batch: 12 | Loss: 20.3082\n",
            "Epoch 68 | Batch: 13 | Loss: 12.9089\n",
            "Epoch 68 | Batch: 14 | Loss: 14.0636\n",
            "Epoch 68 | Batch: 15 | Loss: 8.2446\n",
            "Epoch 68 | Batch: 16 | Loss: 15.6162\n",
            "Epoch 68 | Batch: 17 | Loss: 16.3266\n",
            "Epoch 68 | Batch: 18 | Loss: 15.8869\n",
            "Epoch 68 | Batch: 19 | Loss: 12.6210\n",
            "Epoch 68 | Batch: 20 | Loss: 20.0707\n",
            "Epoch 68 | Batch: 21 | Loss: 15.8929\n",
            "Epoch 68 | Batch: 22 | Loss: 17.2537\n",
            "Epoch 68 | Batch: 23 | Loss: 15.9533\n",
            "Epoch 68 | Batch: 24 | Loss: 5.1596\n",
            "Epoch 69 | Batch: 1 | Loss: 12.4262\n",
            "Epoch 69 | Batch: 2 | Loss: 14.2620\n",
            "Epoch 69 | Batch: 3 | Loss: 8.3290\n",
            "Epoch 69 | Batch: 4 | Loss: 13.0129\n",
            "Epoch 69 | Batch: 5 | Loss: 19.3149\n",
            "Epoch 69 | Batch: 6 | Loss: 17.5117\n",
            "Epoch 69 | Batch: 7 | Loss: 24.8258\n",
            "Epoch 69 | Batch: 8 | Loss: 14.4643\n",
            "Epoch 69 | Batch: 9 | Loss: 19.5510\n",
            "Epoch 69 | Batch: 10 | Loss: 15.1253\n",
            "Epoch 69 | Batch: 11 | Loss: 13.3007\n",
            "Epoch 69 | Batch: 12 | Loss: 15.8137\n",
            "Epoch 69 | Batch: 13 | Loss: 14.4690\n",
            "Epoch 69 | Batch: 14 | Loss: 14.4093\n",
            "Epoch 69 | Batch: 15 | Loss: 12.1836\n",
            "Epoch 69 | Batch: 16 | Loss: 17.7513\n",
            "Epoch 69 | Batch: 17 | Loss: 14.2333\n",
            "Epoch 69 | Batch: 18 | Loss: 15.9244\n",
            "Epoch 69 | Batch: 19 | Loss: 13.9623\n",
            "Epoch 69 | Batch: 20 | Loss: 14.1272\n",
            "Epoch 69 | Batch: 21 | Loss: 15.4043\n",
            "Epoch 69 | Batch: 22 | Loss: 17.0435\n",
            "Epoch 69 | Batch: 23 | Loss: 14.3828\n",
            "Epoch 69 | Batch: 24 | Loss: 8.8945\n",
            "Epoch 70 | Batch: 1 | Loss: 19.8512\n",
            "Epoch 70 | Batch: 2 | Loss: 25.0295\n",
            "Epoch 70 | Batch: 3 | Loss: 12.6153\n",
            "Epoch 70 | Batch: 4 | Loss: 8.0363\n",
            "Epoch 70 | Batch: 5 | Loss: 18.9006\n",
            "Epoch 70 | Batch: 6 | Loss: 8.5021\n",
            "Epoch 70 | Batch: 7 | Loss: 21.5616\n",
            "Epoch 70 | Batch: 8 | Loss: 9.4967\n",
            "Epoch 70 | Batch: 9 | Loss: 22.9571\n",
            "Epoch 70 | Batch: 10 | Loss: 18.8245\n",
            "Epoch 70 | Batch: 11 | Loss: 20.2764\n",
            "Epoch 70 | Batch: 12 | Loss: 14.9503\n",
            "Epoch 70 | Batch: 13 | Loss: 12.8573\n",
            "Epoch 70 | Batch: 14 | Loss: 17.6550\n",
            "Epoch 70 | Batch: 15 | Loss: 24.3659\n",
            "Epoch 70 | Batch: 16 | Loss: 16.4918\n",
            "Epoch 70 | Batch: 17 | Loss: 13.8552\n",
            "Epoch 70 | Batch: 18 | Loss: 16.6744\n",
            "Epoch 70 | Batch: 19 | Loss: 14.0870\n",
            "Epoch 70 | Batch: 20 | Loss: 13.0815\n",
            "Epoch 70 | Batch: 21 | Loss: 10.3843\n",
            "Epoch 70 | Batch: 22 | Loss: 15.2358\n",
            "Epoch 70 | Batch: 23 | Loss: 20.5408\n",
            "Epoch 70 | Batch: 24 | Loss: 10.4160\n",
            "Epoch 71 | Batch: 1 | Loss: 12.0830\n",
            "Epoch 71 | Batch: 2 | Loss: 15.3206\n",
            "Epoch 71 | Batch: 3 | Loss: 11.8607\n",
            "Epoch 71 | Batch: 4 | Loss: 10.8404\n",
            "Epoch 71 | Batch: 5 | Loss: 14.4569\n",
            "Epoch 71 | Batch: 6 | Loss: 17.7374\n",
            "Epoch 71 | Batch: 7 | Loss: 9.6469\n",
            "Epoch 71 | Batch: 8 | Loss: 17.6787\n",
            "Epoch 71 | Batch: 9 | Loss: 14.6979\n",
            "Epoch 71 | Batch: 10 | Loss: 9.5600\n",
            "Epoch 71 | Batch: 11 | Loss: 15.6964\n",
            "Epoch 71 | Batch: 12 | Loss: 14.3244\n",
            "Epoch 71 | Batch: 13 | Loss: 17.6011\n",
            "Epoch 71 | Batch: 14 | Loss: 20.3320\n",
            "Epoch 71 | Batch: 15 | Loss: 14.1744\n",
            "Epoch 71 | Batch: 16 | Loss: 18.9728\n",
            "Epoch 71 | Batch: 17 | Loss: 15.5133\n",
            "Epoch 71 | Batch: 18 | Loss: 16.5809\n",
            "Epoch 71 | Batch: 19 | Loss: 12.4901\n",
            "Epoch 71 | Batch: 20 | Loss: 11.8654\n",
            "Epoch 71 | Batch: 21 | Loss: 12.5701\n",
            "Epoch 71 | Batch: 22 | Loss: 13.8558\n",
            "Epoch 71 | Batch: 23 | Loss: 17.7561\n",
            "Epoch 71 | Batch: 24 | Loss: 10.7765\n",
            "Epoch 72 | Batch: 1 | Loss: 17.0724\n",
            "Epoch 72 | Batch: 2 | Loss: 14.8319\n",
            "Epoch 72 | Batch: 3 | Loss: 10.9421\n",
            "Epoch 72 | Batch: 4 | Loss: 17.6337\n",
            "Epoch 72 | Batch: 5 | Loss: 19.8162\n",
            "Epoch 72 | Batch: 6 | Loss: 16.7389\n",
            "Epoch 72 | Batch: 7 | Loss: 12.1169\n",
            "Epoch 72 | Batch: 8 | Loss: 10.1576\n",
            "Epoch 72 | Batch: 9 | Loss: 13.1794\n",
            "Epoch 72 | Batch: 10 | Loss: 14.2986\n",
            "Epoch 72 | Batch: 11 | Loss: 19.6891\n",
            "Epoch 72 | Batch: 12 | Loss: 22.1554\n",
            "Epoch 72 | Batch: 13 | Loss: 13.8372\n",
            "Epoch 72 | Batch: 14 | Loss: 12.3883\n",
            "Epoch 72 | Batch: 15 | Loss: 11.6393\n",
            "Epoch 72 | Batch: 16 | Loss: 14.6239\n",
            "Epoch 72 | Batch: 17 | Loss: 11.3957\n",
            "Epoch 72 | Batch: 18 | Loss: 18.1354\n",
            "Epoch 72 | Batch: 19 | Loss: 14.4397\n",
            "Epoch 72 | Batch: 20 | Loss: 14.3031\n",
            "Epoch 72 | Batch: 21 | Loss: 11.6647\n",
            "Epoch 72 | Batch: 22 | Loss: 15.0300\n",
            "Epoch 72 | Batch: 23 | Loss: 13.7854\n",
            "Epoch 72 | Batch: 24 | Loss: 10.5482\n",
            "Epoch 73 | Batch: 1 | Loss: 16.9621\n",
            "Epoch 73 | Batch: 2 | Loss: 17.6587\n",
            "Epoch 73 | Batch: 3 | Loss: 16.7508\n",
            "Epoch 73 | Batch: 4 | Loss: 20.3894\n",
            "Epoch 73 | Batch: 5 | Loss: 11.2452\n",
            "Epoch 73 | Batch: 6 | Loss: 15.0289\n",
            "Epoch 73 | Batch: 7 | Loss: 17.1922\n",
            "Epoch 73 | Batch: 8 | Loss: 14.1260\n",
            "Epoch 73 | Batch: 9 | Loss: 11.5234\n",
            "Epoch 73 | Batch: 10 | Loss: 14.0727\n",
            "Epoch 73 | Batch: 11 | Loss: 11.6549\n",
            "Epoch 73 | Batch: 12 | Loss: 14.4991\n",
            "Epoch 73 | Batch: 13 | Loss: 12.3045\n",
            "Epoch 73 | Batch: 14 | Loss: 16.2350\n",
            "Epoch 73 | Batch: 15 | Loss: 12.9789\n",
            "Epoch 73 | Batch: 16 | Loss: 12.9811\n",
            "Epoch 73 | Batch: 17 | Loss: 8.1384\n",
            "Epoch 73 | Batch: 18 | Loss: 16.3207\n",
            "Epoch 73 | Batch: 19 | Loss: 11.1831\n",
            "Epoch 73 | Batch: 20 | Loss: 17.0231\n",
            "Epoch 73 | Batch: 21 | Loss: 19.2488\n",
            "Epoch 73 | Batch: 22 | Loss: 14.7020\n",
            "Epoch 73 | Batch: 23 | Loss: 19.2206\n",
            "Epoch 73 | Batch: 24 | Loss: 11.4603\n",
            "Epoch 74 | Batch: 1 | Loss: 14.8030\n",
            "Epoch 74 | Batch: 2 | Loss: 11.9832\n",
            "Epoch 74 | Batch: 3 | Loss: 12.3731\n",
            "Epoch 74 | Batch: 4 | Loss: 25.9038\n",
            "Epoch 74 | Batch: 5 | Loss: 15.9921\n",
            "Epoch 74 | Batch: 6 | Loss: 15.3626\n",
            "Epoch 74 | Batch: 7 | Loss: 14.1069\n",
            "Epoch 74 | Batch: 8 | Loss: 17.0930\n",
            "Epoch 74 | Batch: 9 | Loss: 19.2548\n",
            "Epoch 74 | Batch: 10 | Loss: 12.6400\n",
            "Epoch 74 | Batch: 11 | Loss: 15.9134\n",
            "Epoch 74 | Batch: 12 | Loss: 18.1446\n",
            "Epoch 74 | Batch: 13 | Loss: 17.5190\n",
            "Epoch 74 | Batch: 14 | Loss: 11.8972\n",
            "Epoch 74 | Batch: 15 | Loss: 11.9641\n",
            "Epoch 74 | Batch: 16 | Loss: 18.9643\n",
            "Epoch 74 | Batch: 17 | Loss: 21.4684\n",
            "Epoch 74 | Batch: 18 | Loss: 14.3606\n",
            "Epoch 74 | Batch: 19 | Loss: 12.1244\n",
            "Epoch 74 | Batch: 20 | Loss: 15.7952\n",
            "Epoch 74 | Batch: 21 | Loss: 13.7931\n",
            "Epoch 74 | Batch: 22 | Loss: 13.1657\n",
            "Epoch 74 | Batch: 23 | Loss: 20.9627\n",
            "Epoch 74 | Batch: 24 | Loss: 11.6202\n",
            "Epoch 75 | Batch: 1 | Loss: 17.0588\n",
            "Epoch 75 | Batch: 2 | Loss: 14.6422\n",
            "Epoch 75 | Batch: 3 | Loss: 14.9405\n",
            "Epoch 75 | Batch: 4 | Loss: 14.5933\n",
            "Epoch 75 | Batch: 5 | Loss: 14.0819\n",
            "Epoch 75 | Batch: 6 | Loss: 13.4706\n",
            "Epoch 75 | Batch: 7 | Loss: 14.2664\n",
            "Epoch 75 | Batch: 8 | Loss: 13.6362\n",
            "Epoch 75 | Batch: 9 | Loss: 14.2361\n",
            "Epoch 75 | Batch: 10 | Loss: 17.9226\n",
            "Epoch 75 | Batch: 11 | Loss: 13.6563\n",
            "Epoch 75 | Batch: 12 | Loss: 13.5414\n",
            "Epoch 75 | Batch: 13 | Loss: 20.3383\n",
            "Epoch 75 | Batch: 14 | Loss: 13.9523\n",
            "Epoch 75 | Batch: 15 | Loss: 15.9875\n",
            "Epoch 75 | Batch: 16 | Loss: 11.7757\n",
            "Epoch 75 | Batch: 17 | Loss: 15.8341\n",
            "Epoch 75 | Batch: 18 | Loss: 10.0993\n",
            "Epoch 75 | Batch: 19 | Loss: 10.9637\n",
            "Epoch 75 | Batch: 20 | Loss: 11.6867\n",
            "Epoch 75 | Batch: 21 | Loss: 15.6607\n",
            "Epoch 75 | Batch: 22 | Loss: 13.5967\n",
            "Epoch 75 | Batch: 23 | Loss: 22.5870\n",
            "Epoch 75 | Batch: 24 | Loss: 15.3247\n",
            "Epoch 76 | Batch: 1 | Loss: 13.5670\n",
            "Epoch 76 | Batch: 2 | Loss: 13.9769\n",
            "Epoch 76 | Batch: 3 | Loss: 15.5808\n",
            "Epoch 76 | Batch: 4 | Loss: 16.0631\n",
            "Epoch 76 | Batch: 5 | Loss: 12.4401\n",
            "Epoch 76 | Batch: 6 | Loss: 7.9043\n",
            "Epoch 76 | Batch: 7 | Loss: 10.1896\n",
            "Epoch 76 | Batch: 8 | Loss: 14.2484\n",
            "Epoch 76 | Batch: 9 | Loss: 12.5046\n",
            "Epoch 76 | Batch: 10 | Loss: 15.2939\n",
            "Epoch 76 | Batch: 11 | Loss: 13.8202\n",
            "Epoch 76 | Batch: 12 | Loss: 10.1843\n",
            "Epoch 76 | Batch: 13 | Loss: 11.3332\n",
            "Epoch 76 | Batch: 14 | Loss: 14.4878\n",
            "Epoch 76 | Batch: 15 | Loss: 14.0901\n",
            "Epoch 76 | Batch: 16 | Loss: 13.9019\n",
            "Epoch 76 | Batch: 17 | Loss: 18.3533\n",
            "Epoch 76 | Batch: 18 | Loss: 29.9514\n",
            "Epoch 76 | Batch: 19 | Loss: 14.8120\n",
            "Epoch 76 | Batch: 20 | Loss: 13.3758\n",
            "Epoch 76 | Batch: 21 | Loss: 15.6764\n",
            "Epoch 76 | Batch: 22 | Loss: 20.2659\n",
            "Epoch 76 | Batch: 23 | Loss: 9.1147\n",
            "Epoch 76 | Batch: 24 | Loss: 13.5838\n",
            "Epoch 77 | Batch: 1 | Loss: 15.1010\n",
            "Epoch 77 | Batch: 2 | Loss: 15.3432\n",
            "Epoch 77 | Batch: 3 | Loss: 19.8407\n",
            "Epoch 77 | Batch: 4 | Loss: 15.8098\n",
            "Epoch 77 | Batch: 5 | Loss: 13.3639\n",
            "Epoch 77 | Batch: 6 | Loss: 13.6628\n",
            "Epoch 77 | Batch: 7 | Loss: 18.7501\n",
            "Epoch 77 | Batch: 8 | Loss: 15.6760\n",
            "Epoch 77 | Batch: 9 | Loss: 18.2553\n",
            "Epoch 77 | Batch: 10 | Loss: 13.3561\n",
            "Epoch 77 | Batch: 11 | Loss: 9.3356\n",
            "Epoch 77 | Batch: 12 | Loss: 15.2502\n",
            "Epoch 77 | Batch: 13 | Loss: 12.7102\n",
            "Epoch 77 | Batch: 14 | Loss: 8.6508\n",
            "Epoch 77 | Batch: 15 | Loss: 16.7236\n",
            "Epoch 77 | Batch: 16 | Loss: 11.8750\n",
            "Epoch 77 | Batch: 17 | Loss: 16.1333\n",
            "Epoch 77 | Batch: 18 | Loss: 16.5165\n",
            "Epoch 77 | Batch: 19 | Loss: 11.3714\n",
            "Epoch 77 | Batch: 20 | Loss: 15.5815\n",
            "Epoch 77 | Batch: 21 | Loss: 13.0956\n",
            "Epoch 77 | Batch: 22 | Loss: 14.1589\n",
            "Epoch 77 | Batch: 23 | Loss: 12.6088\n",
            "Epoch 77 | Batch: 24 | Loss: 17.2525\n",
            "Epoch 78 | Batch: 1 | Loss: 13.9288\n",
            "Epoch 78 | Batch: 2 | Loss: 14.3959\n",
            "Epoch 78 | Batch: 3 | Loss: 13.0815\n",
            "Epoch 78 | Batch: 4 | Loss: 18.8287\n",
            "Epoch 78 | Batch: 5 | Loss: 17.4983\n",
            "Epoch 78 | Batch: 6 | Loss: 12.9152\n",
            "Epoch 78 | Batch: 7 | Loss: 11.2377\n",
            "Epoch 78 | Batch: 8 | Loss: 15.5730\n",
            "Epoch 78 | Batch: 9 | Loss: 13.3198\n",
            "Epoch 78 | Batch: 10 | Loss: 14.4372\n",
            "Epoch 78 | Batch: 11 | Loss: 14.5252\n",
            "Epoch 78 | Batch: 12 | Loss: 15.5989\n",
            "Epoch 78 | Batch: 13 | Loss: 12.5669\n",
            "Epoch 78 | Batch: 14 | Loss: 12.8892\n",
            "Epoch 78 | Batch: 15 | Loss: 8.5479\n",
            "Epoch 78 | Batch: 16 | Loss: 15.4454\n",
            "Epoch 78 | Batch: 17 | Loss: 17.2492\n",
            "Epoch 78 | Batch: 18 | Loss: 12.8125\n",
            "Epoch 78 | Batch: 19 | Loss: 13.5011\n",
            "Epoch 78 | Batch: 20 | Loss: 14.9008\n",
            "Epoch 78 | Batch: 21 | Loss: 16.9277\n",
            "Epoch 78 | Batch: 22 | Loss: 14.7886\n",
            "Epoch 78 | Batch: 23 | Loss: 18.1440\n",
            "Epoch 78 | Batch: 24 | Loss: 13.4955\n",
            "Epoch 79 | Batch: 1 | Loss: 11.9320\n",
            "Epoch 79 | Batch: 2 | Loss: 16.8013\n",
            "Epoch 79 | Batch: 3 | Loss: 15.1208\n",
            "Epoch 79 | Batch: 4 | Loss: 18.3542\n",
            "Epoch 79 | Batch: 5 | Loss: 10.9157\n",
            "Epoch 79 | Batch: 6 | Loss: 16.5753\n",
            "Epoch 79 | Batch: 7 | Loss: 15.6197\n",
            "Epoch 79 | Batch: 8 | Loss: 11.4001\n",
            "Epoch 79 | Batch: 9 | Loss: 10.3805\n",
            "Epoch 79 | Batch: 10 | Loss: 15.6115\n",
            "Epoch 79 | Batch: 11 | Loss: 11.5719\n",
            "Epoch 79 | Batch: 12 | Loss: 17.9468\n",
            "Epoch 79 | Batch: 13 | Loss: 13.1830\n",
            "Epoch 79 | Batch: 14 | Loss: 22.5210\n",
            "Epoch 79 | Batch: 15 | Loss: 12.0107\n",
            "Epoch 79 | Batch: 16 | Loss: 18.0045\n",
            "Epoch 79 | Batch: 17 | Loss: 14.0990\n",
            "Epoch 79 | Batch: 18 | Loss: 16.6951\n",
            "Epoch 79 | Batch: 19 | Loss: 11.4060\n",
            "Epoch 79 | Batch: 20 | Loss: 10.2293\n",
            "Epoch 79 | Batch: 21 | Loss: 23.8954\n",
            "Epoch 79 | Batch: 22 | Loss: 13.9542\n",
            "Epoch 79 | Batch: 23 | Loss: 18.0504\n",
            "Epoch 79 | Batch: 24 | Loss: 12.6381\n",
            "Epoch 80 | Batch: 1 | Loss: 17.5432\n",
            "Epoch 80 | Batch: 2 | Loss: 15.2273\n",
            "Epoch 80 | Batch: 3 | Loss: 13.9247\n",
            "Epoch 80 | Batch: 4 | Loss: 17.1070\n",
            "Epoch 80 | Batch: 5 | Loss: 12.7268\n",
            "Epoch 80 | Batch: 6 | Loss: 18.5007\n",
            "Epoch 80 | Batch: 7 | Loss: 15.4874\n",
            "Epoch 80 | Batch: 8 | Loss: 14.5008\n",
            "Epoch 80 | Batch: 9 | Loss: 13.1123\n",
            "Epoch 80 | Batch: 10 | Loss: 11.8005\n",
            "Epoch 80 | Batch: 11 | Loss: 16.6663\n",
            "Epoch 80 | Batch: 12 | Loss: 20.1795\n",
            "Epoch 80 | Batch: 13 | Loss: 16.9249\n",
            "Epoch 80 | Batch: 14 | Loss: 14.3429\n",
            "Epoch 80 | Batch: 15 | Loss: 15.5362\n",
            "Epoch 80 | Batch: 16 | Loss: 10.3498\n",
            "Epoch 80 | Batch: 17 | Loss: 10.6231\n",
            "Epoch 80 | Batch: 18 | Loss: 10.6601\n",
            "Epoch 80 | Batch: 19 | Loss: 15.6034\n",
            "Epoch 80 | Batch: 20 | Loss: 11.5252\n",
            "Epoch 80 | Batch: 21 | Loss: 19.3599\n",
            "Epoch 80 | Batch: 22 | Loss: 17.0741\n",
            "Epoch 80 | Batch: 23 | Loss: 12.7633\n",
            "Epoch 80 | Batch: 24 | Loss: 11.7542\n",
            "Epoch 81 | Batch: 1 | Loss: 17.3484\n",
            "Epoch 81 | Batch: 2 | Loss: 16.9777\n",
            "Epoch 81 | Batch: 3 | Loss: 9.6983\n",
            "Epoch 81 | Batch: 4 | Loss: 15.4076\n",
            "Epoch 81 | Batch: 5 | Loss: 15.5892\n",
            "Epoch 81 | Batch: 6 | Loss: 18.1668\n",
            "Epoch 81 | Batch: 7 | Loss: 26.5891\n",
            "Epoch 81 | Batch: 8 | Loss: 12.1214\n",
            "Epoch 81 | Batch: 9 | Loss: 12.4475\n",
            "Epoch 81 | Batch: 10 | Loss: 15.2075\n",
            "Epoch 81 | Batch: 11 | Loss: 14.6515\n",
            "Epoch 81 | Batch: 12 | Loss: 17.6705\n",
            "Epoch 81 | Batch: 13 | Loss: 12.0271\n",
            "Epoch 81 | Batch: 14 | Loss: 18.7186\n",
            "Epoch 81 | Batch: 15 | Loss: 14.2791\n",
            "Epoch 81 | Batch: 16 | Loss: 12.6464\n",
            "Epoch 81 | Batch: 17 | Loss: 13.7280\n",
            "Epoch 81 | Batch: 18 | Loss: 9.4499\n",
            "Epoch 81 | Batch: 19 | Loss: 16.2722\n",
            "Epoch 81 | Batch: 20 | Loss: 14.9403\n",
            "Epoch 81 | Batch: 21 | Loss: 9.4057\n",
            "Epoch 81 | Batch: 22 | Loss: 13.4549\n",
            "Epoch 81 | Batch: 23 | Loss: 18.2162\n",
            "Epoch 81 | Batch: 24 | Loss: 12.0661\n",
            "Epoch 82 | Batch: 1 | Loss: 11.7638\n",
            "Epoch 82 | Batch: 2 | Loss: 14.5845\n",
            "Epoch 82 | Batch: 3 | Loss: 17.1142\n",
            "Epoch 82 | Batch: 4 | Loss: 15.5897\n",
            "Epoch 82 | Batch: 5 | Loss: 12.2731\n",
            "Epoch 82 | Batch: 6 | Loss: 19.2957\n",
            "Epoch 82 | Batch: 7 | Loss: 14.7604\n",
            "Epoch 82 | Batch: 8 | Loss: 15.6540\n",
            "Epoch 82 | Batch: 9 | Loss: 11.4681\n",
            "Epoch 82 | Batch: 10 | Loss: 17.1672\n",
            "Epoch 82 | Batch: 11 | Loss: 12.8199\n",
            "Epoch 82 | Batch: 12 | Loss: 14.0357\n",
            "Epoch 82 | Batch: 13 | Loss: 9.9964\n",
            "Epoch 82 | Batch: 14 | Loss: 16.4834\n",
            "Epoch 82 | Batch: 15 | Loss: 12.3711\n",
            "Epoch 82 | Batch: 16 | Loss: 16.4986\n",
            "Epoch 82 | Batch: 17 | Loss: 13.9720\n",
            "Epoch 82 | Batch: 18 | Loss: 14.0127\n",
            "Epoch 82 | Batch: 19 | Loss: 13.1803\n",
            "Epoch 82 | Batch: 20 | Loss: 13.5051\n",
            "Epoch 82 | Batch: 21 | Loss: 22.5529\n",
            "Epoch 82 | Batch: 22 | Loss: 16.3120\n",
            "Epoch 82 | Batch: 23 | Loss: 15.4923\n",
            "Epoch 82 | Batch: 24 | Loss: 12.4128\n",
            "Epoch 83 | Batch: 1 | Loss: 19.4573\n",
            "Epoch 83 | Batch: 2 | Loss: 14.2728\n",
            "Epoch 83 | Batch: 3 | Loss: 16.7351\n",
            "Epoch 83 | Batch: 4 | Loss: 15.8370\n",
            "Epoch 83 | Batch: 5 | Loss: 12.0309\n",
            "Epoch 83 | Batch: 6 | Loss: 16.6379\n",
            "Epoch 83 | Batch: 7 | Loss: 18.5113\n",
            "Epoch 83 | Batch: 8 | Loss: 11.0827\n",
            "Epoch 83 | Batch: 9 | Loss: 10.6455\n",
            "Epoch 83 | Batch: 10 | Loss: 10.2509\n",
            "Epoch 83 | Batch: 11 | Loss: 15.6147\n",
            "Epoch 83 | Batch: 12 | Loss: 8.8848\n",
            "Epoch 83 | Batch: 13 | Loss: 13.1505\n",
            "Epoch 83 | Batch: 14 | Loss: 10.4638\n",
            "Epoch 83 | Batch: 15 | Loss: 16.0590\n",
            "Epoch 83 | Batch: 16 | Loss: 13.7206\n",
            "Epoch 83 | Batch: 17 | Loss: 10.7753\n",
            "Epoch 83 | Batch: 18 | Loss: 20.4647\n",
            "Epoch 83 | Batch: 19 | Loss: 17.7640\n",
            "Epoch 83 | Batch: 20 | Loss: 17.6048\n",
            "Epoch 83 | Batch: 21 | Loss: 13.0272\n",
            "Epoch 83 | Batch: 22 | Loss: 14.7380\n",
            "Epoch 83 | Batch: 23 | Loss: 9.7248\n",
            "Epoch 83 | Batch: 24 | Loss: 17.5100\n",
            "Epoch 84 | Batch: 1 | Loss: 16.0552\n",
            "Epoch 84 | Batch: 2 | Loss: 11.7028\n",
            "Epoch 84 | Batch: 3 | Loss: 9.6654\n",
            "Epoch 84 | Batch: 4 | Loss: 14.3508\n",
            "Epoch 84 | Batch: 5 | Loss: 19.1688\n",
            "Epoch 84 | Batch: 6 | Loss: 14.2972\n",
            "Epoch 84 | Batch: 7 | Loss: 13.8586\n",
            "Epoch 84 | Batch: 8 | Loss: 12.4984\n",
            "Epoch 84 | Batch: 9 | Loss: 13.4116\n",
            "Epoch 84 | Batch: 10 | Loss: 13.2366\n",
            "Epoch 84 | Batch: 11 | Loss: 8.9080\n",
            "Epoch 84 | Batch: 12 | Loss: 16.6625\n",
            "Epoch 84 | Batch: 13 | Loss: 17.4086\n",
            "Epoch 84 | Batch: 14 | Loss: 13.5965\n",
            "Epoch 84 | Batch: 15 | Loss: 19.2752\n",
            "Epoch 84 | Batch: 16 | Loss: 17.8331\n",
            "Epoch 84 | Batch: 17 | Loss: 15.8254\n",
            "Epoch 84 | Batch: 18 | Loss: 15.7191\n",
            "Epoch 84 | Batch: 19 | Loss: 15.7178\n",
            "Epoch 84 | Batch: 20 | Loss: 13.9810\n",
            "Epoch 84 | Batch: 21 | Loss: 16.1953\n",
            "Epoch 84 | Batch: 22 | Loss: 12.9015\n",
            "Epoch 84 | Batch: 23 | Loss: 14.9535\n",
            "Epoch 84 | Batch: 24 | Loss: 6.1479\n",
            "Epoch 85 | Batch: 1 | Loss: 17.2633\n",
            "Epoch 85 | Batch: 2 | Loss: 16.1958\n",
            "Epoch 85 | Batch: 3 | Loss: 13.4751\n",
            "Epoch 85 | Batch: 4 | Loss: 22.9426\n",
            "Epoch 85 | Batch: 5 | Loss: 16.4923\n",
            "Epoch 85 | Batch: 6 | Loss: 13.5532\n",
            "Epoch 85 | Batch: 7 | Loss: 14.4245\n",
            "Epoch 85 | Batch: 8 | Loss: 10.3977\n",
            "Epoch 85 | Batch: 9 | Loss: 15.1853\n",
            "Epoch 85 | Batch: 10 | Loss: 15.1413\n",
            "Epoch 85 | Batch: 11 | Loss: 15.0455\n",
            "Epoch 85 | Batch: 12 | Loss: 15.3596\n",
            "Epoch 85 | Batch: 13 | Loss: 15.6178\n",
            "Epoch 85 | Batch: 14 | Loss: 10.4748\n",
            "Epoch 85 | Batch: 15 | Loss: 12.2704\n",
            "Epoch 85 | Batch: 16 | Loss: 14.5633\n",
            "Epoch 85 | Batch: 17 | Loss: 12.3809\n",
            "Epoch 85 | Batch: 18 | Loss: 17.4768\n",
            "Epoch 85 | Batch: 19 | Loss: 14.6152\n",
            "Epoch 85 | Batch: 20 | Loss: 16.2262\n",
            "Epoch 85 | Batch: 21 | Loss: 11.3281\n",
            "Epoch 85 | Batch: 22 | Loss: 15.0147\n",
            "Epoch 85 | Batch: 23 | Loss: 10.8685\n",
            "Epoch 85 | Batch: 24 | Loss: 6.3745\n",
            "Epoch 86 | Batch: 1 | Loss: 14.5635\n",
            "Epoch 86 | Batch: 2 | Loss: 13.4189\n",
            "Epoch 86 | Batch: 3 | Loss: 10.7880\n",
            "Epoch 86 | Batch: 4 | Loss: 7.3123\n",
            "Epoch 86 | Batch: 5 | Loss: 12.7532\n",
            "Epoch 86 | Batch: 6 | Loss: 18.3154\n",
            "Epoch 86 | Batch: 7 | Loss: 11.4210\n",
            "Epoch 86 | Batch: 8 | Loss: 14.3898\n",
            "Epoch 86 | Batch: 9 | Loss: 17.4518\n",
            "Epoch 86 | Batch: 10 | Loss: 13.6663\n",
            "Epoch 86 | Batch: 11 | Loss: 14.2684\n",
            "Epoch 86 | Batch: 12 | Loss: 9.3914\n",
            "Epoch 86 | Batch: 13 | Loss: 23.0051\n",
            "Epoch 86 | Batch: 14 | Loss: 15.0338\n",
            "Epoch 86 | Batch: 15 | Loss: 17.7398\n",
            "Epoch 86 | Batch: 16 | Loss: 14.0686\n",
            "Epoch 86 | Batch: 17 | Loss: 18.2111\n",
            "Epoch 86 | Batch: 18 | Loss: 12.1542\n",
            "Epoch 86 | Batch: 19 | Loss: 18.0704\n",
            "Epoch 86 | Batch: 20 | Loss: 13.3334\n",
            "Epoch 86 | Batch: 21 | Loss: 18.1785\n",
            "Epoch 86 | Batch: 22 | Loss: 20.8523\n",
            "Epoch 86 | Batch: 23 | Loss: 16.7790\n",
            "Epoch 86 | Batch: 24 | Loss: 9.1688\n",
            "Epoch 87 | Batch: 1 | Loss: 11.0434\n",
            "Epoch 87 | Batch: 2 | Loss: 19.5568\n",
            "Epoch 87 | Batch: 3 | Loss: 13.7484\n",
            "Epoch 87 | Batch: 4 | Loss: 13.7677\n",
            "Epoch 87 | Batch: 5 | Loss: 17.8785\n",
            "Epoch 87 | Batch: 6 | Loss: 17.2356\n",
            "Epoch 87 | Batch: 7 | Loss: 20.3069\n",
            "Epoch 87 | Batch: 8 | Loss: 11.8146\n",
            "Epoch 87 | Batch: 9 | Loss: 12.8014\n",
            "Epoch 87 | Batch: 10 | Loss: 16.5664\n",
            "Epoch 87 | Batch: 11 | Loss: 12.5626\n",
            "Epoch 87 | Batch: 12 | Loss: 13.9662\n",
            "Epoch 87 | Batch: 13 | Loss: 13.1478\n",
            "Epoch 87 | Batch: 14 | Loss: 14.3953\n",
            "Epoch 87 | Batch: 15 | Loss: 19.5002\n",
            "Epoch 87 | Batch: 16 | Loss: 8.9656\n",
            "Epoch 87 | Batch: 17 | Loss: 10.7230\n",
            "Epoch 87 | Batch: 18 | Loss: 15.7318\n",
            "Epoch 87 | Batch: 19 | Loss: 16.9366\n",
            "Epoch 87 | Batch: 20 | Loss: 19.9889\n",
            "Epoch 87 | Batch: 21 | Loss: 12.4936\n",
            "Epoch 87 | Batch: 22 | Loss: 11.4575\n",
            "Epoch 87 | Batch: 23 | Loss: 9.3810\n",
            "Epoch 87 | Batch: 24 | Loss: 8.2030\n",
            "Epoch 88 | Batch: 1 | Loss: 11.1856\n",
            "Epoch 88 | Batch: 2 | Loss: 18.6845\n",
            "Epoch 88 | Batch: 3 | Loss: 16.4893\n",
            "Epoch 88 | Batch: 4 | Loss: 11.3032\n",
            "Epoch 88 | Batch: 5 | Loss: 15.6355\n",
            "Epoch 88 | Batch: 6 | Loss: 12.1110\n",
            "Epoch 88 | Batch: 7 | Loss: 21.2918\n",
            "Epoch 88 | Batch: 8 | Loss: 13.3500\n",
            "Epoch 88 | Batch: 9 | Loss: 14.8612\n",
            "Epoch 88 | Batch: 10 | Loss: 13.1575\n",
            "Epoch 88 | Batch: 11 | Loss: 12.2861\n",
            "Epoch 88 | Batch: 12 | Loss: 15.7277\n",
            "Epoch 88 | Batch: 13 | Loss: 14.6795\n",
            "Epoch 88 | Batch: 14 | Loss: 12.8282\n",
            "Epoch 88 | Batch: 15 | Loss: 12.2200\n",
            "Epoch 88 | Batch: 16 | Loss: 14.5509\n",
            "Epoch 88 | Batch: 17 | Loss: 11.2241\n",
            "Epoch 88 | Batch: 18 | Loss: 15.9497\n",
            "Epoch 88 | Batch: 19 | Loss: 14.1177\n",
            "Epoch 88 | Batch: 20 | Loss: 15.2017\n",
            "Epoch 88 | Batch: 21 | Loss: 24.0051\n",
            "Epoch 88 | Batch: 22 | Loss: 19.1991\n",
            "Epoch 88 | Batch: 23 | Loss: 10.8542\n",
            "Epoch 88 | Batch: 24 | Loss: 9.4916\n",
            "Epoch 89 | Batch: 1 | Loss: 11.5477\n",
            "Epoch 89 | Batch: 2 | Loss: 14.9454\n",
            "Epoch 89 | Batch: 3 | Loss: 16.1418\n",
            "Epoch 89 | Batch: 4 | Loss: 16.9118\n",
            "Epoch 89 | Batch: 5 | Loss: 12.5513\n",
            "Epoch 89 | Batch: 6 | Loss: 14.0587\n",
            "Epoch 89 | Batch: 7 | Loss: 13.4065\n",
            "Epoch 89 | Batch: 8 | Loss: 15.2225\n",
            "Epoch 89 | Batch: 9 | Loss: 15.5210\n",
            "Epoch 89 | Batch: 10 | Loss: 10.9876\n",
            "Epoch 89 | Batch: 11 | Loss: 18.9634\n",
            "Epoch 89 | Batch: 12 | Loss: 14.7618\n",
            "Epoch 89 | Batch: 13 | Loss: 15.5754\n",
            "Epoch 89 | Batch: 14 | Loss: 12.6688\n",
            "Epoch 89 | Batch: 15 | Loss: 17.0919\n",
            "Epoch 89 | Batch: 16 | Loss: 9.9133\n",
            "Epoch 89 | Batch: 17 | Loss: 17.3873\n",
            "Epoch 89 | Batch: 18 | Loss: 14.3510\n",
            "Epoch 89 | Batch: 19 | Loss: 15.9131\n",
            "Epoch 89 | Batch: 20 | Loss: 12.4981\n",
            "Epoch 89 | Batch: 21 | Loss: 12.0373\n",
            "Epoch 89 | Batch: 22 | Loss: 14.8551\n",
            "Epoch 89 | Batch: 23 | Loss: 18.6888\n",
            "Epoch 89 | Batch: 24 | Loss: 10.5627\n",
            "Epoch 90 | Batch: 1 | Loss: 12.4757\n",
            "Epoch 90 | Batch: 2 | Loss: 18.1785\n",
            "Epoch 90 | Batch: 3 | Loss: 14.3266\n",
            "Epoch 90 | Batch: 4 | Loss: 11.8685\n",
            "Epoch 90 | Batch: 5 | Loss: 9.5858\n",
            "Epoch 90 | Batch: 6 | Loss: 15.7431\n",
            "Epoch 90 | Batch: 7 | Loss: 11.4785\n",
            "Epoch 90 | Batch: 8 | Loss: 20.2937\n",
            "Epoch 90 | Batch: 9 | Loss: 15.2715\n",
            "Epoch 90 | Batch: 10 | Loss: 14.6871\n",
            "Epoch 90 | Batch: 11 | Loss: 27.2062\n",
            "Epoch 90 | Batch: 12 | Loss: 15.9871\n",
            "Epoch 90 | Batch: 13 | Loss: 11.5461\n",
            "Epoch 90 | Batch: 14 | Loss: 16.6281\n",
            "Epoch 90 | Batch: 15 | Loss: 14.7387\n",
            "Epoch 90 | Batch: 16 | Loss: 13.3385\n",
            "Epoch 90 | Batch: 17 | Loss: 17.3814\n",
            "Epoch 90 | Batch: 18 | Loss: 12.7442\n",
            "Epoch 90 | Batch: 19 | Loss: 16.1300\n",
            "Epoch 90 | Batch: 20 | Loss: 12.6659\n",
            "Epoch 90 | Batch: 21 | Loss: 15.7093\n",
            "Epoch 90 | Batch: 22 | Loss: 13.6933\n",
            "Epoch 90 | Batch: 23 | Loss: 12.9303\n",
            "Epoch 90 | Batch: 24 | Loss: 13.1735\n",
            "Epoch 91 | Batch: 1 | Loss: 12.7060\n",
            "Epoch 91 | Batch: 2 | Loss: 10.8590\n",
            "Epoch 91 | Batch: 3 | Loss: 18.5730\n",
            "Epoch 91 | Batch: 4 | Loss: 11.4634\n",
            "Epoch 91 | Batch: 5 | Loss: 14.0346\n",
            "Epoch 91 | Batch: 6 | Loss: 19.1918\n",
            "Epoch 91 | Batch: 7 | Loss: 19.5138\n",
            "Epoch 91 | Batch: 8 | Loss: 11.9057\n",
            "Epoch 91 | Batch: 9 | Loss: 12.1994\n",
            "Epoch 91 | Batch: 10 | Loss: 10.7200\n",
            "Epoch 91 | Batch: 11 | Loss: 13.8292\n",
            "Epoch 91 | Batch: 12 | Loss: 14.0042\n",
            "Epoch 91 | Batch: 13 | Loss: 16.5118\n",
            "Epoch 91 | Batch: 14 | Loss: 16.4910\n",
            "Epoch 91 | Batch: 15 | Loss: 15.8681\n",
            "Epoch 91 | Batch: 16 | Loss: 15.8362\n",
            "Epoch 91 | Batch: 17 | Loss: 14.1555\n",
            "Epoch 91 | Batch: 18 | Loss: 11.2124\n",
            "Epoch 91 | Batch: 19 | Loss: 22.7347\n",
            "Epoch 91 | Batch: 20 | Loss: 18.2285\n",
            "Epoch 91 | Batch: 21 | Loss: 10.4974\n",
            "Epoch 91 | Batch: 22 | Loss: 10.4434\n",
            "Epoch 91 | Batch: 23 | Loss: 17.5723\n",
            "Epoch 91 | Batch: 24 | Loss: 7.8687\n",
            "Epoch 92 | Batch: 1 | Loss: 11.0964\n",
            "Epoch 92 | Batch: 2 | Loss: 11.4894\n",
            "Epoch 92 | Batch: 3 | Loss: 16.5535\n",
            "Epoch 92 | Batch: 4 | Loss: 13.4331\n",
            "Epoch 92 | Batch: 5 | Loss: 17.7171\n",
            "Epoch 92 | Batch: 6 | Loss: 16.8960\n",
            "Epoch 92 | Batch: 7 | Loss: 9.2548\n",
            "Epoch 92 | Batch: 8 | Loss: 16.2981\n",
            "Epoch 92 | Batch: 9 | Loss: 12.5274\n",
            "Epoch 92 | Batch: 10 | Loss: 17.2673\n",
            "Epoch 92 | Batch: 11 | Loss: 12.8155\n",
            "Epoch 92 | Batch: 12 | Loss: 13.3842\n",
            "Epoch 92 | Batch: 13 | Loss: 18.3935\n",
            "Epoch 92 | Batch: 14 | Loss: 13.8336\n",
            "Epoch 92 | Batch: 15 | Loss: 13.6036\n",
            "Epoch 92 | Batch: 16 | Loss: 26.7333\n",
            "Epoch 92 | Batch: 17 | Loss: 22.0134\n",
            "Epoch 92 | Batch: 18 | Loss: 11.6525\n",
            "Epoch 92 | Batch: 19 | Loss: 14.7733\n",
            "Epoch 92 | Batch: 20 | Loss: 12.6326\n",
            "Epoch 92 | Batch: 21 | Loss: 12.0080\n",
            "Epoch 92 | Batch: 22 | Loss: 12.4532\n",
            "Epoch 92 | Batch: 23 | Loss: 16.0097\n",
            "Epoch 92 | Batch: 24 | Loss: 12.4361\n",
            "Epoch 93 | Batch: 1 | Loss: 25.1151\n",
            "Epoch 93 | Batch: 2 | Loss: 18.7743\n",
            "Epoch 93 | Batch: 3 | Loss: 12.7662\n",
            "Epoch 93 | Batch: 4 | Loss: 13.9696\n",
            "Epoch 93 | Batch: 5 | Loss: 11.5187\n",
            "Epoch 93 | Batch: 6 | Loss: 12.0655\n",
            "Epoch 93 | Batch: 7 | Loss: 12.8963\n",
            "Epoch 93 | Batch: 8 | Loss: 13.8619\n",
            "Epoch 93 | Batch: 9 | Loss: 13.1317\n",
            "Epoch 93 | Batch: 10 | Loss: 14.0933\n",
            "Epoch 93 | Batch: 11 | Loss: 11.4019\n",
            "Epoch 93 | Batch: 12 | Loss: 11.3962\n",
            "Epoch 93 | Batch: 13 | Loss: 10.8958\n",
            "Epoch 93 | Batch: 14 | Loss: 18.6802\n",
            "Epoch 93 | Batch: 15 | Loss: 14.5577\n",
            "Epoch 93 | Batch: 16 | Loss: 12.6360\n",
            "Epoch 93 | Batch: 17 | Loss: 15.4820\n",
            "Epoch 93 | Batch: 18 | Loss: 14.7689\n",
            "Epoch 93 | Batch: 19 | Loss: 12.5357\n",
            "Epoch 93 | Batch: 20 | Loss: 21.1752\n",
            "Epoch 93 | Batch: 21 | Loss: 14.2265\n",
            "Epoch 93 | Batch: 22 | Loss: 16.0988\n",
            "Epoch 93 | Batch: 23 | Loss: 17.6712\n",
            "Epoch 93 | Batch: 24 | Loss: 9.4828\n",
            "Epoch 94 | Batch: 1 | Loss: 16.0550\n",
            "Epoch 94 | Batch: 2 | Loss: 15.4697\n",
            "Epoch 94 | Batch: 3 | Loss: 13.9460\n",
            "Epoch 94 | Batch: 4 | Loss: 17.2438\n",
            "Epoch 94 | Batch: 5 | Loss: 15.5694\n",
            "Epoch 94 | Batch: 6 | Loss: 13.4518\n",
            "Epoch 94 | Batch: 7 | Loss: 10.7163\n",
            "Epoch 94 | Batch: 8 | Loss: 11.8388\n",
            "Epoch 94 | Batch: 9 | Loss: 14.5747\n",
            "Epoch 94 | Batch: 10 | Loss: 10.3737\n",
            "Epoch 94 | Batch: 11 | Loss: 16.8293\n",
            "Epoch 94 | Batch: 12 | Loss: 12.8779\n",
            "Epoch 94 | Batch: 13 | Loss: 15.5186\n",
            "Epoch 94 | Batch: 14 | Loss: 10.9769\n",
            "Epoch 94 | Batch: 15 | Loss: 14.8372\n",
            "Epoch 94 | Batch: 16 | Loss: 13.3304\n",
            "Epoch 94 | Batch: 17 | Loss: 24.4659\n",
            "Epoch 94 | Batch: 18 | Loss: 18.1772\n",
            "Epoch 94 | Batch: 19 | Loss: 13.5953\n",
            "Epoch 94 | Batch: 20 | Loss: 12.2791\n",
            "Epoch 94 | Batch: 21 | Loss: 13.6360\n",
            "Epoch 94 | Batch: 22 | Loss: 15.5265\n",
            "Epoch 94 | Batch: 23 | Loss: 11.9061\n",
            "Epoch 94 | Batch: 24 | Loss: 8.3076\n",
            "Epoch 95 | Batch: 1 | Loss: 11.8845\n",
            "Epoch 95 | Batch: 2 | Loss: 10.2233\n",
            "Epoch 95 | Batch: 3 | Loss: 15.9825\n",
            "Epoch 95 | Batch: 4 | Loss: 12.4230\n",
            "Epoch 95 | Batch: 5 | Loss: 14.6895\n",
            "Epoch 95 | Batch: 6 | Loss: 12.5684\n",
            "Epoch 95 | Batch: 7 | Loss: 14.9949\n",
            "Epoch 95 | Batch: 8 | Loss: 13.7689\n",
            "Epoch 95 | Batch: 9 | Loss: 16.8411\n",
            "Epoch 95 | Batch: 10 | Loss: 18.4616\n",
            "Epoch 95 | Batch: 11 | Loss: 18.2383\n",
            "Epoch 95 | Batch: 12 | Loss: 16.0409\n",
            "Epoch 95 | Batch: 13 | Loss: 10.0468\n",
            "Epoch 95 | Batch: 14 | Loss: 14.7043\n",
            "Epoch 95 | Batch: 15 | Loss: 13.4967\n",
            "Epoch 95 | Batch: 16 | Loss: 14.2826\n",
            "Epoch 95 | Batch: 17 | Loss: 12.6702\n",
            "Epoch 95 | Batch: 18 | Loss: 9.6069\n",
            "Epoch 95 | Batch: 19 | Loss: 18.5820\n",
            "Epoch 95 | Batch: 20 | Loss: 14.3381\n",
            "Epoch 95 | Batch: 21 | Loss: 20.2901\n",
            "Epoch 95 | Batch: 22 | Loss: 12.1539\n",
            "Epoch 95 | Batch: 23 | Loss: 16.5285\n",
            "Epoch 95 | Batch: 24 | Loss: 8.9739\n",
            "Epoch 96 | Batch: 1 | Loss: 12.1984\n",
            "Epoch 96 | Batch: 2 | Loss: 12.8083\n",
            "Epoch 96 | Batch: 3 | Loss: 15.2560\n",
            "Epoch 96 | Batch: 4 | Loss: 16.6116\n",
            "Epoch 96 | Batch: 5 | Loss: 11.8196\n",
            "Epoch 96 | Batch: 6 | Loss: 14.5784\n",
            "Epoch 96 | Batch: 7 | Loss: 10.1999\n",
            "Epoch 96 | Batch: 8 | Loss: 14.0407\n",
            "Epoch 96 | Batch: 9 | Loss: 12.1860\n",
            "Epoch 96 | Batch: 10 | Loss: 12.7525\n",
            "Epoch 96 | Batch: 11 | Loss: 17.5240\n",
            "Epoch 96 | Batch: 12 | Loss: 11.5643\n",
            "Epoch 96 | Batch: 13 | Loss: 12.9956\n",
            "Epoch 96 | Batch: 14 | Loss: 18.3863\n",
            "Epoch 96 | Batch: 15 | Loss: 10.6814\n",
            "Epoch 96 | Batch: 16 | Loss: 15.0038\n",
            "Epoch 96 | Batch: 17 | Loss: 16.8979\n",
            "Epoch 96 | Batch: 18 | Loss: 14.5089\n",
            "Epoch 96 | Batch: 19 | Loss: 13.1882\n",
            "Epoch 96 | Batch: 20 | Loss: 15.9974\n",
            "Epoch 96 | Batch: 21 | Loss: 17.0106\n",
            "Epoch 96 | Batch: 22 | Loss: 15.0071\n",
            "Epoch 96 | Batch: 23 | Loss: 15.9483\n",
            "Epoch 96 | Batch: 24 | Loss: 10.9766\n",
            "Epoch 97 | Batch: 1 | Loss: 15.3961\n",
            "Epoch 97 | Batch: 2 | Loss: 16.5634\n",
            "Epoch 97 | Batch: 3 | Loss: 14.9046\n",
            "Epoch 97 | Batch: 4 | Loss: 15.5233\n",
            "Epoch 97 | Batch: 5 | Loss: 11.6096\n",
            "Epoch 97 | Batch: 6 | Loss: 15.5527\n",
            "Epoch 97 | Batch: 7 | Loss: 16.7664\n",
            "Epoch 97 | Batch: 8 | Loss: 14.8683\n",
            "Epoch 97 | Batch: 9 | Loss: 9.2704\n",
            "Epoch 97 | Batch: 10 | Loss: 15.6085\n",
            "Epoch 97 | Batch: 11 | Loss: 8.8967\n",
            "Epoch 97 | Batch: 12 | Loss: 12.3142\n",
            "Epoch 97 | Batch: 13 | Loss: 14.7602\n",
            "Epoch 97 | Batch: 14 | Loss: 14.4641\n",
            "Epoch 97 | Batch: 15 | Loss: 11.9815\n",
            "Epoch 97 | Batch: 16 | Loss: 15.9165\n",
            "Epoch 97 | Batch: 17 | Loss: 11.1419\n",
            "Epoch 97 | Batch: 18 | Loss: 17.7520\n",
            "Epoch 97 | Batch: 19 | Loss: 16.4846\n",
            "Epoch 97 | Batch: 20 | Loss: 17.3363\n",
            "Epoch 97 | Batch: 21 | Loss: 13.4690\n",
            "Epoch 97 | Batch: 22 | Loss: 11.9624\n",
            "Epoch 97 | Batch: 23 | Loss: 21.1962\n",
            "Epoch 97 | Batch: 24 | Loss: 8.4590\n",
            "Epoch 98 | Batch: 1 | Loss: 13.0493\n",
            "Epoch 98 | Batch: 2 | Loss: 7.5733\n",
            "Epoch 98 | Batch: 3 | Loss: 16.6684\n",
            "Epoch 98 | Batch: 4 | Loss: 16.0668\n",
            "Epoch 98 | Batch: 5 | Loss: 14.1491\n",
            "Epoch 98 | Batch: 6 | Loss: 8.6972\n",
            "Epoch 98 | Batch: 7 | Loss: 14.1018\n",
            "Epoch 98 | Batch: 8 | Loss: 18.5485\n",
            "Epoch 98 | Batch: 9 | Loss: 15.3037\n",
            "Epoch 98 | Batch: 10 | Loss: 13.0494\n",
            "Epoch 98 | Batch: 11 | Loss: 9.2531\n",
            "Epoch 98 | Batch: 12 | Loss: 19.2188\n",
            "Epoch 98 | Batch: 13 | Loss: 13.2148\n",
            "Epoch 98 | Batch: 14 | Loss: 9.4631\n",
            "Epoch 98 | Batch: 15 | Loss: 17.4927\n",
            "Epoch 98 | Batch: 16 | Loss: 14.9230\n",
            "Epoch 98 | Batch: 17 | Loss: 15.6164\n",
            "Epoch 98 | Batch: 18 | Loss: 12.3186\n",
            "Epoch 98 | Batch: 19 | Loss: 21.4981\n",
            "Epoch 98 | Batch: 20 | Loss: 13.1387\n",
            "Epoch 98 | Batch: 21 | Loss: 21.1643\n",
            "Epoch 98 | Batch: 22 | Loss: 19.5501\n",
            "Epoch 98 | Batch: 23 | Loss: 14.0751\n",
            "Epoch 98 | Batch: 24 | Loss: 8.5099\n",
            "Epoch 99 | Batch: 1 | Loss: 12.7659\n",
            "Epoch 99 | Batch: 2 | Loss: 13.2172\n",
            "Epoch 99 | Batch: 3 | Loss: 11.4912\n",
            "Epoch 99 | Batch: 4 | Loss: 17.2079\n",
            "Epoch 99 | Batch: 5 | Loss: 13.0498\n",
            "Epoch 99 | Batch: 6 | Loss: 14.1761\n",
            "Epoch 99 | Batch: 7 | Loss: 17.0389\n",
            "Epoch 99 | Batch: 8 | Loss: 17.4722\n",
            "Epoch 99 | Batch: 9 | Loss: 17.4446\n",
            "Epoch 99 | Batch: 10 | Loss: 14.8336\n",
            "Epoch 99 | Batch: 11 | Loss: 14.4848\n",
            "Epoch 99 | Batch: 12 | Loss: 16.2609\n",
            "Epoch 99 | Batch: 13 | Loss: 16.4204\n",
            "Epoch 99 | Batch: 14 | Loss: 19.8962\n",
            "Epoch 99 | Batch: 15 | Loss: 14.4585\n",
            "Epoch 99 | Batch: 16 | Loss: 16.2947\n",
            "Epoch 99 | Batch: 17 | Loss: 13.5261\n",
            "Epoch 99 | Batch: 18 | Loss: 15.3480\n",
            "Epoch 99 | Batch: 19 | Loss: 11.3509\n",
            "Epoch 99 | Batch: 20 | Loss: 8.2581\n",
            "Epoch 99 | Batch: 21 | Loss: 12.8250\n",
            "Epoch 99 | Batch: 22 | Loss: 13.6050\n",
            "Epoch 99 | Batch: 23 | Loss: 17.6330\n",
            "Epoch 99 | Batch: 24 | Loss: 7.9054\n",
            "Epoch 100 | Batch: 1 | Loss: 11.9224\n",
            "Epoch 100 | Batch: 2 | Loss: 15.8305\n",
            "Epoch 100 | Batch: 3 | Loss: 9.4824\n",
            "Epoch 100 | Batch: 4 | Loss: 15.1030\n",
            "Epoch 100 | Batch: 5 | Loss: 16.5870\n",
            "Epoch 100 | Batch: 6 | Loss: 19.2224\n",
            "Epoch 100 | Batch: 7 | Loss: 19.5506\n",
            "Epoch 100 | Batch: 8 | Loss: 19.1941\n",
            "Epoch 100 | Batch: 9 | Loss: 16.6861\n",
            "Epoch 100 | Batch: 10 | Loss: 15.8528\n",
            "Epoch 100 | Batch: 11 | Loss: 16.2682\n",
            "Epoch 100 | Batch: 12 | Loss: 14.5858\n",
            "Epoch 100 | Batch: 13 | Loss: 13.3344\n",
            "Epoch 100 | Batch: 14 | Loss: 10.2621\n",
            "Epoch 100 | Batch: 15 | Loss: 18.1810\n",
            "Epoch 100 | Batch: 16 | Loss: 11.1211\n",
            "Epoch 100 | Batch: 17 | Loss: 15.3599\n",
            "Epoch 100 | Batch: 18 | Loss: 10.8372\n",
            "Epoch 100 | Batch: 19 | Loss: 17.1118\n",
            "Epoch 100 | Batch: 20 | Loss: 8.0718\n",
            "Epoch 100 | Batch: 21 | Loss: 15.1963\n",
            "Epoch 100 | Batch: 22 | Loss: 8.9053\n",
            "Epoch 100 | Batch: 23 | Loss: 12.5098\n",
            "Epoch 100 | Batch: 24 | Loss: 12.1130\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}